{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "q_QuctboP3Tv"
      ],
      "gpuType": "A100",
      "toc_visible": true,
      "mount_file_id": "1pQBkM-fUmwWgoDcKxDF_Zl82BHqdmloO",
      "authorship_tag": "ABX9TyO0yo6YJVGSr4AlUkU/hw7r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adinsegall/dl4am-cvae-bilstm/blob/main/DL4AM_Coursework_Segall.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL4AM Coursework: Combining Loop Candidacy Detection and Source Separation Models\n",
        "\n",
        "Author: Adin Segall\n",
        "\n",
        "This notebook contains the code, results, and analysis for the DL4AM coursework project focused on applying deep learning techniques to musical audio processing tasks. The goal is to implement and combine two distinct models:\n",
        "\n",
        "1. A BiLSTM-based binary classifier to predict the \"loopability\" of short music segments (i.e. their suitability for seamless repetition). This model will learn on mel spectrogram input representations.  \n",
        "\n",
        "2. A convolutional variational autoencoder (CVAE) to perform source separation on mixed audio signals, isolating individual instrumental elements. The CVAE will operate on magnitude spectrogram inputs and produce time-frequency masks to extract sources.\n",
        "\n",
        "Both models will be trained and evaluated independently on the Free Music Archive (FMA) dataset, which provides source audio files, and optionally the Groove MIDI dataset for more granular rhythm pattern analysis. Key evaluation metrics will include accuracy and F1-score for the loop classifier, and signal-to-distortion ratio (SDR) and related source separation metrics for the CVAE.  \n",
        "\n",
        "After developing the standalone models, different strategies for joint optimization and transfer learning will be explored to assess potential performance gains from shared feature extraction and end-to-end training.\n",
        "\n",
        "The notebook is organized as follows:\n",
        "1. Setup\n",
        "   1.1 Imports\n",
        "   1.2 Logging\n",
        "   1.3 Device Configuration\n",
        "2. Dataset Loading and Preprocessing\n",
        "   2.1 FMA Dataset\n",
        "   2.2 Groove MIDI Dataset\n",
        "3. Model Implementations\n",
        "4. Training Procedures\n",
        "5. Evaluation and Results\n",
        "6. Model Combination Strategies\n",
        "7. Discussion and Interpretation\n",
        "8. Conclusion and Future Directions\n",
        "\n",
        "Code and analysis will be presented with the goal of academic rigor, suitable for conference submission in applied machine learning for audio. All key modeling choices and training details will be justified according to best practices established in the DL4AM module and relevant literature."
      ],
      "metadata": {
        "id": "cHUmgcxwOzwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup"
      ],
      "metadata": {
        "id": "q_QuctboP3Tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pretty_midi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTzxdza3up-G",
        "outputId": "c9f79e4a-0a21-4128-e5ff-124f8ee97999"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pretty_midi in /usr/local/lib/python3.11/dist-packages (0.2.10)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (2.0.2)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (1.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mido>=1.1.16->pretty_midi) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2IGcnMKbwUfr",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 1.1 Imports\n",
        "\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import logging\n",
        "import zipfile\n",
        "from os import listdir\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import torchaudio\n",
        "from torchaudio.transforms import MelSpectrogram\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import pretty_midi\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.2 Logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vWd4SCxsP-a_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.3 Device Configuration\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mMknV9GaTzBC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Datasets"
      ],
      "metadata": {
        "id": "W9TmdV-NT7vP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.0 Dataset Download and Setup\n",
        "\n",
        "# Path to dataset storage inside Google Drive\n",
        "drive_root = '/content/drive/MyDrive/DL4AM_datasets'\n",
        "\n",
        "# Make sure the directory exists\n",
        "os.makedirs(drive_root, exist_ok=True)\n",
        "\n",
        "# Paths inside Google Drive\n",
        "fma_small_zip = os.path.join(drive_root, 'fma_small.zip')\n",
        "fma_small_folder = os.path.join(drive_root, 'fma_small')\n",
        "fma_small_url = 'https://os.unil.cloud.switch.ch/fma/fma_small.zip'\n",
        "\n",
        "fma_metadata_zip = os.path.join(drive_root, 'fma_metadata.zip')\n",
        "fma_metadata_folder = os.path.join(drive_root, 'fma_metadata')\n",
        "fma_metadata_url = 'https://os.unil.cloud.switch.ch/fma/fma_metadata.zip'\n",
        "\n",
        "egmd_zip = os.path.join(drive_root, 'e-gmd-v1.0.0-midi.zip')\n",
        "egmd_folder = os.path.join(drive_root, 'e-gmd-v1.0.0-midi')\n",
        "egmd_url = 'https://storage.googleapis.com/magentadata/datasets/e-gmd/v1.0.0/e-gmd-v1.0.0-midi.zip'\n",
        "\n",
        "# --- FMA Small ---\n",
        "if not os.path.exists(fma_small_folder):\n",
        "    print(f\"Downloading FMA Small to {fma_small_zip}...\")\n",
        "    !wget -O \"$fma_small_zip\" \"$fma_small_url\"\n",
        "\n",
        "    print(f\"Extracting to {fma_small_folder}...\")\n",
        "    !unzip -q \"$fma_small_zip\" -d \"$drive_root\"\n",
        "    os.remove(fma_small_zip)\n",
        "else:\n",
        "    print(f\"FMA Small already exists at {fma_small_folder}\")\n",
        "\n",
        "# --- FMA Metadata ---\n",
        "if not os.path.exists(fma_metadata_folder):\n",
        "    print(f\"Downloading FMA Metadata to {fma_metadata_zip}...\")\n",
        "    !wget -O \"$fma_metadata_zip\" \"$fma_metadata_url\"\n",
        "\n",
        "    print(f\"Extracting to {fma_metadata_folder}...\")\n",
        "    !unzip -q \"$fma_metadata_zip\" -d \"$drive_root\"\n",
        "    os.remove(fma_metadata_zip)\n",
        "else:\n",
        "    print(f\"FMA Metadata already exists at {fma_metadata_folder}\")\n",
        "\n",
        "# --- E-GMD MIDI ---\n",
        "if not os.path.exists(egmd_folder):\n",
        "    print(f\"Downloading E-GMD MIDI to {egmd_zip}...\")\n",
        "    !wget -O \"$egmd_zip\" \"$egmd_url\"\n",
        "\n",
        "    print(f\"Extracting to {egmd_folder}...\")\n",
        "    with zipfile.ZipFile(egmd_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(drive_root)\n",
        "    os.remove(egmd_zip)\n",
        "else:\n",
        "    print(f\"E-GMD MIDI already exists at {egmd_folder}\")\n",
        "\n",
        "print(\"Dataset setup complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "89ZC2HpShKlc",
        "outputId": "883b9085-83c3-4353-d632-c72fb1b505c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FMA Small already exists at /content/drive/MyDrive/DL4AM_datasets/fma_small\n",
            "FMA Metadata already exists at /content/drive/MyDrive/DL4AM_datasets/fma_metadata\n",
            "E-GMD MIDI already exists at /content/drive/MyDrive/DL4AM_datasets/e-gmd-v1.0.0-midi\n",
            "Dataset setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.1 FMA Dataset\n",
        "\n",
        "class FMADataset(Dataset):\n",
        "    \"\"\"Free Music Archive audio dataset (log-mel spectrograms + genre labels).\"\"\"\n",
        "    def __init__(self, root_dir, metadata_file, transform=None,\n",
        "                 n_mels=128, hop_length=512, sample_rate=22050, n_frames=860):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (str): Path to FMA root directory (e.g., 'fma_small').\n",
        "            metadata_file (str): Path to metadata CSV file (e.g., 'tracks.csv').\n",
        "            transform (callable, optional): Optional transform to apply to each sample.\n",
        "            n_mels (int): Number of mel bins.\n",
        "            hop_length (int): Hop length for mel spectrogram.\n",
        "            sample_rate (int): Target sample rate.\n",
        "            n_frames (int): Target number of spectrogram frames (for trimming/padding).\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.n_mels = n_mels\n",
        "        self.hop_length = hop_length\n",
        "        self.sample_rate = sample_rate\n",
        "        self.n_frames = n_frames\n",
        "        # Calculate the mean and standard deviation of the training data\n",
        "        self.data_mean = None\n",
        "        self.data_std = None\n",
        "\n",
        "        # Load metadata and filter valid tracks\n",
        "        logger.info(f\"Loading metadata from {metadata_file}\")\n",
        "        self.tracks = self._load_metadata(metadata_file)\n",
        "        logger.info(f\"Loaded metadata for {len(self.tracks)} tracks\")\n",
        "\n",
        "        # Find all MP3 files recursively in the root directory\n",
        "        self.file_paths = self._find_mp3_files(root_dir)\n",
        "        logger.info(f\"Found {len(self.file_paths)} MP3 files in {root_dir}\")\n",
        "\n",
        "        # Match files to metadata and keep only valid tracks\n",
        "        self._match_files_to_metadata()\n",
        "        logger.info(f\"Dataset contains {len(self.valid_indices)} valid tracks with metadata\")\n",
        "\n",
        "        # Create label encoder for genres\n",
        "        self._create_label_encoder()\n",
        "\n",
        "    def _load_metadata(self, metadata_file):\n",
        "        \"\"\"Load and parse the tracks metadata file\"\"\"\n",
        "        metadata = pd.read_csv(metadata_file, index_col=0, header=[0, 1])\n",
        "\n",
        "        # Keep only the tracks with a valid genre\n",
        "        metadata = metadata[metadata['track', 'genre_top'].notna()]\n",
        "\n",
        "        # Convert multi-level columns to single level for easier access\n",
        "        metadata.columns = [f\"{col[0]}_{col[1]}\" for col in metadata.columns]\n",
        "\n",
        "        return metadata\n",
        "\n",
        "    def _find_mp3_files(self, root_dir):\n",
        "        \"\"\"Recursively find all MP3 files in the root directory\"\"\"\n",
        "        file_paths = []\n",
        "        for root, dirs, files in os.walk(root_dir):\n",
        "            for file in files:\n",
        "                if file.endswith('.mp3'):\n",
        "                    file_paths.append(os.path.join(root, file))\n",
        "        return file_paths\n",
        "\n",
        "    def _match_files_to_metadata(self):\n",
        "        \"\"\"Match MP3 files to metadata entries\"\"\"\n",
        "        self.valid_indices = []\n",
        "        self.track_ids = []\n",
        "        self.valid_file_paths = []\n",
        "\n",
        "        for i, file_path in enumerate(self.file_paths):\n",
        "            # Extract track ID from filename (remove .mp3 extension)\n",
        "            filename = os.path.basename(file_path)\n",
        "            try:\n",
        "                track_id = int(filename.split('.')[0])\n",
        "\n",
        "                # Check if track exists in metadata\n",
        "                if track_id in self.tracks.index:\n",
        "                    self.valid_indices.append(i)\n",
        "                    self.track_ids.append(track_id)\n",
        "                    self.valid_file_paths.append(file_path)\n",
        "            except:\n",
        "                # Skip files with invalid names\n",
        "                continue\n",
        "\n",
        "    def _create_label_encoder(self):\n",
        "        \"\"\"Create a label encoder for genre labels\"\"\"\n",
        "        genres = [self.tracks.loc[track_id, 'track_genre_top'] for track_id in self.track_ids]\n",
        "        self.encoder = LabelEncoder()\n",
        "        self.encoder.fit(genres)\n",
        "        self.num_classes = len(self.encoder.classes_)\n",
        "        logger.info(f\"Found {self.num_classes} unique genre classes\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get file path and track ID\n",
        "        file_path = self.valid_file_paths[idx]\n",
        "        track_id = self.track_ids[idx]\n",
        "\n",
        "        try:\n",
        "            # Load audio file\n",
        "            waveform, sr = torchaudio.load(file_path)\n",
        "\n",
        "            # Convert to mono if stereo\n",
        "            if waveform.shape[0] > 1:\n",
        "                waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "\n",
        "            # Resample if necessary\n",
        "            if sr != self.sample_rate:\n",
        "                waveform = torchaudio.functional.resample(waveform, sr, self.sample_rate)\n",
        "\n",
        "            # Convert to numpy for librosa processing\n",
        "            waveform_np = waveform.numpy().squeeze()\n",
        "\n",
        "            # Compute mel spectrogram\n",
        "            mel_spec = librosa.feature.melspectrogram(\n",
        "                y=waveform_np,\n",
        "                sr=self.sample_rate,\n",
        "                n_mels=self.n_mels,\n",
        "                hop_length=self.hop_length\n",
        "            )\n",
        "            log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "            # Normalize the log-mel spectrogram using the mean and standard deviation\n",
        "            if self.data_mean is not None and self.data_std is not None:\n",
        "                log_mel_spec = (log_mel_spec - self.data_mean) / (self.data_std + 1e-8)\n",
        "            else:\n",
        "                # If mean and std are not provided, standardize the data\n",
        "                log_mel_spec = (log_mel_spec - log_mel_spec.mean()) / (log_mel_spec.std() + 1e-8)\n",
        "\n",
        "            # Pad or trim to fixed frame length\n",
        "            if log_mel_spec.shape[1] < self.n_frames:\n",
        "                pad_width = self.n_frames - log_mel_spec.shape[1]\n",
        "                log_mel_spec = np.pad(log_mel_spec, ((0, 0), (0, pad_width)), mode='constant')\n",
        "            else:\n",
        "                log_mel_spec = log_mel_spec[:, :self.n_frames]\n",
        "\n",
        "            # Add channel dimension\n",
        "            log_mel_spec = log_mel_spec[np.newaxis, :, :]\n",
        "\n",
        "            # Get genre label\n",
        "            genre = self.tracks.loc[track_id, 'track_genre_top']\n",
        "            label = self.encoder.transform([genre])[0]\n",
        "\n",
        "            sample = {\n",
        "                'spectrogram': torch.tensor(log_mel_spec, dtype=torch.float32),\n",
        "                'class_label': label,\n",
        "                'track_id': track_id\n",
        "            }\n",
        "\n",
        "            if self.transform:\n",
        "                sample = self.transform(sample)\n",
        "\n",
        "            return sample\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error processing {file_path}: {e}\")\n",
        "            # Return a dummy sample as fallback (you might want to handle this differently)\n",
        "            return {\n",
        "                'spectrogram': torch.zeros((1, self.n_mels, self.n_frames), dtype=torch.float32),\n",
        "                'class_label': 0,\n",
        "                'track_id': track_id\n",
        "            }\n",
        "\n",
        "    def get_train_val_indices(self, val_size=0.2, random_state=42):\n",
        "        \"\"\"Create random train/validation split indices\"\"\"\n",
        "        indices = list(range(len(self.valid_indices)))\n",
        "        n_val = int(len(indices) * val_size)\n",
        "\n",
        "        # Shuffle indices\n",
        "        np.random.seed(random_state)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        # Split indices\n",
        "        train_indices = indices[n_val:]\n",
        "        val_indices = indices[:n_val]\n",
        "\n",
        "        return train_indices, val_indices"
      ],
      "metadata": {
        "id": "lwAHkBd-T3nx",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.2 Groove MIDI Dataset\n",
        "\n",
        "class GrooveMIDIDataset(Dataset):\n",
        "    def __init__(self, root_dir, max_files=50, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.max_files = max_files\n",
        "\n",
        "        # Get list of MIDI files\n",
        "        self.midi_files = [os.path.join(root_dir, 'midi', f) for f in os.listdir(os.path.join(root_dir, 'midi'))]\n",
        "\n",
        "        # Randomly select a subset of MIDI files\n",
        "        if len(self.midi_files) > max_files:\n",
        "            self.midi_files = random.sample(self.midi_files, max_files)\n",
        "\n",
        "        logger.info(f'Loaded {len(self.midi_files)} MIDI files from {root_dir}')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.midi_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        midi_path = self.midi_files[idx]\n",
        "\n",
        "        try:\n",
        "            # Load MIDI file\n",
        "            midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
        "\n",
        "            # Extract features\n",
        "            onsets = []\n",
        "            velocities = []\n",
        "            durations = []\n",
        "            microtimings = []\n",
        "\n",
        "            for instrument in midi_data.instruments:\n",
        "                if not instrument.is_drum:\n",
        "                    for note in instrument.notes:\n",
        "                        onsets.append(midi_data.time_to_tick(note.start) / midi_data.resolution)\n",
        "                        velocities.append(note.velocity)\n",
        "                        durations.append(midi_data.time_to_tick(note.end - note.start) / midi_data.resolution)\n",
        "                        microtimings.append((note.start - midi_data.tick_to_time(midi_data.time_to_tick(note.start))) * midi_data.resolution)\n",
        "\n",
        "            # Create feature matrix\n",
        "            n_frames = 128  # Adjust as needed\n",
        "            onset_frame = np.zeros((n_frames,))\n",
        "            velocity_frame = np.zeros((n_frames,))\n",
        "            duration_frame = np.zeros((n_frames,))\n",
        "            microtiming_frame = np.zeros((n_frames,))\n",
        "\n",
        "            for onset, velocity, duration, microtiming in zip(onsets, velocities, durations, microtimings):\n",
        "                onset_idx = int(onset * (n_frames - 1))\n",
        "                onset_frame[onset_idx] = 1\n",
        "                velocity_frame[onset_idx] = velocity\n",
        "                duration_frame[onset_idx] = duration\n",
        "                microtiming_frame[onset_idx] = microtiming\n",
        "\n",
        "            # Stack features into a matrix\n",
        "            feature_matrix = np.stack((onset_frame, velocity_frame, duration_frame, microtiming_frame))\n",
        "\n",
        "            # Normalize feature matrix\n",
        "            mean = feature_matrix.mean()\n",
        "            std = feature_matrix.std()\n",
        "            feature_matrix = (feature_matrix - mean) / std\n",
        "\n",
        "            # Add channel dimension\n",
        "            feature_matrix = feature_matrix[np.newaxis, :, :]\n",
        "\n",
        "            # Create sample dictionary\n",
        "            sample = {'feature_matrix': feature_matrix,\n",
        "                      'midi_path': midi_path}\n",
        "\n",
        "            if self.transform:\n",
        "                sample = self.transform(sample)\n",
        "\n",
        "            return sample\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f'Failed to load {midi_path}. Error: {e}')\n",
        "            return self.__getitem__(random.randint(0, self.__len__() - 1))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1UWk6EaLxcry"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.3 Dataset Instantiation and DataLoaders\n",
        "# Define paths to your data and metadata\n",
        "fma_small_dir = \"/content/drive/MyDrive/DL4AM_datasets/fma_small\"\n",
        "fma_metadata_file = \"/content/drive/MyDrive/DL4AM_datasets/fma_metadata/tracks.csv\"\n",
        "\n",
        "# Create dataset instance\n",
        "logger.info(\"Creating FMA dataset instance...\")\n",
        "fma_dataset = FMADataset(\n",
        "    root_dir=fma_small_dir,\n",
        "    metadata_file=fma_metadata_file,\n",
        "    transform=None,  # No transform needed since we handle tensor conversion in __getitem__\n",
        "    n_mels=128,\n",
        "    hop_length=512,\n",
        "    sample_rate=22050,\n",
        "    n_frames=860\n",
        ")\n",
        "# Create random train/validation split indices (80% train, 20% validation)\n",
        "train_indices, val_indices = fma_dataset.get_train_val_indices(val_size=0.2, random_state=42)\n",
        "logger.info(f\"Train set: {len(train_indices)} samples, Validation set: {len(val_indices)} samples\")\n",
        "\n",
        "# Calculate the mean and standard deviation of the training data\n",
        "if len(train_indices) > 0:\n",
        "    train_data = torch.stack([fma_dataset[i]['spectrogram'] for i in train_indices])\n",
        "    fma_dataset.data_mean = train_data.mean()\n",
        "    fma_dataset.data_std = train_data.std()\n",
        "else:\n",
        "    logger.warning(\"No training data found. Skipping mean and standard deviation calculation.\")\n",
        "\n",
        "\n",
        "\n",
        "# Create data loaders for CVAE model\n",
        "cvae_train_loader = DataLoader(\n",
        "    dataset=fma_dataset,\n",
        "    batch_size=4,\n",
        "    sampler=SubsetRandomSampler(train_indices),\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "cvae_val_loader = DataLoader(\n",
        "    dataset=fma_dataset,\n",
        "    batch_size=4,\n",
        "    sampler=SubsetRandomSampler(val_indices),\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Create data loaders for BiLSTM model (using the same dataset and split)\n",
        "bilstm_train_loader = DataLoader(\n",
        "    dataset=fma_dataset,\n",
        "    batch_size=4,\n",
        "    sampler=SubsetRandomSampler(train_indices),\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "bilstm_val_loader = DataLoader(\n",
        "    dataset=fma_dataset,\n",
        "    batch_size=4,\n",
        "    sampler=SubsetRandomSampler(val_indices),\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Test the data loader\n",
        "logger.info(\"Testing data loader...\")\n",
        "try:\n",
        "    sample_batch = next(iter(cvae_train_loader))\n",
        "    logger.info(f\"Sample batch spectrogram shape: {sample_batch['spectrogram'].shape}\")\n",
        "    logger.info(f\"Sample batch class labels: {sample_batch['class_label'][:5]}\")  # Show first 5 labels\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error testing data loader: {e}\")"
      ],
      "metadata": {
        "id": "eyS5FEkW5mba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a44281-b2df-48d1-f3d0-24f1e8b1bbaa",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108925.mp3: Failed to open the input \"/content/drive/MyDrive/DL4AM_datasets/fma_small/108/108925.mp3\" (Invalid argument).\n",
            "Exception raised from get_input_format_context at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_reader/stream_reader.cpp:42 (most recent call first):\n",
            "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x79bfa736c1b6 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\n",
            "frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x79bfa7315a76 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\n",
            "frame #2: <unknown function> + 0x42034 (0x79bfa72a8034 in /usr/local/lib/python3.11/dist-packages/torio/lib/libtorio_ffmpeg4.so)\n",
            "frame #3: torio::io::StreamingMediaDecoder::StreamingMediaDecoder(std::string const&, std::optional<std::string> const&, std::optional<std::map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<std::string const, std::string> > > > const&) + 0x14 (0x79bfa72aaa34 in /usr/local/lib/python3.11/dist-packages/torio/lib/libtorio_ffmpeg4.so)\n",
            "frame #4: <unknown function> + 0x3bfee (0x79be7af58fee in /usr/local/lib/python3.11/dist-packages/torio/lib/_torio_ffmpeg4.so)\n",
            "frame #5: <unknown function> + 0x330c7 (0x79be7af500c7 in /usr/local/lib/python3.11/dist-packages/torio/lib/_torio_ffmpeg4.so)\n",
            "frame #6: /usr/bin/python3() [0x55560b]\n",
            "frame #7: _PyObject_MakeTpCall + 0x27c (0x52f6dc in /usr/bin/python3)\n",
            "frame #8: /usr/bin/python3() [0x5853fd]\n",
            "frame #9: /usr/bin/python3() [0x56e2a9]\n",
            "frame #10: /usr/bin/python3() [0x52fac0]\n",
            "frame #11: <unknown function> + 0xfc6b (0x79bfa7751c6b in /usr/local/lib/python3.11/dist-packages/torchaudio/lib/_torchaudio.so)\n",
            "frame #12: _PyObject_MakeTpCall + 0x27c (0x52f6dc in /usr/bin/python3)\n",
            "frame #13: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #14: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #15: /usr/bin/python3() [0x56df36]\n",
            "frame #16: _PyObject_MakeTpCall + 0x23b (0x52f69b in /usr/bin/python3)\n",
            "frame #17: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #18: /usr/bin/python3() [0x613a24]\n",
            "frame #19: PyEval_EvalCode + 0x97 (0x613087 in /usr/bin/python3)\n",
            "frame #20: /usr/bin/python3() [0x62cde3]\n",
            "frame #21: _PyEval_EvalFrameDefault + 0x3801 (0x5409b1 in /usr/bin/python3)\n",
            "frame #22: /usr/bin/python3() [0x6288d0]\n",
            "frame #23: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #24: /usr/bin/python3() [0x6288d0]\n",
            "frame #25: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #26: /usr/bin/python3() [0x6288d0]\n",
            "frame #27: /usr/bin/python3() [0x62ae9c]\n",
            "frame #28: _PyEval_EvalFrameDefault + 0x3a8a (0x540c3a in /usr/bin/python3)\n",
            "frame #29: /usr/bin/python3() [0x585b17]\n",
            "frame #30: /usr/bin/python3() [0x5852fe]\n",
            "frame #31: PyObject_Call + 0xf4 (0x570784 in /usr/bin/python3)\n",
            "frame #32: _PyEval_EvalFrameDefault + 0x4aab (0x541c5b in /usr/bin/python3)\n",
            "frame #33: /usr/bin/python3() [0x6288d0]\n",
            "frame #34: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #35: /usr/bin/python3() [0x6288d0]\n",
            "frame #36: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #37: /usr/bin/python3() [0x6288d0]\n",
            "frame #38: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #39: /usr/bin/python3() [0x6288d0]\n",
            "frame #40: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #41: /usr/bin/python3() [0x6288d0]\n",
            "frame #42: <unknown function> + 0x745f (0x79c037bfa45f in /usr/lib/python3.11/lib-dynload/_asyncio.cpython-311-x86_64-linux-gnu.so)\n",
            "frame #43: /usr/bin/python3() [0x553a8f]\n",
            "frame #44: /usr/bin/python3() [0x4d0cb0]\n",
            "frame #45: /usr/bin/python3() [0x4e95e3]\n",
            "frame #46: /usr/bin/python3() [0x54b2cb]\n",
            "frame #47: _PyEval_EvalFrameDefault + 0x9668 (0x546818 in /usr/bin/python3)\n",
            "frame #48: /usr/bin/python3() [0x613a24]\n",
            "frame #49: PyEval_EvalCode + 0x97 (0x613087 in /usr/bin/python3)\n",
            "frame #50: /usr/bin/python3() [0x62cde3]\n",
            "frame #51: /usr/bin/python3() [0x54b2cb]\n",
            "frame #52: PyObject_Vectorcall + 0x35 (0x54b1b5 in /usr/bin/python3)\n",
            "frame #53: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #54: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #55: /usr/bin/python3() [0x63ec10]\n",
            "frame #56: Py_RunMain + 0x13c (0x63e56c in /usr/bin/python3)\n",
            "frame #57: Py_BytesMain + 0x2d (0x60436d in /usr/bin/python3)\n",
            "frame #58: <unknown function> + 0x29d90 (0x79c038337d90 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "frame #59: __libc_start_main + 0x80 (0x79c038337e40 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "frame #60: _start + 0x25 (0x6041f5 in /usr/bin/python3)\n",
            "\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099134.mp3: Failed to open the input \"/content/drive/MyDrive/DL4AM_datasets/fma_small/099/099134.mp3\" (Invalid argument).\n",
            "Exception raised from get_input_format_context at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_reader/stream_reader.cpp:42 (most recent call first):\n",
            "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x79bfa736c1b6 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\n",
            "frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x79bfa7315a76 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\n",
            "frame #2: <unknown function> + 0x42034 (0x79bfa72a8034 in /usr/local/lib/python3.11/dist-packages/torio/lib/libtorio_ffmpeg4.so)\n",
            "frame #3: torio::io::StreamingMediaDecoder::StreamingMediaDecoder(std::string const&, std::optional<std::string> const&, std::optional<std::map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<std::string const, std::string> > > > const&) + 0x14 (0x79bfa72aaa34 in /usr/local/lib/python3.11/dist-packages/torio/lib/libtorio_ffmpeg4.so)\n",
            "frame #4: <unknown function> + 0x3bfee (0x79be7af58fee in /usr/local/lib/python3.11/dist-packages/torio/lib/_torio_ffmpeg4.so)\n",
            "frame #5: <unknown function> + 0x330c7 (0x79be7af500c7 in /usr/local/lib/python3.11/dist-packages/torio/lib/_torio_ffmpeg4.so)\n",
            "frame #6: /usr/bin/python3() [0x55560b]\n",
            "frame #7: _PyObject_MakeTpCall + 0x27c (0x52f6dc in /usr/bin/python3)\n",
            "frame #8: /usr/bin/python3() [0x5853fd]\n",
            "frame #9: /usr/bin/python3() [0x56e2a9]\n",
            "frame #10: /usr/bin/python3() [0x52fac0]\n",
            "frame #11: <unknown function> + 0xfc6b (0x79bfa7751c6b in /usr/local/lib/python3.11/dist-packages/torchaudio/lib/_torchaudio.so)\n",
            "frame #12: _PyObject_MakeTpCall + 0x27c (0x52f6dc in /usr/bin/python3)\n",
            "frame #13: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #14: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #15: /usr/bin/python3() [0x56df36]\n",
            "frame #16: _PyObject_MakeTpCall + 0x23b (0x52f69b in /usr/bin/python3)\n",
            "frame #17: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #18: /usr/bin/python3() [0x613a24]\n",
            "frame #19: PyEval_EvalCode + 0x97 (0x613087 in /usr/bin/python3)\n",
            "frame #20: /usr/bin/python3() [0x62cde3]\n",
            "frame #21: _PyEval_EvalFrameDefault + 0x3801 (0x5409b1 in /usr/bin/python3)\n",
            "frame #22: /usr/bin/python3() [0x6288d0]\n",
            "frame #23: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #24: /usr/bin/python3() [0x6288d0]\n",
            "frame #25: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #26: /usr/bin/python3() [0x6288d0]\n",
            "frame #27: /usr/bin/python3() [0x62ae9c]\n",
            "frame #28: _PyEval_EvalFrameDefault + 0x3a8a (0x540c3a in /usr/bin/python3)\n",
            "frame #29: /usr/bin/python3() [0x585b17]\n",
            "frame #30: /usr/bin/python3() [0x5852fe]\n",
            "frame #31: PyObject_Call + 0xf4 (0x570784 in /usr/bin/python3)\n",
            "frame #32: _PyEval_EvalFrameDefault + 0x4aab (0x541c5b in /usr/bin/python3)\n",
            "frame #33: /usr/bin/python3() [0x6288d0]\n",
            "frame #34: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #35: /usr/bin/python3() [0x6288d0]\n",
            "frame #36: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #37: /usr/bin/python3() [0x6288d0]\n",
            "frame #38: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #39: /usr/bin/python3() [0x6288d0]\n",
            "frame #40: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #41: /usr/bin/python3() [0x6288d0]\n",
            "frame #42: <unknown function> + 0x745f (0x79c037bfa45f in /usr/lib/python3.11/lib-dynload/_asyncio.cpython-311-x86_64-linux-gnu.so)\n",
            "frame #43: /usr/bin/python3() [0x553a8f]\n",
            "frame #44: /usr/bin/python3() [0x4d0cb0]\n",
            "frame #45: /usr/bin/python3() [0x4e95e3]\n",
            "frame #46: /usr/bin/python3() [0x54b2cb]\n",
            "frame #47: _PyEval_EvalFrameDefault + 0x9668 (0x546818 in /usr/bin/python3)\n",
            "frame #48: /usr/bin/python3() [0x613a24]\n",
            "frame #49: PyEval_EvalCode + 0x97 (0x613087 in /usr/bin/python3)\n",
            "frame #50: /usr/bin/python3() [0x62cde3]\n",
            "frame #51: /usr/bin/python3() [0x54b2cb]\n",
            "frame #52: PyObject_Vectorcall + 0x35 (0x54b1b5 in /usr/bin/python3)\n",
            "frame #53: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #54: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #55: /usr/bin/python3() [0x63ec10]\n",
            "frame #56: Py_RunMain + 0x13c (0x63e56c in /usr/bin/python3)\n",
            "frame #57: Py_BytesMain + 0x2d (0x60436d in /usr/bin/python3)\n",
            "frame #58: <unknown function> + 0x29d90 (0x79c038337d90 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "frame #59: __libc_start_main + 0x80 (0x79c038337e40 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "frame #60: _start + 0x25 (0x6041f5 in /usr/bin/python3)\n",
            "\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133297.mp3: Failed to open the input \"/content/drive/MyDrive/DL4AM_datasets/fma_small/133/133297.mp3\" (Invalid argument).\n",
            "Exception raised from get_input_format_context at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_reader/stream_reader.cpp:42 (most recent call first):\n",
            "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x79bfa736c1b6 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\n",
            "frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x79bfa7315a76 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\n",
            "frame #2: <unknown function> + 0x42034 (0x79bfa72a8034 in /usr/local/lib/python3.11/dist-packages/torio/lib/libtorio_ffmpeg4.so)\n",
            "frame #3: torio::io::StreamingMediaDecoder::StreamingMediaDecoder(std::string const&, std::optional<std::string> const&, std::optional<std::map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<std::string const, std::string> > > > const&) + 0x14 (0x79bfa72aaa34 in /usr/local/lib/python3.11/dist-packages/torio/lib/libtorio_ffmpeg4.so)\n",
            "frame #4: <unknown function> + 0x3bfee (0x79be7af58fee in /usr/local/lib/python3.11/dist-packages/torio/lib/_torio_ffmpeg4.so)\n",
            "frame #5: <unknown function> + 0x330c7 (0x79be7af500c7 in /usr/local/lib/python3.11/dist-packages/torio/lib/_torio_ffmpeg4.so)\n",
            "frame #6: /usr/bin/python3() [0x55560b]\n",
            "frame #7: _PyObject_MakeTpCall + 0x27c (0x52f6dc in /usr/bin/python3)\n",
            "frame #8: /usr/bin/python3() [0x5853fd]\n",
            "frame #9: /usr/bin/python3() [0x56e2a9]\n",
            "frame #10: /usr/bin/python3() [0x52fac0]\n",
            "frame #11: <unknown function> + 0xfc6b (0x79bfa7751c6b in /usr/local/lib/python3.11/dist-packages/torchaudio/lib/_torchaudio.so)\n",
            "frame #12: _PyObject_MakeTpCall + 0x27c (0x52f6dc in /usr/bin/python3)\n",
            "frame #13: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #14: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #15: /usr/bin/python3() [0x56df36]\n",
            "frame #16: _PyObject_MakeTpCall + 0x23b (0x52f69b in /usr/bin/python3)\n",
            "frame #17: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #18: /usr/bin/python3() [0x613a24]\n",
            "frame #19: PyEval_EvalCode + 0x97 (0x613087 in /usr/bin/python3)\n",
            "frame #20: /usr/bin/python3() [0x62cde3]\n",
            "frame #21: _PyEval_EvalFrameDefault + 0x3801 (0x5409b1 in /usr/bin/python3)\n",
            "frame #22: /usr/bin/python3() [0x6288d0]\n",
            "frame #23: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #24: /usr/bin/python3() [0x6288d0]\n",
            "frame #25: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #26: /usr/bin/python3() [0x6288d0]\n",
            "frame #27: /usr/bin/python3() [0x62ae9c]\n",
            "frame #28: _PyEval_EvalFrameDefault + 0x3a8a (0x540c3a in /usr/bin/python3)\n",
            "frame #29: /usr/bin/python3() [0x585b17]\n",
            "frame #30: /usr/bin/python3() [0x5852fe]\n",
            "frame #31: PyObject_Call + 0xf4 (0x570784 in /usr/bin/python3)\n",
            "frame #32: _PyEval_EvalFrameDefault + 0x4aab (0x541c5b in /usr/bin/python3)\n",
            "frame #33: /usr/bin/python3() [0x6288d0]\n",
            "frame #34: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #35: /usr/bin/python3() [0x6288d0]\n",
            "frame #36: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #37: /usr/bin/python3() [0x6288d0]\n",
            "frame #38: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #39: /usr/bin/python3() [0x6288d0]\n",
            "frame #40: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #41: /usr/bin/python3() [0x6288d0]\n",
            "frame #42: <unknown function> + 0x745f (0x79c037bfa45f in /usr/lib/python3.11/lib-dynload/_asyncio.cpython-311-x86_64-linux-gnu.so)\n",
            "frame #43: /usr/bin/python3() [0x553a8f]\n",
            "frame #44: /usr/bin/python3() [0x4d0cb0]\n",
            "frame #45: /usr/bin/python3() [0x4e95e3]\n",
            "frame #46: /usr/bin/python3() [0x54b2cb]\n",
            "frame #47: _PyEval_EvalFrameDefault + 0x9668 (0x546818 in /usr/bin/python3)\n",
            "frame #48: /usr/bin/python3() [0x613a24]\n",
            "frame #49: PyEval_EvalCode + 0x97 (0x613087 in /usr/bin/python3)\n",
            "frame #50: /usr/bin/python3() [0x62cde3]\n",
            "frame #51: /usr/bin/python3() [0x54b2cb]\n",
            "frame #52: PyObject_Vectorcall + 0x35 (0x54b1b5 in /usr/bin/python3)\n",
            "frame #53: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #54: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #55: /usr/bin/python3() [0x63ec10]\n",
            "frame #56: Py_RunMain + 0x13c (0x63e56c in /usr/bin/python3)\n",
            "frame #57: Py_BytesMain + 0x2d (0x60436d in /usr/bin/python3)\n",
            "frame #58: <unknown function> + 0x29d90 (0x79c038337d90 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "frame #59: __libc_start_main + 0x80 (0x79c038337e40 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "frame #60: _start + 0x25 (0x6041f5 in /usr/bin/python3)\n",
            "\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045474.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064008.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032327.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055123.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011839.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029526.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105141.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038879.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098666.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013578.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114036.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036799.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120189.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116755.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105722.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048931.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072064.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114297.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122626.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028072.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049401.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/015/015770.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107476.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126103.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145609.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129362.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093704.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132794.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021167.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111393.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106954.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068898.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3 Models"
      ],
      "metadata": {
        "id": "96pqZKE70Cqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.1 CVAE Source Separator\n",
        "\n",
        "#helper function\n",
        "def compute_conv_output_shape(input_dim, n_frames, layers, kernel_sizes, strides, padding=1):\n",
        "    h, w = input_dim, n_frames\n",
        "    for kernel_size, stride in zip(kernel_sizes, strides):\n",
        "        h = (h + 2*padding - kernel_size) // stride + 1\n",
        "        w = (w + 2*padding - kernel_size) // stride + 1\n",
        "    return h, w\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim, n_frames=860, kernel_sizes=[3, 3, 3], strides=[2, 2, 2]):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=kernel_sizes[0], stride=strides[0], padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=kernel_sizes[1], stride=strides[1], padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=kernel_sizes[2], stride=strides[2], padding=1)\n",
        "        h, w = compute_conv_output_shape(input_dim, n_frames, len(kernel_sizes), kernel_sizes, strides)\n",
        "        self.flatten_size = 128 * h * w\n",
        "\n",
        "        self.fc1 = nn.Linear(self.flatten_size, hidden_dim)\n",
        "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = x.view(x.shape[0], -1)  # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        mu = self.fc_mu(x)\n",
        "        log_var = self.fc_logvar(x)\n",
        "        return mu, log_var\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, output_dim, n_frames=860, kernel_sizes=[3, 3, 3], strides=[2, 2, 2]):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.n_frames = n_frames\n",
        "\n",
        "        h, w = compute_conv_output_shape(output_dim, n_frames, len(kernel_sizes), kernel_sizes, strides)\n",
        "        self.encoded_channels = 128\n",
        "        self.encoded_height = h\n",
        "        self.encoded_width = w\n",
        "        self.flatten_size = self.encoded_channels * self.encoded_height * self.encoded_width\n",
        "\n",
        "        self.fc2 = nn.Linear(hidden_dim, self.flatten_size)\n",
        "\n",
        "        # Transposed convolutions for upsampling\n",
        "        self.deconv1 = nn.ConvTranspose2d(128, 64, kernel_size=kernel_sizes[2], stride=strides[2], padding=1, output_padding=1)\n",
        "        self.deconv2 = nn.ConvTranspose2d(64, 32, kernel_size=kernel_sizes[1], stride=strides[1], padding=1, output_padding=1)\n",
        "        self.deconv3 = nn.ConvTranspose2d(32, 1, kernel_size=kernel_sizes[0], stride=strides[0], padding=1, output_padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = x.view(x.shape[0], self.encoded_channels, self.encoded_height, self.encoded_width)\n",
        "        x = F.relu(self.deconv1(x))\n",
        "        x = F.relu(self.deconv2(x))\n",
        "        x = self.deconv3(x)\n",
        "\n",
        "        # Ensure the output has the exact same dimensions as the input\n",
        "        x = F.interpolate(x, size=(128, self.n_frames), mode='bilinear', align_corners=False)\n",
        "\n",
        "        reconstruction = torch.sigmoid(x)\n",
        "        return reconstruction\n",
        "\n",
        "# CVAE class with initialize_model method\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim, n_frames=860, kernel_sizes=[3, 3, 3], strides=[2, 2, 2]):\n",
        "        super(CVAE, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder_conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=kernel_sizes[0], stride=strides[0], padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=kernel_sizes[1], stride=strides[1], padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=kernel_sizes[2], stride=strides[2], padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Calculate flattened size using the updated compute_conv_output_shape function\n",
        "        h, w = compute_conv_output_shape(input_dim, n_frames, len(kernel_sizes), kernel_sizes, strides)\n",
        "        self.flatten_size = 128 * h * w\n",
        "\n",
        "        self.fc_mu = nn.Linear(self.flatten_size, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(self.flatten_size, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.fc_decoder = nn.Linear(latent_dim, self.flatten_size)\n",
        "\n",
        "        self.decoder_conv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=kernel_sizes[2], stride=strides[2], padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=kernel_sizes[1], stride=strides[1], padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 1, kernel_size=kernel_sizes[0], stride=strides[0], padding=1, output_padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.n_frames = n_frames\n",
        "\n",
        "    def initialize_model(self, device):\n",
        "        self.apply(self._init_weights)\n",
        "        self.to(device)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Conv2d, nn.ConvTranspose2d)):\n",
        "            nn.init.kaiming_normal_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                nn.init.constant_(module.bias, 0)\n",
        "        elif isinstance(module, nn.BatchNorm2d):\n",
        "            nn.init.constant_(module.weight, 1)\n",
        "            nn.init.constant_(module.bias, 0)\n",
        "\n",
        "    def encode(self, x):\n",
        "        print(f\"Encoder input shape: {x.shape}\")\n",
        "        x = self.encoder_conv(x)\n",
        "        print(f\"Encoder output shape: {x.shape}\")\n",
        "        x = x.view(x.size(0), -1)\n",
        "        print(f\"Flattened encoder output shape: {x.shape}\")\n",
        "        mu = self.fc_mu(x)\n",
        "        log_var = self.fc_logvar(x)\n",
        "        print(f\"Mu shape: {mu.shape}\")\n",
        "        print(f\"Log_var shape: {log_var.shape}\")\n",
        "        return mu, log_var\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu + eps * std\n",
        "        return z\n",
        "\n",
        "    def decode(self, z):\n",
        "        print(f\"Decoder input shape: {z.shape}\")\n",
        "        x = self.fc_decoder(z)\n",
        "        print(f\"Decoder FC output shape: {x.shape}\")\n",
        "        conv_layers = [layer for layer in self.encoder_conv if isinstance(layer, nn.Conv2d)]\n",
        "        h, w = compute_conv_output_shape(self.input_dim, self.n_frames, len(conv_layers), [layer.kernel_size[0] for layer in conv_layers], [layer.stride[0] for layer in conv_layers])\n",
        "        x = x.view(x.size(0), 128, h, w)\n",
        "        print(f\"Reshaped decoder output shape: {x.shape}\")\n",
        "        x = self.decoder_conv(x)\n",
        "        print(f\"Decoder conv output shape: {x.shape}\")\n",
        "        if x.shape[2:] != (self.input_dim, self.n_frames):\n",
        "            x = F.interpolate(x, size=(self.input_dim, self.n_frames), mode='bilinear', align_corners=False)\n",
        "        print(f\"Final decoder output shape: {x.shape}\")\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"Model input shape: {x.shape}\")\n",
        "        mu, log_var = self.encode(x)\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        print(f\"Latent vector shape: {z.shape}\")\n",
        "        recon_x = self.decode(z)\n",
        "        print(f\"Model output shape: {recon_x.shape}\")\n",
        "        return recon_x, mu, log_var"
      ],
      "metadata": {
        "id": "jJ2aq55ozujL",
        "cellView": "form"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.2 BiLSTM Loop Candidacy Classifier\n",
        "\n",
        "class BiLSTMLoopClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Bidirectional LSTM-based binary classifier for predicting loop candidacy.\n",
        "    Takes mel spectrograms as input and outputs binary classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim=128, hidden_dim=256, num_layers=2, dropout=0.3):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_dim (int): Number of input features (mel bins)\n",
        "            hidden_dim (int): Hidden dimension of the LSTM\n",
        "            num_layers (int): Number of LSTM layers\n",
        "            dropout (float): Dropout probability (applied between LSTM layers and before final classification)\n",
        "        \"\"\"\n",
        "        super(BiLSTMLoopClassifier, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout_prob = dropout\n",
        "\n",
        "        # Bidirectional LSTM layers\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Feature extraction from the LSTM output\n",
        "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)  # *2 for bidirectional\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Final classification layer\n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the BiLSTM classifier.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape [batch_size, 1, mel_bins, time_frames]\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Probability score for loop candidacy\n",
        "        \"\"\"\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # Reshape from [batch_size, 1, mel_bins, time_frames] to [batch_size, time_frames, mel_bins]\n",
        "        # by removing channel dimension and transposing\n",
        "        x = x.squeeze(1).transpose(1, 2)\n",
        "\n",
        "        # Pass through LSTM\n",
        "        lstm_out, _ = self.lstm(x)  # [batch_size, time_frames, hidden_dim*2]\n",
        "\n",
        "        # Extract features from the last time step\n",
        "        # Alternative: Use attention mechanism over all time steps\n",
        "        last_hidden = lstm_out[:, -1, :]  # [batch_size, hidden_dim*2]\n",
        "\n",
        "        # Feature processing\n",
        "        x = F.relu(self.fc1(last_hidden))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Final classification\n",
        "        logits = self.fc2(x)\n",
        "\n",
        "        # Return sigmoid output for binary classification\n",
        "        # return torch.sigmoid(logits).squeeze(-1)\n",
        "        # Return raw logits for BCEWithLogitsLoss\n",
        "        return logits.squeeze(-1)\n",
        "\n",
        "class LSTMWithAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Variation of the loop classifier that incorporates an attention mechanism\n",
        "    over the LSTM outputs to better focus on parts of the sequence that\n",
        "    are most relevant for loop candidacy prediction.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim=128, hidden_dim=256, num_layers=2, dropout=0.3):\n",
        "        super(LSTMWithAttention, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout_prob = dropout\n",
        "\n",
        "        # BiLSTM layers\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention = nn.Linear(hidden_dim * 2, 1)\n",
        "\n",
        "        # Output layers\n",
        "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reshape from [batch_size, 1, mel_bins, time_frames] to [batch_size, time_frames, mel_bins]\n",
        "        x = x.squeeze(1).transpose(1, 2)\n",
        "\n",
        "        # Pass through BiLSTM\n",
        "        lstm_out, _ = self.lstm(x)  # [batch_size, time_frames, hidden_dim*2]\n",
        "\n",
        "        # Calculate attention weights\n",
        "        attention_weights = F.softmax(self.attention(lstm_out), dim=1)\n",
        "\n",
        "        # Apply attention weights to get context vector\n",
        "        context = torch.sum(attention_weights * lstm_out, dim=1)\n",
        "\n",
        "        # Process context vector\n",
        "        x = F.relu(self.fc1(context))\n",
        "        x = self.dropout(x)\n",
        "        logits = self.fc2(x)\n",
        "\n",
        "        # Return sigmoid output\n",
        "        # return torch.sigmoid(logits).squeeze(-1)\n",
        "        # Return raw logits for BCEWithLogitsLoss\n",
        "        return logits.squeeze(-1)\n",
        "\n",
        "class RhythmicFeatureExtractor(nn.Module):\n",
        "    \"\"\"\n",
        "    Specialized convolutional module for extracting rhythmic features\n",
        "    from spectrograms before passing to BiLSTM. This can help detect\n",
        "    patterns that are important for loop candidacy.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=1, out_channels=16):\n",
        "        super(RhythmicFeatureExtractor, self).__init__()\n",
        "\n",
        "        # Horizontal convolutions to capture time patterns\n",
        "        self.time_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(1, 7), padding=(0, 3)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(1, 2))\n",
        "        )\n",
        "\n",
        "        # Vertical convolutions to capture frequency patterns\n",
        "        self.freq_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(7, 1), padding=(3, 0)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 1))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply time and frequency convolutions\n",
        "        time_features = self.time_conv(x)  # Captures rhythm patterns\n",
        "        freq_features = self.freq_conv(x)  # Captures tonal patterns\n",
        "\n",
        "        # Concatenate features along the channel dimension\n",
        "        return torch.cat([time_features, freq_features], dim=1)\n",
        "\n",
        "class HybridLoopClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    A hybrid model combining convolutional feature extraction with BiLSTM\n",
        "    for loop candidacy classification. This architecture first extracts\n",
        "    rhythmic and tonal patterns from the spectrogram using CNNs and then\n",
        "    analyzes the temporal dependencies using a BiLSTM.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim=128, hidden_dim=256, num_layers=2, dropout=0.3):\n",
        "        super(HybridLoopClassifier, self).__init__()\n",
        "\n",
        "        # Feature extractor\n",
        "        self.feature_extractor = RhythmicFeatureExtractor(in_channels=1, out_channels=16)\n",
        "\n",
        "        # Adapting dimensions for LSTM\n",
        "        self.conv_adapt = nn.Conv2d(32, 1, kernel_size=1)\n",
        "\n",
        "        # BiLSTM for sequence modeling (input dim is halved due to pooling)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_dim // 2,  # Reduced by frequency pooling\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Output layers\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract rhythmic features with CNN\n",
        "        x = self.feature_extractor(x)  # [batch_size, 32, mel_bins/2, time_frames/2]\n",
        "\n",
        "        # Adapt channels for LSTM\n",
        "        x = self.conv_adapt(x)  # [batch_size, 1, mel_bins/2, time_frames/2]\n",
        "\n",
        "        # Reshape for LSTM: [batch_size, time_frames/2, mel_bins/2]\n",
        "        x = x.squeeze(1).transpose(1, 2)\n",
        "\n",
        "        # Process with BiLSTM\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Global pooling across time\n",
        "        x = lstm_out.transpose(1, 2)  # [batch_size, hidden_dim*2, time_frames/2]\n",
        "        x = self.global_pool(x).squeeze(-1)  # [batch_size, hidden_dim*2]\n",
        "\n",
        "        # Final classification\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        logits = self.fc2(x)\n",
        "\n",
        "        # return torch.sigmoid(logits).squeeze(-1)\n",
        "\n",
        "        # Return raw logits for BCEWithLogitsLoss\n",
        "        return logits.squeeze(-1)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2cb4IkoC0Rcv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4 Training Procedures"
      ],
      "metadata": {
        "id": "MdXdwV7n-k1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4.1 CVAE Training Loop\n",
        "\n",
        "def loss_function(recon_x, x, mu, log_var, beta=0.001):\n",
        "    \"\"\"\n",
        "    Compute the CVAE loss function.\n",
        "\n",
        "    Args:\n",
        "        recon_x (torch.Tensor): The reconstructed spectrogram\n",
        "        x (torch.Tensor): The original spectrogram\n",
        "        mu (torch.Tensor): The mean of the latent Gaussian\n",
        "        log_var (torch.Tensor): The log variance of the latent Gaussian\n",
        "        beta (float): The weight for the KL divergence term\n",
        "\n",
        "    Returns:\n",
        "        tuple: (total_loss, reconstruction_loss, kl_divergence)\n",
        "    \"\"\"\n",
        "    print(f\"Reconstructed output shape: {recon_x.shape}\")\n",
        "    print(f\"Input data shape: {x.shape}\")\n",
        "    print(f\"Reconstructed output min/max: {recon_x.min().item()}/{recon_x.max().item()}\")\n",
        "    print(f\"Input data min/max: {x.min().item()}/{x.max().item()}\")\n",
        "\n",
        "    # Initially, we used binary cross-entropy (BCE) loss for reconstruction\n",
        "    # However, BCE loss is typically used for binary classification problems\n",
        "    # where the target values are either 0 or 1. In our case, the input data\n",
        "    # is normalized to have zero mean and unit variance, which means the target\n",
        "    # values can be negative or greater than 1. Therefore, we switched to using\n",
        "    # mean squared error (MSE) loss, which is more suitable for regression tasks\n",
        "    # and reconstruction problems where the aim is to minimize the squared\n",
        "    # difference between the predicted and target values.\n",
        "\n",
        "    # MSE loss for reconstruction\n",
        "    reconstruction_loss = F.mse_loss(recon_x, x, reduction='mean')\n",
        "\n",
        "    # KL divergence: -0.5 * sum(1 + log_var - mu^2 - exp(log_var))\n",
        "    kl_divergence = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "\n",
        "    # Total loss is reconstruction loss plus weighted KL divergence\n",
        "    total_loss = reconstruction_loss + beta * kl_divergence\n",
        "\n",
        "    return total_loss, reconstruction_loss, kl_divergence\n",
        "\n",
        "def train_cvae(model, train_loader, val_loader=None, epochs=100, lr=1e-4,\n",
        "              beta=0.001, device='cuda', checkpoint_dir='./checkpoints',\n",
        "              checkpoint_interval=10, early_stopping_patience=10):\n",
        "\n",
        "    \"\"\"\n",
        "    Train the CVAE model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The CVAE model\n",
        "        train_loader (DataLoader): DataLoader for training data\n",
        "        val_loader (DataLoader, optional): DataLoader for validation data\n",
        "        epochs (int): Number of training epochs\n",
        "        lr (float): Learning rate\n",
        "        beta (float): Weight for the KL divergence term\n",
        "        device (str): Device to train on ('cuda' or 'cpu')\n",
        "        checkpoint_dir (str): Directory to save model checkpoints\n",
        "        checkpoint_interval (int): Save model every n epochs\n",
        "        early_stopping_patience (int): Stop training if validation loss doesn't improve for n epochs\n",
        "\n",
        "    Returns:\n",
        "        nn.Module: The trained model\n",
        "        dict: Training history\n",
        "    \"\"\"\n",
        "\n",
        "    accumulation_steps = 8 #number of steps to accumulate gradients\n",
        "\n",
        "    # Create checkpoint directory if it doesn't exist\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    # Move model to device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Initialize optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "    # Initialize training history\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_recon_loss': [],\n",
        "        'train_kl_loss': [],\n",
        "        'val_loss': [],\n",
        "        'val_recon_loss': [],\n",
        "        'val_kl_loss': []\n",
        "    }\n",
        "\n",
        "    # Early stopping variables\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    best_model_path = os.path.join(checkpoint_dir, 'cvae_best_model.pt')\n",
        "\n",
        "    logger.info(f\"Starting CVAE training for {epochs} epochs\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_recon_loss = 0\n",
        "        train_kl_loss = 0\n",
        "\n",
        "        # Progress bar for training batches\n",
        "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
        "\n",
        "        # Training loop over batches\n",
        "        for batch_idx, sample in enumerate(train_pbar):\n",
        "            # Get spectrogram from sample\n",
        "            data = sample['spectrogram'].to(device).float()\n",
        "\n",
        "            print(f\"Input data shape: {data.shape}\")\n",
        "\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            recon_batch, mu, log_var = model(data)\n",
        "            loss, recon_loss, kl_loss = loss_function(recon_batch, data, mu, log_var, beta)\n",
        "\n",
        "            print(f\"Reconstructed output shape: {recon_batch.shape}\")\n",
        "            print(f\"Input data shape: {data.shape}\")\n",
        "\n",
        "            # Remove the gradient accumulation code\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # Remove the redundant loss calculation and backward pass\n",
        "\n",
        "            # Accumulate batch loss\n",
        "            train_loss += loss.item()\n",
        "            train_recon_loss += recon_loss.item()\n",
        "            train_kl_loss += kl_loss.item()\n",
        "\n",
        "            # Update progress bar\n",
        "            train_pbar.set_postfix({\n",
        "                'loss': loss.item(),\n",
        "                'recon_loss': recon_loss.item(),\n",
        "                'kl_loss': kl_loss.item()\n",
        "            })\n",
        "\n",
        "        # Calculate average training loss for the epoch\n",
        "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "        avg_train_recon_loss = train_recon_loss / len(train_loader.dataset)\n",
        "        avg_train_kl_loss = train_kl_loss / len(train_loader.dataset)\n",
        "\n",
        "        # Store training loss in history\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['train_recon_loss'].append(avg_train_recon_loss)\n",
        "        history['train_kl_loss'].append(avg_train_kl_loss)\n",
        "\n",
        "        # Log training metrics\n",
        "        logger.info(f\"Epoch {epoch+1}/{epochs} - Train Loss: {avg_train_loss:.4f} \"\n",
        "                   f\"(Recon: {avg_train_recon_loss:.4f}, KL: {avg_train_kl_loss:.4f})\")\n",
        "\n",
        "        logger.info(f\"Epoch {epoch+1} completed in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "        # Validation phase\n",
        "        if val_loader is not None:\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            val_recon_loss = 0\n",
        "            val_kl_loss = 0\n",
        "\n",
        "            # No gradient calculation during validation\n",
        "            with torch.no_grad():\n",
        "                # Progress bar for validation batches\n",
        "                val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\")\n",
        "\n",
        "                # Validation loop over batches\n",
        "                for batch_idx, sample in enumerate(val_pbar):\n",
        "                    # Get spectrogram from sample\n",
        "                    data = sample['spectrogram'].to(device).float()\n",
        "\n",
        "                    # Forward pass\n",
        "                    recon_batch, mu, log_var = model(data)\n",
        "\n",
        "                    # Calculate loss\n",
        "                    loss, recon_loss, kl_loss = loss_function(recon_batch, data, mu, log_var, beta)\n",
        "\n",
        "                    # Accumulate batch loss\n",
        "                    val_loss += loss.item()\n",
        "                    val_recon_loss += recon_loss.item()\n",
        "                    val_kl_loss += kl_loss.item()\n",
        "\n",
        "                    # Update progress bar\n",
        "                    val_pbar.set_postfix({\n",
        "                        'val_loss': loss.item(),\n",
        "                        'val_recon_loss': recon_loss.item(),\n",
        "                        'val_kl_loss': kl_loss.item()\n",
        "                    })\n",
        "\n",
        "            # Calculate average validation loss for the epoch\n",
        "            avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "            avg_val_recon_loss = val_recon_loss / len(val_loader.dataset)\n",
        "            avg_val_kl_loss = val_kl_loss / len(val_loader.dataset)\n",
        "\n",
        "            # Store validation loss in history\n",
        "            history['val_loss'].append(avg_val_loss)\n",
        "            history['val_recon_loss'].append(avg_val_recon_loss)\n",
        "            history['val_kl_loss'].append(avg_val_kl_loss)\n",
        "\n",
        "            # Log validation metrics\n",
        "            logger.info(f\"Epoch {epoch+1}/{epochs} - Val Loss: {avg_val_loss:.4f} \"\n",
        "                       f\"(Recon: {avg_val_recon_loss:.4f}, KL: {avg_val_kl_loss:.4f})\")\n",
        "\n",
        "            # Update learning rate based on validation loss\n",
        "            scheduler.step(avg_val_loss)\n",
        "\n",
        "            # Check for early stopping\n",
        "            if avg_val_loss < best_val_loss:\n",
        "                logger.info(f\"Validation loss improved from {best_val_loss:.4f} to {avg_val_loss:.4f}\")\n",
        "                best_val_loss = avg_val_loss\n",
        "                patience_counter = 0\n",
        "\n",
        "                # Save the best model\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'loss': avg_val_loss,\n",
        "                }, best_model_path)\n",
        "                logger.info(f\"Saved best model to {best_model_path}\")\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                logger.info(f\"Validation loss did not improve. Patience: {patience_counter}/{early_stopping_patience}\")\n",
        "\n",
        "                if patience_counter >= early_stopping_patience:\n",
        "                    logger.info(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "                    break\n",
        "\n",
        "        # Save checkpoint periodically\n",
        "        if (epoch + 1) % checkpoint_interval == 0:\n",
        "            checkpoint_path = os.path.join(checkpoint_dir, f'cvae_epoch_{epoch+1}.pt')\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': avg_train_loss,\n",
        "            }, checkpoint_path)\n",
        "            logger.info(f\"Saved checkpoint to {checkpoint_path}\")\n",
        "\n",
        "    # Load the best model if validation was used\n",
        "    if val_loader is not None and os.path.exists(best_model_path):\n",
        "        logger.info(f\"Loading best model from {best_model_path}\")\n",
        "        checkpoint = torch.load(best_model_path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    logger.info(\"CVAE training completed\")\n",
        "\n",
        "    return model, history\n",
        "\n",
        "\n",
        "def visualize_cvae_training(history):\n",
        "    \"\"\"\n",
        "    Visualize the training history of the CVAE model.\n",
        "\n",
        "    Args:\n",
        "        history (dict): Training history containing loss metrics\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Plot total loss\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(history['train_loss'], label='Train')\n",
        "    if 'val_loss' in history and len(history['val_loss']) > 0:\n",
        "        plt.plot(history['val_loss'], label='Validation')\n",
        "    plt.title('Total Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot reconstruction loss\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(history['train_recon_loss'], label='Train')\n",
        "    if 'val_recon_loss' in history and len(history['val_recon_loss']) > 0:\n",
        "        plt.plot(history['val_recon_loss'], label='Validation')\n",
        "    plt.title('Reconstruction Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot KL divergence\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(history['train_kl_loss'], label='Train')\n",
        "    if 'val_kl_loss' in history and len(history['val_kl_loss']) > 0:\n",
        "        plt.plot(history['val_kl_loss'], label='Validation')\n",
        "    plt.title('KL Divergence')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def generate_samples(model, num_samples=5, latent_dim=32, device='cuda'):\n",
        "    \"\"\"\n",
        "    Generate samples from the trained CVAE model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained CVAE model\n",
        "        num_samples (int): Number of samples to generate\n",
        "        latent_dim (int): Dimension of the latent space\n",
        "        device (str): Device to use ('cuda' or 'cpu')\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Generated samples\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Sample from the latent space\n",
        "        z = torch.randn(num_samples, latent_dim).to(device)\n",
        "\n",
        "        # Decode the latent samples\n",
        "        samples = model.decoder(z)\n",
        "\n",
        "    return samples\n",
        "\n",
        "\n",
        "def visualize_cvae_reconstructions(model, dataloader, num_examples=5, device='cuda'):\n",
        "    \"\"\"\n",
        "    Visualize original spectrograms and their reconstructions.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained CVAE model\n",
        "        dataloader (DataLoader): DataLoader containing the data\n",
        "        num_examples (int): Number of examples to visualize\n",
        "        device (str): Device to use ('cuda' or 'cpu')\n",
        "    \"\"\"\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Get examples from dataloader\n",
        "    examples = []\n",
        "    for batch_idx, sample in enumerate(dataloader):\n",
        "        if batch_idx >= num_examples:\n",
        "            break\n",
        "        examples.append(sample['spectrogram'])\n",
        "\n",
        "    # Concatenate examples\n",
        "    examples = torch.cat(examples[:num_examples])\n",
        "    examples = examples.to(device)\n",
        "\n",
        "    # Generate reconstructions\n",
        "    with torch.no_grad():\n",
        "        reconstructions, _, _ = model(examples)\n",
        "\n",
        "    # Move tensors to CPU for visualization\n",
        "    examples = examples.cpu()\n",
        "    reconstructions = reconstructions.cpu()\n",
        "\n",
        "    # Visualize originals and reconstructions\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for i in range(num_examples):\n",
        "        # Original spectrogram\n",
        "        plt.subplot(2, num_examples, i + 1)\n",
        "        plt.imshow(examples[i].squeeze(), cmap='viridis', origin='lower', aspect='auto')\n",
        "        plt.title(f\"Original {i+1}\")\n",
        "        plt.colorbar()\n",
        "\n",
        "        # Reconstructed spectrogram\n",
        "        plt.subplot(2, num_examples, num_examples + i + 1)\n",
        "        plt.imshow(reconstructions[i].squeeze(), cmap='viridis', origin='lower', aspect='auto')\n",
        "        plt.title(f\"Reconstructed {i+1}\")\n",
        "        plt.colorbar()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Enj7FzpJ-lyb",
        "cellView": "form"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4.2 BiLSTM Training Loop\n",
        "\n",
        "def train_bilstm(model, train_loader, val_loader=None, epochs=100, lr=1e-3,\n",
        "                device='cuda', checkpoint_dir='./checkpoints',\n",
        "                checkpoint_interval=10, early_stopping_patience=10):\n",
        "    \"\"\"\n",
        "    Train the BiLSTM model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The BiLSTM model\n",
        "        train_loader (DataLoader): DataLoader for training data\n",
        "        val_loader (DataLoader, optional): DataLoader for validation data\n",
        "        epochs (int): Number of training epochs\n",
        "        lr (float): Learning rate\n",
        "        device (str): Device to train on ('cuda' or 'cpu')\n",
        "        checkpoint_dir (str): Directory to save model checkpoints\n",
        "        checkpoint_interval (int): Save model every n epochs\n",
        "        early_stopping_patience (int): Stop training if validation metric doesn't improve for n epochs\n",
        "\n",
        "    Returns:\n",
        "        nn.Module: The trained model\n",
        "        dict: Training history\n",
        "    \"\"\"\n",
        "    # Create checkpoint directory if it doesn't exist\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    # Move model to device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Initialize optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = ReduceLROnPlateau(optimizer, 'max', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "    # Initialize training history\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'train_precision': [],\n",
        "        'train_recall': [],\n",
        "        'train_f1': [],\n",
        "        'val_loss': [],\n",
        "        'val_acc': [],\n",
        "        'val_precision': [],\n",
        "        'val_recall': [],\n",
        "        'val_f1': []\n",
        "    }\n",
        "\n",
        "    # Initialize early stopping\n",
        "    best_val_f1 = 0.0\n",
        "    patience_counter = 0\n",
        "    best_model_path = os.path.join(checkpoint_dir, 'bilstm_best_model.pt')\n",
        "\n",
        "    logger.info(f\"Starting BiLSTM training for {epochs} epochs\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Training loop\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        y_true_train = []\n",
        "        y_pred_train = []\n",
        "\n",
        "        # Progress bar for training\n",
        "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
        "\n",
        "        for batch_idx, sample in enumerate(train_pbar):\n",
        "            # Get spectrogram and labels from sample\n",
        "            spec = sample['spectrogram'].to(device).float()\n",
        "            labels = sample['class_label'].to(device)\n",
        "\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(spec)\n",
        "            loss = F.binary_cross_entropy_with_logits(logits, labels.float())\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Collect true and predicted labels\n",
        "            y_true_train.extend(labels.tolist())\n",
        "            y_pred_train.extend((torch.sigmoid(logits) > 0.5).long().tolist())\n",
        "\n",
        "            train_loss += loss.item() * len(labels)\n",
        "\n",
        "            # Update progress bar\n",
        "            train_pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        # Calculate training metrics\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = accuracy_score(y_true_train, y_pred_train)\n",
        "        train_precision = precision_score(y_true_train, y_pred_train)\n",
        "        train_recall = recall_score(y_true_train, y_pred_train)\n",
        "        train_f1 = f1_score(y_true_train, y_pred_train)\n",
        "\n",
        "        # Store training metrics\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['train_precision'].append(train_precision)\n",
        "        history['train_recall'].append(train_recall)\n",
        "        history['train_f1'].append(train_f1)\n",
        "\n",
        "        # Log training metrics\n",
        "        logger.info(f\"Epoch {epoch+1}/{epochs} - \"\n",
        "                    f\"Train Loss: {train_loss:.4f}, \"\n",
        "                    f\"Acc: {train_acc:.4f}, \"\n",
        "                    f\"Precision: {train_precision:.4f}, \"\n",
        "                    f\"Recall: {train_recall:.4f}, \"\n",
        "                    f\"F1: {train_f1:.4f}\")\n",
        "\n",
        "        logger.info(f\"Epoch {epoch+1} train completed in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "        # Validation loop\n",
        "        if val_loader is not None:\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            y_true_val = []\n",
        "            y_pred_val = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\")\n",
        "\n",
        "                for batch_idx, sample in enumerate(val_pbar):\n",
        "                    spec = sample['spectrogram'].to(device).float()\n",
        "                    labels = sample['class_label'].to(device)\n",
        "\n",
        "                    logits = model(spec)\n",
        "                    loss = F.binary_cross_entropy_with_logits(logits, labels.float())\n",
        "\n",
        "                    y_true_val.extend(labels.tolist())\n",
        "                    y_pred_val.extend((torch.sigmoid(logits) > 0.5).long().tolist())\n",
        "\n",
        "                    val_loss += loss.item() * len(labels)\n",
        "\n",
        "                    val_pbar.set_postfix({'val_loss': loss.item()})\n",
        "\n",
        "            # Calculate validation metrics\n",
        "            val_loss /= len(val_loader.dataset)\n",
        "            val_acc = accuracy_score(y_true_val, y_pred_val)\n",
        "            val_precision = precision_score(y_true_val, y_pred_val)\n",
        "            val_recall = recall_score(y_true_val, y_pred_val)\n",
        "            val_f1 = f1_score(y_true_val, y_pred_val)\n",
        "\n",
        "            # Store validation metrics\n",
        "            history['val_loss'].append(val_loss)\n",
        "            history['val_acc'].append(val_acc)\n",
        "            history['val_precision'].append(val_precision)\n",
        "            history['val_recall'].append(val_recall)\n",
        "            history['val_f1'].append(val_f1)\n",
        "\n",
        "            # Log validation metrics\n",
        "            logger.info(f\"Epoch {epoch+1}/{epochs} - \"\n",
        "                        f\"Val Loss: {val_loss:.4f}, \"\n",
        "                        f\"Acc: {val_acc:.4f}, \"\n",
        "                        f\"Precision: {val_precision:.4f}, \"\n",
        "                        f\"Recall: {val_recall:.4f}, \"\n",
        "                        f\"F1: {val_f1:.4f}\")\n",
        "\n",
        "            # Update learning rate based on F1\n",
        "            scheduler.step(val_f1)\n",
        "\n",
        "            # Check early stopping\n",
        "            if val_f1 > best_val_f1:\n",
        "                logger.info(f\"F1 improved from {best_val_f1:.4f} to {val_f1:.4f}\")\n",
        "                best_val_f1 = val_f1\n",
        "                patience_counter = 0\n",
        "                torch.save(model.state_dict(), best_model_path)\n",
        "                logger.info(f\"Best model saved to {best_model_path}\")\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                logger.info(f\"F1 did not improve. Patience: {patience_counter}/{early_stopping_patience}\")\n",
        "\n",
        "                if patience_counter == early_stopping_patience:\n",
        "                    logger.info(\"Early stopping triggered\")\n",
        "                    break\n",
        "\n",
        "        # Periodic checkpoints\n",
        "        if (epoch + 1) % checkpoint_interval == 0:\n",
        "            checkpoint_path = os.path.join(checkpoint_dir, f'bilstm_epoch_{epoch+1}.pt')\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "            logger.info(f\"Checkpoint saved to {checkpoint_path}\")\n",
        "\n",
        "    # Load best model\n",
        "    if val_loader is not None:\n",
        "        model.load_state_dict(torch.load(best_model_path))\n",
        "        logger.info(f\"Best model loaded from {best_model_path}\")\n",
        "\n",
        "    logger.info(\"BiLSTM training completed\")\n",
        "\n",
        "    return model, history\n",
        "\n",
        "\n",
        "def visualize_bilstm_training(history):\n",
        "    \"\"\"Visualization of BiLSTM training history.\"\"\"\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(20, 10))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # Plot losses\n",
        "    axes[0].plot(history['train_loss'], label='Train Loss')\n",
        "    if 'val_loss' in history:\n",
        "        axes[0].plot(history['val_loss'], label='Validation Loss')\n",
        "    axes[0].set_title(\"Loss\")\n",
        "    axes[0].set_xlabel(\"Epoch\")\n",
        "    axes[0].legend()\n",
        "\n",
        "    metric_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1\"]\n",
        "\n",
        "    # Plot other metrics\n",
        "    for i, name in enumerate(metric_names, start=1):\n",
        "        train_key = f\"train_{name.lower()}\"\n",
        "        val_key = f\"val_{name.lower()}\"\n",
        "\n",
        "        axes[i].plot(history[train_key], label=f'Train {name}')\n",
        "        if val_key in history:\n",
        "            axes[i].plot(history[val_key], label=f'Validation {name}')\n",
        "        axes[i].set_title(name)\n",
        "        axes[i].set_xlabel(\"Epoch\")\n",
        "        axes[i].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QnKhBQxxu9G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "metadata": {
        "id": "BNMHtOZYxNFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# # Define hyperparameter search space\n",
        "# model = CVAE(\n",
        "#     input_dim=128,  # Number of mel bands\n",
        "#     hidden_dim=128,\n",
        "#     latent_dim=cvae_p['latent_dim'],\n",
        "#     n_frames=860    # Number of frames in your spectrograms\n",
        "# )\n",
        "\n",
        "# print(torch.cuda.is_available())\n",
        "# print(torch.cuda.device_count())\n",
        "# # print(model.state_dict())\n",
        "# for name, param in model.named_parameters():\n",
        "#     print(f\"Parameter: {name}, Device: {param.device}\")"
      ],
      "metadata": {
        "id": "3LtxQ_kkzA_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Extract & Visualize a Sample from FMADataset ===\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# === Load 1 sample from your dataset ===\n",
        "sample = fma_dataset[0]  # Change index if you want a different sample\n",
        "spectrogram = sample['spectrogram']  # Shape: [1, 128, 860] (or similar)\n",
        "\n",
        "# === Convert to numpy for plotting ===\n",
        "spec_np = spectrogram.squeeze().numpy()  # Shape: [128, 860]\n",
        "\n",
        "# === Display the spectrogram ===\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.imshow(spec_np, origin='lower', aspect='auto', cmap='magma')\n",
        "plt.title(\"Sample Log-Mel Spectrogram from FMADataset\")\n",
        "plt.xlabel(\"Time Frames\")\n",
        "plt.ylabel(\"Mel Bands\")\n",
        "plt.colorbar(format=\"%+2.0f dB\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# === Save tensor for upload to Claude ===\n",
        "torch.save(spectrogram, \"dummy_spec.pt\")\n",
        "print(\"Saved dummy_spec.pt for upload.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "J1guuVfgKC9j",
        "outputId": "e3cedeed-f73f-4360-8915-a62833b80fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved dummy_spec.pt for upload.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model size estimate calculations\n",
        "\n",
        "import torch\n",
        "\n",
        "# Calculate the model size\n",
        "total_params = sum(p.numel() for p in cvae_model.parameters())\n",
        "model_size_bytes = total_params * 4\n",
        "model_size_mib = model_size_bytes / (1024 ** 2)\n",
        "\n",
        "# Estimate the activation size (assuming activations are the same size as parameters)\n",
        "activation_size_bytes = model_size_bytes\n",
        "\n",
        "# Estimate the gradient size (same size as parameters)\n",
        "gradient_size_bytes = model_size_bytes\n",
        "\n",
        "# Specify the batch size\n",
        "batch_size = 4  # Replace with your actual batch size\n",
        "\n",
        "# Calculate the total memory required\n",
        "total_memory_bytes = (model_size_bytes + activation_size_bytes + gradient_size_bytes) * batch_size\n",
        "total_memory_mib = total_memory_bytes / (1024 ** 2)\n",
        "\n",
        "print(f\"Estimated model size: {model_size_mib:.2f} MiB\")\n",
        "print(f\"Estimated total memory required: {total_memory_mib:.2f} MiB\")\n",
        "\n",
        "total_params = sum(p.numel() for p in cvae_model.parameters())\n",
        "print(f\"Total number of parameters: {total_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "xz8xr7Y73eeQ",
        "outputId": "8551539d-5d1c-4e34-9578-da7c19427153",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cvae_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-4abb357255f4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Calculate the model size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtotal_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel_size_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_params\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_size_mib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_size_bytes\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cvae_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CUDA Model Loading Device Check\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Sanity check: create and move a simple Conv2d layer\n",
        "try:\n",
        "    test_conv = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1)\n",
        "    test_conv.to(device)\n",
        "    print(\" Conv2d test passed\")\n",
        "except Exception as e:\n",
        "    print(\" Conv2d failed:\", e)\n",
        "\n",
        "# Now try only your encoder\n",
        "try:\n",
        "    encoder = Encoder(input_dim=128, hidden_dim=128, latent_dim=32, n_frames=860)\n",
        "    encoder.to(device)\n",
        "    print(\" Encoder test passed\")\n",
        "except Exception as e:\n",
        "    print(\" Encoder failed:\", e)\n",
        "\n",
        "# Now try decoder\n",
        "try:\n",
        "    decoder = Decoder(latent_dim=32, hidden_dim=128, output_dim=128, n_frames=860)\n",
        "    decoder.to(device)\n",
        "    print(\" Decoder test passed\")\n",
        "except Exception as e:\n",
        "    print(\" Decoder failed:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlzL6HY5OWMi",
        "outputId": "2723f204-1e1a-42af-efe3-8476cb7380fe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            " Conv2d test passed\n",
            " Encoder test passed\n",
            " Decoder test passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "print(torch.cuda.mem_get_info(0))"
      ],
      "metadata": {
        "id": "hXhoWsjnxHC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4.3 Train Models\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = torch.device('cpu')\n",
        "\n",
        "# === Hyperparameter Tuning ===\n",
        "# Define hyperparameter search space\n",
        "cvae_params = {\n",
        "    'latent_dim': [16, 32, 64],     # Dimensionality of the latent space\n",
        "    'lr': [1e-4, 1e-3],             # Learning rates to try\n",
        "    'beta': [0.001, 0.01, 0.1],     # Weighting for KL divergence in the loss\n",
        "}\n",
        "\n",
        "bilstm_params = {\n",
        "    'hidden_dim': [64, 128, 256],\n",
        "    'num_layers': [1, 2, 3],\n",
        "    'dropout': [0.1, 0.3, 0.5],\n",
        "    'lr': [1e-4, 1e-3, 1e-2],\n",
        "}\n",
        "\n",
        "\n",
        "# Perform grid search over hyperparameters\n",
        "best_cvae_params = None\n",
        "best_cvae_val_loss = float('inf')\n",
        "best_bilstm_params = None\n",
        "best_bilstm_val_f1 = 0.0\n",
        "\n",
        "for cvae_p in ParameterGrid(cvae_params):\n",
        "    for bilstm_p in ParameterGrid(bilstm_params):\n",
        "        logger.info(f\"Training with CVAE params: {cvae_p}, BiLSTM params: {bilstm_p}\")\n",
        "\n",
        "        # Create models with current hyperparameters\n",
        "        cvae_model = CVAE(input_dim=128, hidden_dim=128, latent_dim=cvae_p['latent_dim'])\n",
        "        cvae_model = cvae_model.to(device)  # Move model to the device before training\n",
        "\n",
        "        # === Train CVAE ===\n",
        "        try:\n",
        "            trained_cvae, cvae_history = train_cvae(\n",
        "                model=cvae_model,\n",
        "                train_loader=cvae_train_loader,\n",
        "                val_loader=cvae_val_loader,\n",
        "                epochs=100,\n",
        "                lr=cvae_p['lr'],\n",
        "                beta=cvae_p['beta'],\n",
        "                device=device,\n",
        "                checkpoint_dir=\"./checkpoints/cvae\"\n",
        "            )\n",
        "        except RuntimeError as e:\n",
        "            print(f\"CVAE training failed: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            trained_cvae, cvae_history = None, None\n",
        "            continue  # skip to next hyperparameter combo if training fails\n",
        "\n",
        "    #  Only check best after successful training\n",
        "    if cvae_history:\n",
        "        min_val_loss = min(cvae_history['val_loss'])\n",
        "        if min_val_loss < best_cvae_val_loss:\n",
        "            best_cvae_val_loss = min_val_loss\n",
        "            best_cvae_params = cvae_p\n",
        "            logger.info(f\"New best CVAE with val loss {min_val_loss:.4f}\")\n",
        "            torch.save(trained_cvae.state_dict(), \"./checkpoints/cvae/best_cvae.pt\")\n",
        "\n",
        "\n",
        "        # # === Train BiLSTM ===\n",
        "        # trained_bilstm, bilstm_history = train_bilstm(\n",
        "        #     model=bilstm_model,\n",
        "        #     train_loader=bilstm_train_loader,\n",
        "        #     val_loader=bilstm_val_loader,\n",
        "        #     epochs=50,\n",
        "        #     lr=bilstm_p['lr'],\n",
        "        #     device=device,\n",
        "        #     checkpoint_dir=\"./checkpoints/bilstm\"\n",
        "        # )\n",
        "\n",
        "        # # Check if best BiLSTM so far\n",
        "        # max_val_f1 = max(bilstm_history['val_f1'])\n",
        "        # if max_val_f1 > best_bilstm_val_f1:\n",
        "        #     best_bilstm_val_f1 = max_val_f1\n",
        "        #     best_bilstm_params = bilstm_p\n",
        "        #     logger.info(f\"New best BiLSTM with val F1 {max_val_f1:.4f}\")\n",
        "        #     torch.save(trained_bilstm.state_dict(), \"./checkpoints/bilstm/best_bilstm.pt\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# === TEMP: Manually train CVAE with default params to verify it works ===\n",
        "\n",
        "manual_cvae_params = {\n",
        "    'latent_dim': 32,\n",
        "    'lr': 1e-4,\n",
        "    'beta': 0.001,\n",
        "}\n",
        "\n",
        "logger.info(\"Training CVAE manually with default hyperparameters to initialize best_cvae_params.\")\n",
        "cvae_model = CVAE(input_dim=128, hidden_dim=128, latent_dim=manual_cvae_params['latent_dim'])\n",
        "cvae_model = cvae_model.to(device)  # Move model to the device before training\n",
        "trained_cvae, cvae_history = train_cvae(\n",
        "    model=cvae_model,\n",
        "    train_loader=cvae_train_loader,\n",
        "    val_loader=cvae_val_loader,\n",
        "    epochs=100,\n",
        "    lr=manual_cvae_params['lr'],\n",
        "    beta=manual_cvae_params['beta'],\n",
        "    device=device,\n",
        "    checkpoint_dir=\"./checkpoints/cvae\"\n",
        ")\n",
        "\n",
        "# Save these params as \"best\" for now so the rest of the code works\n",
        "best_cvae_params = manual_cvae_params\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # === Train Final Models with Best Hyperparameters ===\n",
        "# if best_cvae_params is None:\n",
        "#     raise RuntimeError(\"No successful CVAE training runs. Cannot proceed with final training.\")\n",
        "# logger.info(f\"Training final CVAE with params: {best_cvae_params}\")\n",
        "\n",
        "\n",
        "# cvae_model = CVAE(input_dim=n_mels, hidden_dim=128, latent_dim=best_cvae_params['latent_dim'])\n",
        "# trained_cvae, cvae_history = train_cvae(\n",
        "#     model=cvae_model,\n",
        "#     train_loader=cvae_train_loader,\n",
        "#     val_loader=cvae_val_loader,\n",
        "#     epochs=100,\n",
        "#     lr=best_cvae_params['lr'],\n",
        "#     beta=best_cvae_params['beta'],\n",
        "#     device=device,\n",
        "#     checkpoint_dir=\"./checkpoints/cvae\"\n",
        "# )\n",
        "\n",
        "# logger.info(f\"Training final BiLSTM with params: {best_bilstm_params}\")\n",
        "# bilstm_model = BiLSTMLoopClassifier(\n",
        "#     input_dim=n_mels, hidden_dim=best_bilstm_params['hidden_dim'],\n",
        "#     num_layers=best_bilstm_params['num_layers'], dropout=best_bilstm_params['dropout']\n",
        "# )\n",
        "# trained_bilstm, bilstm_history = train_bilstm(\n",
        "#     model=bilstm_model,\n",
        "#     train_loader=bilstm_train_loader,\n",
        "#     val_loader=bilstm_val_loader,\n",
        "#     epochs=100,\n",
        "#     lr=best_bilstm_params['lr'],\n",
        "#     device=device,\n",
        "#     checkpoint_dir=\"./checkpoints/bilstm\"\n",
        "# )\n",
        "\n",
        "# === Visualize Training Results ===\n",
        "visualize_cvae_training(cvae_history)\n",
        "visualize_cvae_reconstructions(trained_cvae, cvae_val_loader)\n",
        "\n",
        "# visualize_bilstm_training(bilstm_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T6aTrD4yR0D",
        "outputId": "10c0fe69-5213-4851-fb3b-a8e1ea72644c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "Epoch 1/100 [Train]:   0%|          | 0/1600 [00:00<?, ?it/s]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/025/025378.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075317.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119715.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127159.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049408.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067360.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110779.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113935.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114544.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105915.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038560.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047894.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143290.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/079/079977.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069561.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054442.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036643.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048293.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/031/031889.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118671.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/015/015541.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047100.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003913.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075376.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001891.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.4170682430267334/0.6462549567222595\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115267.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056797.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108843.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110652.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126884.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055113.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087968.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105826.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   0%|          | 1/1600 [00:04<2:01:22,  4.55s/it, loss=0.297, recon_loss=0.297, kl_loss=0.0191]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111376.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.37857601046562195/0.6523900032043457\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123509.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132455.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091933.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/041/041709.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138578.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   0%|          | 2/1600 [00:05<1:08:50,  2.58s/it, loss=0.303, recon_loss=0.295, kl_loss=8.13]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126519.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.40171018242836/0.6435840725898743\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122357.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   0%|          | 3/1600 [00:06<42:23,  1.59s/it, loss=0.295, recon_loss=0.295, kl_loss=0.562]  WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089477.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114295.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010698.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.4060533046722412/0.6304754614830017\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013747.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119898.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091312.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   0%|          | 4/1600 [00:07<38:15,  1.44s/it, loss=0.295, recon_loss=0.294, kl_loss=0.964]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126415.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.41622164845466614/0.6267642974853516\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075412.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   0%|          | 5/1600 [00:07<28:47,  1.08s/it, loss=0.297, recon_loss=0.294, kl_loss=2.99]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145750.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048990.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.38454392552375793/0.6325708031654358\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085598.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006857.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   0%|          | 6/1600 [00:08<26:35,  1.00s/it, loss=0.296, recon_loss=0.293, kl_loss=2.77]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122685.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114232.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 0.41774919629096985/0.6401181817054749\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081565.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129094.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143941.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   0%|          | 7/1600 [00:09<26:27,  1.00it/s, loss=0.294, recon_loss=0.292, kl_loss=1.37]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129404.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.4230833351612091/0.626602828502655\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029739.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111375.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108025.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   0%|          | 8/1600 [00:10<25:07,  1.06it/s, loss=0.292, recon_loss=0.291, kl_loss=0.35]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004510.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136404.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 0.3475963771343231/0.6459693908691406\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/061/061172.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043869.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   1%|          | 9/1600 [00:11<24:15,  1.09it/s, loss=0.289, recon_loss=0.289, kl_loss=0.167]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006360.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.38713186979293823/0.6351685523986816\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114291.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/018/018032.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   1%|          | 10/1600 [00:11<21:08,  1.25it/s, loss=0.289, recon_loss=0.288, kl_loss=0.646]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124180.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.3546527624130249/0.6587368249893188\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004520.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086485.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019438.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091458.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   1%|          | 11/1600 [00:12<22:25,  1.18it/s, loss=0.286, recon_loss=0.285, kl_loss=1.34]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144935.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019708.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.3486737608909607/0.6576566696166992\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066180.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091205.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   1%|          | 12/1600 [00:13<21:59,  1.20it/s, loss=0.288, recon_loss=0.286, kl_loss=1.9]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017631.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038834.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132786.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124480.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114404.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.37453174591064453/0.642334520816803\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:   1%|          | 13/1600 [00:14<23:22,  1.13it/s, loss=0.287, recon_loss=0.285, kl_loss=2.11]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.36531901359558105/0.6458606123924255\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129927.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130265.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   1%|          | 14/1600 [00:15<19:36,  1.35it/s, loss=0.286, recon_loss=0.284, kl_loss=1.9]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.3577587604522705/0.6518967747688293\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006803.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118739.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129880.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   1%|          | 15/1600 [00:15<18:49,  1.40it/s, loss=0.286, recon_loss=0.284, kl_loss=1.53]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126241.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138069.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004786.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069825.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.33522742986679077/0.6655746102333069\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059706.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126104.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072074.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   1%|          | 16/1600 [00:16<22:45,  1.16it/s, loss=0.28, recon_loss=0.279, kl_loss=1.12]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124517.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.3303748071193695/0.646753191947937\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:   1%|          | 17/1600 [00:17<17:56,  1.47it/s, loss=0.284, recon_loss=0.283, kl_loss=0.83]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113268.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.35085949301719666/0.6430301070213318\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026008.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148606.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   1%|          | 18/1600 [00:17<16:56,  1.56it/s, loss=0.283, recon_loss=0.282, kl_loss=0.649]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029747.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.3151957094669342/0.6518833637237549\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060864.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/041/041819.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026906.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013197.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120315.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085836.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   1%|          | 19/1600 [00:18<20:54,  1.26it/s, loss=0.279, recon_loss=0.278, kl_loss=0.571]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010670.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004522.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.32270094752311707/0.6294685006141663\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064989.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026035.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   1%|         | 20/1600 [00:19<21:49,  1.21it/s, loss=0.278, recon_loss=0.277, kl_loss=0.575]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075925.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.3765454590320587/0.6169214844703674\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130933.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146727.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/079/079986.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   1%|         | 21/1600 [00:20<21:48,  1.21it/s, loss=0.282, recon_loss=0.282, kl_loss=0.622]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052120.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.35528621077537537/0.6407677531242371\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123504.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098578.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143060.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   1%|         | 22/1600 [00:21<21:42,  1.21it/s, loss=0.278, recon_loss=0.277, kl_loss=0.675]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144212.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.32101085782051086/0.629011869430542\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/020/020432.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004078.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   1%|         | 23/1600 [00:22<19:55,  1.32it/s, loss=0.278, recon_loss=0.277, kl_loss=0.755]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126521.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010675.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.34478050470352173/0.6258736252784729\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109903.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   2%|         | 24/1600 [00:22<18:47,  1.40it/s, loss=0.275, recon_loss=0.275, kl_loss=0.837]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108422.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038783.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115922.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072926.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.31038153171539307/0.6404420733451843\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064522.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060041.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   2%|         | 25/1600 [00:23<21:25,  1.22it/s, loss=0.273, recon_loss=0.272, kl_loss=0.93]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047201.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.31831827759742737/0.6287546157836914\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071885.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   2%|         | 26/1600 [00:24<18:40,  1.40it/s, loss=0.275, recon_loss=0.273, kl_loss=1.07]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073309.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044781.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105722.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129056.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107181.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.3256808817386627/0.6636002659797668\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145653.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141166.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   2%|         | 27/1600 [00:25<23:18,  1.13it/s, loss=0.273, recon_loss=0.272, kl_loss=1.23]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106955.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.2848636507987976/0.629540741443634\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052035.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   2%|         | 28/1600 [00:25<20:02,  1.31it/s, loss=0.273, recon_loss=0.272, kl_loss=1.45]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014742.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109481.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.3176998794078827/0.641420304775238\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148518.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   2%|         | 29/1600 [00:26<18:55,  1.38it/s, loss=0.271, recon_loss=0.269, kl_loss=1.66]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075417.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141568.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142358.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136709.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.34049758315086365/0.6357755064964294\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115339.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119369.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   2%|         | 30/1600 [00:27<20:32,  1.27it/s, loss=0.273, recon_loss=0.271, kl_loss=1.86]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040230.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088960.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.3045804798603058/0.6242102980613708\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046839.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   2%|         | 31/1600 [00:28<19:02,  1.37it/s, loss=0.272, recon_loss=0.27, kl_loss=2.01]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082928.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/100/100479.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014063.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.32256045937538147/0.6179243326187134\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/147/147021.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   2%|         | 32/1600 [00:28<19:28,  1.34it/s, loss=0.267, recon_loss=0.264, kl_loss=2.1]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071096.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125824.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043699.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 0.3092237412929535/0.6334718465805054\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053301.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000892.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   2%|         | 33/1600 [00:29<20:07,  1.30it/s, loss=0.269, recon_loss=0.267, kl_loss=2.22]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114042.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.294441282749176/0.6359966993331909\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146481.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118735.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123974.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   2%|         | 34/1600 [00:30<20:03,  1.30it/s, loss=0.267, recon_loss=0.265, kl_loss=2.36]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.3088998794555664/0.6199778318405151\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000615.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038777.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   2%|         | 35/1600 [00:30<17:08,  1.52it/s, loss=0.269, recon_loss=0.267, kl_loss=2.46]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105674.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.304450660943985/0.6213913559913635\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/039/039530.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141901.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   2%|         | 36/1600 [00:31<16:08,  1.61it/s, loss=0.265, recon_loss=0.262, kl_loss=2.49]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148231.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/150/150017.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063457.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082892.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049842.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/065/065076.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.2624244689941406/0.6539318561553955\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127192.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/150/150266.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   2%|         | 37/1600 [00:32<21:52,  1.19it/s, loss=0.26, recon_loss=0.257, kl_loss=2.58]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074365.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.2635921239852905/0.6204354763031006\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113280.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:   2%|         | 38/1600 [00:33<19:06,  1.36it/s, loss=0.26, recon_loss=0.257, kl_loss=2.78]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110262.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084484.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134956.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.2802310883998871/0.626418948173523\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/100/100480.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115766.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148168.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   2%|         | 39/1600 [00:34<22:29,  1.16it/s, loss=0.262, recon_loss=0.259, kl_loss=3.17]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128484.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.2518094480037689/0.6278277635574341\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142571.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   2%|         | 40/1600 [00:34<19:33,  1.33it/s, loss=0.259, recon_loss=0.255, kl_loss=3.58]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126522.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.2626746892929077/0.6278245449066162\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094038.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081193.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115271.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   3%|         | 41/1600 [00:35<20:10,  1.29it/s, loss=0.257, recon_loss=0.253, kl_loss=3.87]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133835.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141303.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.22764825820922852/0.6321661472320557\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004836.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036616.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   3%|         | 42/1600 [00:36<19:19,  1.34it/s, loss=0.253, recon_loss=0.249, kl_loss=4.06]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054151.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.2653410732746124/0.6413320899009705\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121665.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   3%|         | 43/1600 [00:36<17:37,  1.47it/s, loss=0.253, recon_loss=0.248, kl_loss=4.29]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064855.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113934.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127648.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.22863799333572388/0.6326754093170166\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090617.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108026.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072072.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   3%|         | 44/1600 [00:37<19:25,  1.34it/s, loss=0.253, recon_loss=0.249, kl_loss=4.5]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.2421630620956421/0.6467960476875305\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145476.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133572.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/079/079985.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111382.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029350.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   3%|         | 45/1600 [00:38<20:57,  1.24it/s, loss=0.255, recon_loss=0.25, kl_loss=4.68]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.2325935661792755/0.6204337477684021\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123968.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045513.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   3%|         | 46/1600 [00:39<18:06,  1.43it/s, loss=0.252, recon_loss=0.247, kl_loss=4.75]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129694.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.22856305539608002/0.620421826839447\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/034/034511.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107389.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144424.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059930.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   3%|         | 47/1600 [00:40<20:00,  1.29it/s, loss=0.248, recon_loss=0.243, kl_loss=4.83]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040851.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.2540341019630432/0.6198158860206604\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110765.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114265.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   3%|         | 48/1600 [00:40<18:28,  1.40it/s, loss=0.254, recon_loss=0.249, kl_loss=4.75]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084198.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/061/061734.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092881.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.17517730593681335/0.6292991638183594\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055713.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014315.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125159.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   3%|         | 49/1600 [00:41<20:50,  1.24it/s, loss=0.243, recon_loss=0.239, kl_loss=4.46]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144809.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038890.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.2679920494556427/0.6053575277328491\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006856.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048454.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   3%|         | 50/1600 [00:42<20:38,  1.25it/s, loss=0.253, recon_loss=0.248, kl_loss=4.41]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096657.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024363.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.1889542043209076/0.6403306126594543\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072607.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011919.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   3%|         | 51/1600 [00:43<20:37,  1.25it/s, loss=0.243, recon_loss=0.239, kl_loss=4.28]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/031/031165.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.18038249015808105/0.6537789702415466\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107020.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   3%|         | 52/1600 [00:43<17:47,  1.45it/s, loss=0.235, recon_loss=0.231, kl_loss=4.57]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141167.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.22044678032398224/0.6315810084342957\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080519.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033461.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067673.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136469.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   3%|         | 53/1600 [00:44<19:18,  1.34it/s, loss=0.242, recon_loss=0.236, kl_loss=5.24]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122624.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131940.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/152/152570.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109355.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.19623376429080963/0.6336178183555603\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051661.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   3%|         | 54/1600 [00:45<20:27,  1.26it/s, loss=0.241, recon_loss=0.235, kl_loss=6.23]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120161.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/065/065073.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135054.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.14858096837997437/0.6455511450767517\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045388.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:   3%|         | 55/1600 [00:46<20:19,  1.27it/s, loss=0.24, recon_loss=0.233, kl_loss=7.14]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133833.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.13735216856002808/0.6449988484382629\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124891.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134797.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   4%|         | 56/1600 [00:46<18:44,  1.37it/s, loss=0.232, recon_loss=0.224, kl_loss=7.69]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011772.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/058/058221.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.18249092996120453/0.6197014451026917\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128476.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   4%|         | 57/1600 [00:47<18:05,  1.42it/s, loss=0.238, recon_loss=0.23, kl_loss=8.12]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007711.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072047.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030519.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011638.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011334.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.11883628368377686/0.6600996255874634\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092574.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013749.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   4%|         | 59/1600 [00:48<15:53,  1.62it/s, loss=0.229, recon_loss=0.221, kl_loss=8.37]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111223.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.16944412887096405/0.6567928791046143\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017491.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127494.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.1748349964618683/0.6403646469116211\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120188.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   4%|         | 60/1600 [00:49<16:26,  1.56it/s, loss=0.234, recon_loss=0.225, kl_loss=8.42]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110204.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.1718285232782364/0.6340963840484619\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086799.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068909.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072612.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121655.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   4%|         | 61/1600 [00:50<17:36,  1.46it/s, loss=0.23, recon_loss=0.222, kl_loss=7.95]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038435.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122398.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097589.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145259.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067600.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.1709601730108261/0.6283741593360901\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109543.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138068.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   4%|         | 62/1600 [00:51<21:29,  1.19it/s, loss=0.232, recon_loss=0.225, kl_loss=7.48]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.14282727241516113/0.6450538635253906\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098297.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144543.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   4%|         | 63/1600 [00:51<18:15,  1.40it/s, loss=0.227, recon_loss=0.219, kl_loss=7.18]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036257.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.1558314710855484/0.6248138546943665\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121453.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014737.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   4%|         | 64/1600 [00:52<17:29,  1.46it/s, loss=0.228, recon_loss=0.221, kl_loss=7.46]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145552.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032336.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.13912151753902435/0.6437718272209167\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120160.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086081.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054667.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135229.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   4%|         | 65/1600 [00:53<20:20,  1.26it/s, loss=0.226, recon_loss=0.218, kl_loss=7.54]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.08481691777706146/0.6675336360931396\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131904.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139687.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070208.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121987.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   4%|         | 66/1600 [00:54<21:11,  1.21it/s, loss=0.215, recon_loss=0.207, kl_loss=7.61]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.1088765412569046/0.6603867411613464\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115764.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114200.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094093.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043857.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   4%|         | 67/1600 [00:55<22:21,  1.14it/s, loss=0.211, recon_loss=0.202, kl_loss=8.48]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038361.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.1424013376235962/0.616625189781189\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108016.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/147/147059.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134384.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   4%|         | 68/1600 [00:56<21:53,  1.17it/s, loss=0.239, recon_loss=0.229, kl_loss=10.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.10482490062713623/0.6593678593635559\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091623.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086679.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127936.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   4%|         | 69/1600 [00:57<21:11,  1.20it/s, loss=0.217, recon_loss=0.207, kl_loss=10.3]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053675.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.10029114037752151/0.6418827772140503\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075389.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014539.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   4%|         | 70/1600 [00:57<19:22,  1.32it/s, loss=0.215, recon_loss=0.205, kl_loss=9.76]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110261.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.09783167392015457/0.6637047529220581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006442.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073792.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028483.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134359.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084291.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/147/147815.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   4%|         | 71/1600 [00:58<22:53,  1.11it/s, loss=0.21, recon_loss=0.201, kl_loss=9.41]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052039.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.09063465148210526/0.6695899367332458\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045521.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   4%|         | 72/1600 [00:59<19:11,  1.33it/s, loss=0.206, recon_loss=0.197, kl_loss=9.05]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126670.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.08151592314243317/0.6489953398704529\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080680.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126221.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   5%|         | 73/1600 [00:59<18:24,  1.38it/s, loss=0.202, recon_loss=0.192, kl_loss=9.16]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072785.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013735.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006762.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.10297544300556183/0.636174201965332\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111151.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/005/005191.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122504.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   5%|         | 74/1600 [01:00<20:42,  1.23it/s, loss=0.218, recon_loss=0.208, kl_loss=9.52]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086763.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.08518372476100922/0.6415442228317261\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123760.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114409.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056468.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   5%|         | 75/1600 [01:01<20:56,  1.21it/s, loss=0.206, recon_loss=0.197, kl_loss=9.77]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053160.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.08672825247049332/0.643764853477478\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011333.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   5%|         | 76/1600 [01:02<17:55,  1.42it/s, loss=0.208, recon_loss=0.197, kl_loss=10.6]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082920.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060477.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090824.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.07572691142559052/0.6490938067436218\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085838.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010381.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011682.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145728.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   5%|         | 77/1600 [01:03<22:24,  1.13it/s, loss=0.204, recon_loss=0.193, kl_loss=11.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.06010066345334053/0.6674138307571411\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004108.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086724.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   5%|         | 78/1600 [01:03<18:59,  1.34it/s, loss=0.197, recon_loss=0.185, kl_loss=11.5]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133273.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.09077171981334686/0.639003574848175\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123442.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074376.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097960.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   5%|         | 79/1600 [01:04<19:53,  1.27it/s, loss=0.208, recon_loss=0.196, kl_loss=12.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126507.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143214.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010577.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.07659658789634705/0.642279863357544\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127541.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116878.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   5%|         | 80/1600 [01:05<20:03,  1.26it/s, loss=0.2, recon_loss=0.188, kl_loss=12.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0441591702401638/0.6552262902259827\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070660.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014319.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   5%|         | 81/1600 [01:06<17:15,  1.47it/s, loss=0.19, recon_loss=0.178, kl_loss=11.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.02843921259045601/0.6793875694274902\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056796.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125618.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073466.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   5%|         | 82/1600 [01:06<15:45,  1.60it/s, loss=0.184, recon_loss=0.173, kl_loss=11]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125681.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149370.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.058959003537893295/0.6675119996070862\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148131.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097404.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026655.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080002.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   5%|         | 83/1600 [01:07<18:08,  1.39it/s, loss=0.183, recon_loss=0.172, kl_loss=11.2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072200.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054031.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003708.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.034113481640815735/0.6575345396995544\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149082.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145748.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   5%|         | 84/1600 [01:08<19:37,  1.29it/s, loss=0.195, recon_loss=0.183, kl_loss=12.2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063804.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.02057446353137493/0.7106321454048157\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106562.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   5%|         | 85/1600 [01:08<17:13,  1.47it/s, loss=0.172, recon_loss=0.16, kl_loss=12.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.06973721832036972/0.6515575647354126\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009307.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069828.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092556.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117252.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148187.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   5%|         | 86/1600 [01:09<18:50,  1.34it/s, loss=0.188, recon_loss=0.177, kl_loss=11.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.06766971200704575/0.6644760370254517\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080695.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121323.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040984.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148120.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148587.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   5%|         | 87/1600 [01:10<20:08,  1.25it/s, loss=0.19, recon_loss=0.179, kl_loss=11.2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052650.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.04670296981930733/0.6515867114067078\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093917.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093710.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 88/1600 [01:11<18:19,  1.37it/s, loss=0.181, recon_loss=0.17, kl_loss=11]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.04679282754659653/0.6562166810035706\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146482.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097540.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090616.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 89/1600 [01:11<18:01,  1.40it/s, loss=0.187, recon_loss=0.176, kl_loss=11.8]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082780.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071503.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012514.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004234.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054568.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 89/1600 [01:12<18:01,  1.40it/s, loss=0.186, recon_loss=0.174, kl_loss=12]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.051309533417224884/0.6479413509368896\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/100 [Train]:   6%|         | 90/1600 [01:12<19:43,  1.28it/s, loss=0.186, recon_loss=0.174, kl_loss=12]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083511.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070426.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.043157413601875305/0.64567631483078\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064861.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071884.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 91/1600 [01:13<18:45,  1.34it/s, loss=0.182, recon_loss=0.17, kl_loss=12]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144477.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.040530577301979065/0.6784725785255432\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144179.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/034/034003.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117631.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126747.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 92/1600 [01:14<19:20,  1.30it/s, loss=0.189, recon_loss=0.177, kl_loss=11.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014663.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113028.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.044285714626312256/0.6594937443733215\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064520.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011784.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013708.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 93/1600 [01:15<21:11,  1.19it/s, loss=0.181, recon_loss=0.17, kl_loss=10.5]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091349.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007526.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.05448656901717186/0.6381424069404602\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014603.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 94/1600 [01:16<19:41,  1.27it/s, loss=0.176, recon_loss=0.165, kl_loss=10.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036998.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.024158108979463577/0.6630364060401917\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096399.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127189.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048463.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 95/1600 [01:16<20:03,  1.25it/s, loss=0.164, recon_loss=0.153, kl_loss=10.8]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110736.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.04619460552930832/0.6407967209815979\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105670.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072477.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056802.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 96/1600 [01:17<19:16,  1.30it/s, loss=0.173, recon_loss=0.161, kl_loss=12.7]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054481.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.021665500476956367/0.6848989129066467\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089485.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 97/1600 [01:17<16:29,  1.52it/s, loss=0.171, recon_loss=0.156, kl_loss=14.7]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030043.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131986.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113512.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134034.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.03689718618988991/0.6549543142318726\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141618.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130927.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 98/1600 [01:18<18:45,  1.33it/s, loss=0.163, recon_loss=0.147, kl_loss=15.6]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056696.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.035042647272348404/0.6468397974967957\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136706.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 99/1600 [01:19<16:23,  1.53it/s, loss=0.174, recon_loss=0.159, kl_loss=15]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117610.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.03317658603191376/0.6582736968994141\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121998.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057440.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 100/1600 [01:19<16:01,  1.56it/s, loss=0.168, recon_loss=0.155, kl_loss=12.9]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006366.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145477.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.032510507851839066/0.6468430757522583\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086415.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026020.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030740.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 101/1600 [01:20<16:36,  1.50it/s, loss=0.162, recon_loss=0.151, kl_loss=11.1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.043262045830488205/0.6492404937744141\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/025/025063.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121256.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075749.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 102/1600 [01:21<15:27,  1.61it/s, loss=0.162, recon_loss=0.152, kl_loss=9.89]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033477.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109349.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086040.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.038603998720645905/0.6417094469070435\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115263.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091318.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114938.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122804.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059687.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 103/1600 [01:22<20:43,  1.20it/s, loss=0.176, recon_loss=0.165, kl_loss=10.3]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133561.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.04034659266471863/0.6540248990058899\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108957.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   6%|         | 104/1600 [01:22<17:51,  1.40it/s, loss=0.161, recon_loss=0.15, kl_loss=11.2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134792.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.024443553760647774/0.6751669049263\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109450.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001427.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   7%|         | 105/1600 [01:23<17:00,  1.47it/s, loss=0.156, recon_loss=0.144, kl_loss=12.9]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144937.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066405.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091163.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097544.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   7%|         | 106/1600 [01:24<17:48,  1.40it/s, loss=0.163, recon_loss=0.148, kl_loss=14.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.02419627271592617/0.6529558300971985\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145003.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063065.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.020523149520158768/0.6586863994598389\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035535.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114201.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   7%|         | 107/1600 [01:25<18:16,  1.36it/s, loss=0.156, recon_loss=0.14, kl_loss=15.2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124916.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056795.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.023940956220030785/0.643018364906311\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/100/100976.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066649.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107256.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059562.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047074.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   7%|         | 108/1600 [01:26<22:45,  1.09it/s, loss=0.154, recon_loss=0.139, kl_loss=15.1]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003895.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.01671137474477291/0.684831976890564\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098547.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   7%|         | 109/1600 [01:26<19:26,  1.28it/s, loss=0.155, recon_loss=0.14, kl_loss=14.2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109925.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.04290156066417694/0.6316012740135193\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085831.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066187.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109497.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   7%|         | 110/1600 [01:27<19:20,  1.28it/s, loss=0.164, recon_loss=0.152, kl_loss=12.6]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111392.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062189.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.028353814035654068/0.638840913772583\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141295.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046717.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109978.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   7%|         | 111/1600 [01:28<21:01,  1.18it/s, loss=0.154, recon_loss=0.143, kl_loss=11.3]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010673.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.019123418256640434/0.6478351950645447\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084091.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064008.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059727.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   7%|         | 112/1600 [01:29<20:50,  1.19it/s, loss=0.143, recon_loss=0.132, kl_loss=10.9]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122627.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.04591992497444153/0.6244548559188843\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:   7%|         | 113/1600 [01:29<16:29,  1.50it/s, loss=0.158, recon_loss=0.146, kl_loss=11.8]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001685.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.014747987501323223/0.6577746868133545\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104065.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114237.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132963.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084202.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093727.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   7%|         | 114/1600 [01:30<19:27,  1.27it/s, loss=0.142, recon_loss=0.128, kl_loss=13.9]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054482.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140565.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149776.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107955.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.033674273639917374/0.6255558133125305\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133447.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   7%|         | 115/1600 [01:31<20:19,  1.22it/s, loss=0.155, recon_loss=0.139, kl_loss=15.7]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120326.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118674.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/031/031356.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.018810704350471497/0.6690276265144348\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121316.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   7%|         | 116/1600 [01:32<20:31,  1.20it/s, loss=0.141, recon_loss=0.125, kl_loss=16.6]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111225.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115769.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.011014170944690704/0.6464853286743164\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017611.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   7%|         | 117/1600 [01:33<18:49,  1.31it/s, loss=0.147, recon_loss=0.131, kl_loss=15.9]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133431.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.007948718965053558/0.6710667014122009\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014391.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137500.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043962.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129184.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   7%|         | 118/1600 [01:34<19:55,  1.24it/s, loss=0.137, recon_loss=0.123, kl_loss=14.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/152/152103.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.015263446606695652/0.6366801261901855\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059688.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124870.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/058/058213.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   7%|         | 119/1600 [01:34<19:44,  1.25it/s, loss=0.145, recon_loss=0.133, kl_loss=12.1]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064625.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121346.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.029346704483032227/0.618577241897583\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060533.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   8%|         | 120/1600 [01:35<18:02,  1.37it/s, loss=0.147, recon_loss=0.137, kl_loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.032709311693906784/0.6250913739204407\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056248.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122079.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   8%|         | 121/1600 [01:35<16:07,  1.53it/s, loss=0.152, recon_loss=0.141, kl_loss=10.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006603.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.009130225516855717/0.6722606420516968\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066075.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030521.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071157.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092872.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006779.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053578.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046736.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   8%|         | 122/1600 [01:37<20:48,  1.18it/s, loss=0.119, recon_loss=0.108, kl_loss=11.5]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013537.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012737.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.020272620022296906/0.6289396286010742\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:   8%|         | 123/1600 [01:37<18:15,  1.35it/s, loss=0.13, recon_loss=0.117, kl_loss=12.9]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.025243250653147697/0.6190094351768494\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035204.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118507.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   8%|         | 124/1600 [01:38<15:43,  1.56it/s, loss=0.142, recon_loss=0.128, kl_loss=14.1]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090618.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.014729239977896214/0.6422791481018066\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131792.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120150.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084290.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042141.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092565.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081576.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   8%|         | 125/1600 [01:39<19:21,  1.27it/s, loss=0.128, recon_loss=0.113, kl_loss=15.5]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059449.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110264.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028571.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145606.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0064472416415810585/0.6468645334243774\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/152/152568.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   8%|         | 127/1600 [01:40<16:06,  1.52it/s, loss=0.133, recon_loss=0.119, kl_loss=14.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.016914403066039085/0.6274923086166382\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096169.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130134.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059708.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006674.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.011020278558135033/0.6423121094703674\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038817.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017344.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026013.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/016/016745.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   8%|         | 128/1600 [01:42<22:30,  1.09it/s, loss=0.127, recon_loss=0.114, kl_loss=12.9]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143215.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.012945634312927723/0.6306400895118713\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/031/031043.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   8%|         | 129/1600 [01:42<19:41,  1.25it/s, loss=0.129, recon_loss=0.118, kl_loss=11.7]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035007.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084155.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072604.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.01652943715453148/0.6290032863616943\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119993.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133788.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   8%|         | 130/1600 [01:43<20:42,  1.18it/s, loss=0.123, recon_loss=0.112, kl_loss=11]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139990.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.028963251039385796/0.6052367091178894\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048491.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096678.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010375.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   8%|         | 131/1600 [01:44<20:46,  1.18it/s, loss=0.14, recon_loss=0.13, kl_loss=10.8]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.020417844876646996/0.6211770176887512\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062450.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132964.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   8%|         | 132/1600 [01:44<17:35,  1.39it/s, loss=0.139, recon_loss=0.127, kl_loss=11.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.017423812299966812/0.6287115812301636\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115294.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036143.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122630.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   8%|         | 133/1600 [01:45<16:37,  1.47it/s, loss=0.125, recon_loss=0.113, kl_loss=12.6]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137424.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.008516895584762096/0.640274167060852\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110772.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057344.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081938.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036965.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073169.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   8%|         | 134/1600 [01:46<18:35,  1.31it/s, loss=0.114, recon_loss=0.101, kl_loss=13.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038450.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144470.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141296.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.014364940114319324/0.6276898980140686\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114242.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099501.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   8%|         | 135/1600 [01:47<19:43,  1.24it/s, loss=0.124, recon_loss=0.11, kl_loss=13.5]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062164.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.010109199211001396/0.6169331669807434\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033070.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118059.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026754.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   8%|         | 136/1600 [01:48<19:40,  1.24it/s, loss=0.118, recon_loss=0.104, kl_loss=13.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.006838642060756683/0.6413949131965637\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032337.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/079/079610.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   9%|         | 137/1600 [01:48<16:53,  1.44it/s, loss=0.124, recon_loss=0.111, kl_loss=12.9]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000621.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114413.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.024744609370827675/0.6028144955635071\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108343.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116876.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   9%|         | 138/1600 [01:49<16:38,  1.46it/s, loss=0.143, recon_loss=0.13, kl_loss=12.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111015.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091092.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064332.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0033801558893173933/0.634494423866272\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130692.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062533.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109687.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   9%|         | 139/1600 [01:50<18:25,  1.32it/s, loss=0.124, recon_loss=0.113, kl_loss=11.7]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.01123239565640688/0.6259971261024475\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108880.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052945.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088858.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119187.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   9%|         | 140/1600 [01:50<18:57,  1.28it/s, loss=0.111, recon_loss=0.0995, kl_loss=11.7]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/041/041095.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.004411797039210796/0.6320952773094177\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120105.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012058.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123976.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   9%|         | 141/1600 [01:51<18:29,  1.32it/s, loss=0.117, recon_loss=0.105, kl_loss=11.9]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.009194844402372837/0.6178275346755981\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038908.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140576.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   9%|         | 142/1600 [01:52<15:46,  1.54it/s, loss=0.119, recon_loss=0.107, kl_loss=12.3]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124474.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.010177372954785824/0.6280532479286194\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098574.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132794.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125377.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108022.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134824.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   9%|         | 143/1600 [01:52<18:05,  1.34it/s, loss=0.118, recon_loss=0.106, kl_loss=12.2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069002.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.010779841803014278/0.6131535768508911\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111416.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120466.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/018/018038.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   9%|         | 144/1600 [01:53<18:34,  1.31it/s, loss=0.125, recon_loss=0.113, kl_loss=12.5]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110106.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.012011351995170116/0.6030799150466919\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073123.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085788.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063255.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   9%|         | 146/1600 [01:54<14:20,  1.69it/s, loss=0.0998, recon_loss=0.0873, kl_loss=12.5]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118920.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0033648156095296144/0.6239210367202759\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044780.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048444.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098205.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017884.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113164.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063043.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0062681641429662704/0.6323562860488892\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013571.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088429.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   9%|         | 147/1600 [01:56<20:20,  1.19it/s, loss=0.113, recon_loss=0.101, kl_loss=12.2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026174.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.006027934607118368/0.6201551556587219\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012052.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   9%|         | 149/1600 [01:56<13:15,  1.83it/s, loss=0.109, recon_loss=0.0962, kl_loss=12.5]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0037188283167779446/0.6134526133537292\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121659.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013191.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.011889318935573101/0.6047661900520325\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092889.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114410.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144469.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148186.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126319.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094803.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087971.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024370.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:   9%|         | 150/1600 [01:58<21:05,  1.15it/s, loss=0.112, recon_loss=0.1, kl_loss=12]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027547.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055807.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 0.011153833009302616/0.5903794169425964\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:   9%|         | 151/1600 [01:58<18:10,  1.33it/s, loss=0.109, recon_loss=0.0972, kl_loss=11.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134939.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.005890962667763233/0.6378769874572754\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001193.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113558.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126183.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048492.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010376.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  10%|         | 153/1600 [02:00<15:40,  1.54it/s, loss=0.107, recon_loss=0.0967, kl_loss=10.7]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.007146944757550955/0.6035653352737427\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081600.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038818.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0026420948561280966/0.6044833660125732\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126585.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119118.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  10%|         | 154/1600 [02:00<16:13,  1.49it/s, loss=0.106, recon_loss=0.0955, kl_loss=10.9]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.005117909051477909/0.5880508422851562\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135224.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089212.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142360.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130347.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/078/078849.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137935.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091317.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  10%|         | 155/1600 [02:02<20:28,  1.18it/s, loss=0.107, recon_loss=0.0961, kl_loss=11.3]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094426.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117626.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024423.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057661.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00963672250509262/0.580405056476593\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  10%|         | 156/1600 [02:02<20:19,  1.18it/s, loss=0.113, recon_loss=0.101, kl_loss=11.7]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108305.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00324427243322134/0.6009953022003174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029355.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043621.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111149.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  10%|         | 157/1600 [02:03<19:48,  1.21it/s, loss=0.0967, recon_loss=0.0843, kl_loss=12.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059707.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0034151561558246613/0.6003190875053406\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138017.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108427.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138581.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  10%|         | 158/1600 [02:04<19:28,  1.23it/s, loss=0.0888, recon_loss=0.0768, kl_loss=12]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081189.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097962.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 0.007469664793461561/0.6034334301948547\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004799.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  10%|         | 159/1600 [02:05<17:22,  1.38it/s, loss=0.0994, recon_loss=0.0883, kl_loss=11]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0038914356846362352/0.5903459787368774\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055290.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097894.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  10%|         | 160/1600 [02:05<14:52,  1.61it/s, loss=0.0988, recon_loss=0.0884, kl_loss=10.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.003089270321652293/0.5821390151977539\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137990.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131791.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033426.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055830.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097697.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126899.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  10%|         | 161/1600 [02:06<17:00,  1.41it/s, loss=0.107, recon_loss=0.0968, kl_loss=10.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.004438010510057211/0.5906670093536377\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071242.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024512.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000694.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138212.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  10%|         | 162/1600 [02:07<17:05,  1.40it/s, loss=0.0956, recon_loss=0.0848, kl_loss=10.8]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133441.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052126.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021058.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042023.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0042076800018548965/0.585368275642395\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092562.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069727.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  10%|         | 163/1600 [02:08<19:35,  1.22it/s, loss=0.096, recon_loss=0.0847, kl_loss=11.3]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075442.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0038300477899610996/0.6007944941520691\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040234.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  10%|         | 164/1600 [02:08<17:13,  1.39it/s, loss=0.0926, recon_loss=0.0811, kl_loss=11.6]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004849.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.002043212531134486/0.6023901104927063\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146685.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/022/022473.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144587.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  10%|         | 165/1600 [02:09<18:03,  1.32it/s, loss=0.0914, recon_loss=0.0799, kl_loss=11.5]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080000.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142530.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071692.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112196.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0014685355126857758/0.5963634848594666\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083789.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  10%|         | 166/1600 [02:10<18:18,  1.30it/s, loss=0.0817, recon_loss=0.0705, kl_loss=11.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0012571377446874976/0.5910147428512573\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069824.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128504.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  10%|         | 167/1600 [02:10<15:49,  1.51it/s, loss=0.0923, recon_loss=0.0819, kl_loss=10.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011262.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125614.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130693.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  10%|         | 168/1600 [02:11<14:45,  1.62it/s, loss=0.09, recon_loss=0.0801, kl_loss=9.97]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114405.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00278977258130908/0.5824793577194214\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136275.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133770.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105827.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098666.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0023893998004496098/0.568046510219574\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127865.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105914.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  11%|         | 169/1600 [02:12<17:49,  1.34it/s, loss=0.0862, recon_loss=0.0767, kl_loss=9.47]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0017028853762894869/0.573600709438324\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027164.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/037/037538.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  11%|         | 170/1600 [02:12<15:47,  1.51it/s, loss=0.0873, recon_loss=0.0779, kl_loss=9.35]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044793.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00718484865501523/0.5941003561019897\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093919.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136091.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  11%|         | 171/1600 [02:13<15:10,  1.57it/s, loss=0.0956, recon_loss=0.0861, kl_loss=9.42]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124409.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137593.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107029.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001644.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127281.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043844.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0029049022123217583/0.5718753933906555\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  11%|         | 172/1600 [02:14<18:00,  1.32it/s, loss=0.0809, recon_loss=0.071, kl_loss=9.92]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108155.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098580.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075440.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108298.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/102/102092.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0008222888573072851/0.5713499188423157\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  11%|         | 173/1600 [02:15<19:27,  1.22it/s, loss=0.0811, recon_loss=0.0708, kl_loss=10.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129055.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129054.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0015526205534115434/0.5852287411689758\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111228.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071250.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  11%|         | 174/1600 [02:16<18:56,  1.25it/s, loss=0.0826, recon_loss=0.0723, kl_loss=10.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007483.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0015601289924234152/0.5874536037445068\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108808.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052041.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/037/037368.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  11%|         | 175/1600 [02:16<19:05,  1.24it/s, loss=0.0814, recon_loss=0.0711, kl_loss=10.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0005511549534276128/0.5694721341133118\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126295.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006459.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075378.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  11%|         | 176/1600 [02:17<18:18,  1.30it/s, loss=0.076, recon_loss=0.0659, kl_loss=10.2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141181.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105451.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0027259320486336946/0.5658745169639587\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029128.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/002/002099.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024420.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  11%|         | 177/1600 [02:18<19:10,  1.24it/s, loss=0.0843, recon_loss=0.0745, kl_loss=9.76]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/020/020667.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036272.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081082.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0034415225964039564/0.5558097958564758\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068898.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  11%|         | 178/1600 [02:19<19:01,  1.25it/s, loss=0.0924, recon_loss=0.0828, kl_loss=9.54]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117945.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0014521314296871424/0.5727728605270386\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088863.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030198.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  11%|         | 179/1600 [02:19<17:14,  1.37it/s, loss=0.0877, recon_loss=0.0777, kl_loss=10]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045149.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.004030564799904823/0.567241370677948\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125299.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024515.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118569.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001196.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125004.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  11%|        | 180/1600 [02:20<20:18,  1.17it/s, loss=0.0901, recon_loss=0.0793, kl_loss=10.7]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068844.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00260735466144979/0.5666643381118774\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126882.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  11%|        | 182/1600 [02:21<12:51,  1.84it/s, loss=0.0763, recon_loss=0.0647, kl_loss=11.6]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0013820889871567488/0.5603974461555481\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064331.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142552.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0019247183809056878/0.5618714094161987\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127532.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131292.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126320.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009721.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/151/151404.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107957.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113282.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  11%|        | 183/1600 [02:22<18:43,  1.26it/s, loss=0.0829, recon_loss=0.0716, kl_loss=11.3]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121590.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0008964559528976679/0.5688243508338928\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011839.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/025/025603.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  12%|        | 184/1600 [02:23<16:38,  1.42it/s, loss=0.0738, recon_loss=0.0633, kl_loss=10.5]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129920.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054666.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 0.000963936559855938/0.550782322883606\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125186.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114401.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115944.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066394.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  12%|        | 186/1600 [02:24<14:26,  1.63it/s, loss=0.0699, recon_loss=0.0614, kl_loss=8.49]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0026788711547851562/0.5624145269393921\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024899.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131764.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088868.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055289.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  12%|        | 187/1600 [02:25<15:10,  1.55it/s, loss=0.0799, recon_loss=0.0721, kl_loss=7.87]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0033562066964805126/0.5531612634658813\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137715.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107101.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098628.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053724.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140262.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123832.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0036141350865364075/0.5537128448486328\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139491.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124752.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  12%|        | 188/1600 [02:26<19:51,  1.19it/s, loss=0.0778, recon_loss=0.0698, kl_loss=7.99]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024698.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.002174957189708948/0.5568181276321411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024431.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  12%|        | 189/1600 [02:27<17:15,  1.36it/s, loss=0.0787, recon_loss=0.0702, kl_loss=8.53]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011771.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0016271345084533095/0.5487737655639648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000141.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074388.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  12%|        | 190/1600 [02:27<15:53,  1.48it/s, loss=0.0802, recon_loss=0.0703, kl_loss=9.88]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/016/016819.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.001508978079073131/0.5450961589813232\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120207.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141876.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068407.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  12%|        | 191/1600 [02:28<16:39,  1.41it/s, loss=0.0827, recon_loss=0.0713, kl_loss=11.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063472.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113698.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139537.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0027961975429207087/0.5569777488708496\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  12%|        | 192/1600 [02:28<15:36,  1.50it/s, loss=0.0769, recon_loss=0.0642, kl_loss=12.7]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110102.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074960.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128811.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001702.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0008980902493931353/0.5716838836669922\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138320.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096400.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000667.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143095.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  12%|        | 193/1600 [02:30<20:06,  1.17it/s, loss=0.0807, recon_loss=0.0676, kl_loss=13.1]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026022.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096935.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 0.0009034449467435479/0.5437111258506775\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098300.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  12%|        | 194/1600 [02:30<18:57,  1.24it/s, loss=0.0839, recon_loss=0.0709, kl_loss=13]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0002890390169341117/0.555698037147522\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091081.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074959.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  12%|        | 195/1600 [02:31<16:33,  1.41it/s, loss=0.0701, recon_loss=0.0582, kl_loss=11.9]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088892.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116733.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021998.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129398.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0010647712042555213/0.5517542958259583\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119063.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029037.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062001.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  12%|        | 196/1600 [02:32<19:45,  1.18it/s, loss=0.0729, recon_loss=0.0626, kl_loss=10.3]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108472.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0005266841617412865/0.5504514575004578\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/041/041812.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  12%|        | 197/1600 [02:33<17:07,  1.37it/s, loss=0.0683, recon_loss=0.0594, kl_loss=8.9]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035199.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.003052434651181102/0.5444795489311218\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/023/023372.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057938.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  12%|        | 198/1600 [02:33<16:38,  1.40it/s, loss=0.0747, recon_loss=0.067, kl_loss=7.74]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133439.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054479.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107248.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0006849515484645963/0.553646445274353\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112065.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094039.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/061/061011.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  12%|        | 199/1600 [02:34<18:57,  1.23it/s, loss=0.0617, recon_loss=0.0543, kl_loss=7.39]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138019.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145041.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0006675414042547345/0.5429505705833435\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130016.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056693.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  12%|        | 200/1600 [02:35<18:46,  1.24it/s, loss=0.0707, recon_loss=0.0633, kl_loss=7.37]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.000820332788862288/0.5406638383865356\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071690.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114402.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  13%|        | 201/1600 [02:35<15:55,  1.46it/s, loss=0.0736, recon_loss=0.0655, kl_loss=8.11]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053154.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106502.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113294.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0009556352742947638/0.5603794455528259\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087098.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019184.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124394.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056520.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  13%|        | 202/1600 [02:37<19:10,  1.22it/s, loss=0.0775, recon_loss=0.0678, kl_loss=9.7]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.000539870816282928/0.540314257144928\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072134.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114292.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  13%|        | 203/1600 [02:37<16:04,  1.45it/s, loss=0.0691, recon_loss=0.058, kl_loss=11.2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125818.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.004189372528344393/0.539512574672699\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114375.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  13%|        | 204/1600 [02:37<14:31,  1.60it/s, loss=0.075, recon_loss=0.0626, kl_loss=12.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048044.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130136.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145258.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051267.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 0.0026736820582300425/0.5457342863082886\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060753.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012067.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042659.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010672.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  13%|        | 205/1600 [02:39<19:13,  1.21it/s, loss=0.0752, recon_loss=0.062, kl_loss=13.2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132779.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0010052048601210117/0.5382530093193054\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088486.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  13%|        | 206/1600 [02:39<16:31,  1.41it/s, loss=0.0692, recon_loss=0.0563, kl_loss=12.9]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125820.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00092459557345137/0.5312376022338867\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116869.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  13%|        | 207/1600 [02:40<14:27,  1.61it/s, loss=0.0693, recon_loss=0.0576, kl_loss=11.7]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067829.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042374.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131923.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030895.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00018166138033848256/0.5389623641967773\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054464.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056028.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118061.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  13%|        | 208/1600 [02:41<17:27,  1.33it/s, loss=0.0587, recon_loss=0.0485, kl_loss=10.3]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060871.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00021625732188113034/0.5318626165390015\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134790.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094036.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  13%|        | 209/1600 [02:41<16:01,  1.45it/s, loss=0.0557, recon_loss=0.0469, kl_loss=8.81]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125182.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0009641166543588042/0.5416732430458069\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/150/150063.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130930.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116465.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009511.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074391.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  13%|        | 210/1600 [02:42<19:03,  1.22it/s, loss=0.0655, recon_loss=0.0582, kl_loss=7.36]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085428.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0021937175188213587/0.534553050994873\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075748.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  13%|        | 211/1600 [02:43<16:18,  1.42it/s, loss=0.0687, recon_loss=0.0618, kl_loss=6.83]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.001823966857045889/0.5373329520225525\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094099.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055402.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  13%|        | 212/1600 [02:43<14:36,  1.58it/s, loss=0.0696, recon_loss=0.0622, kl_loss=7.48]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059443.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0004511544539127499/0.5381636619567871\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038967.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118951.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127623.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075932.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011775.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  13%|        | 213/1600 [02:44<17:14,  1.34it/s, loss=0.0524, recon_loss=0.0438, kl_loss=8.68]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0010315875988453627/0.5308209657669067\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121450.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085792.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122201.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127358.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  13%|        | 214/1600 [02:45<17:18,  1.33it/s, loss=0.0647, recon_loss=0.0552, kl_loss=9.49]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038828.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  13%|        | 215/1600 [02:45<14:27,  1.60it/s, loss=0.0581, recon_loss=0.0476, kl_loss=10.5]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0005382278468459845/0.5323269367218018\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136331.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055119.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092131.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0005381873925216496/0.5241655707359314\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/101/101119.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052000.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064866.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011264.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080518.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117159.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  14%|        | 216/1600 [02:47<20:30,  1.12it/s, loss=0.0557, recon_loss=0.0447, kl_loss=11]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148210.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00042616346036083996/0.5231077075004578\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012526.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  14%|        | 217/1600 [02:47<17:28,  1.32it/s, loss=0.0541, recon_loss=0.0434, kl_loss=10.8]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093940.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00027791500906459987/0.530929684638977\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145432.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085950.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055285.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057697.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  14%|        | 218/1600 [02:48<18:58,  1.21it/s, loss=0.0611, recon_loss=0.0511, kl_loss=9.99]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148216.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0004599741369020194/0.5308961868286133\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096946.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063224.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  14%|        | 219/1600 [02:49<17:09,  1.34it/s, loss=0.066, recon_loss=0.0566, kl_loss=9.38]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00019987330597359687/0.5243633389472961\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113284.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/102/102195.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  14%|        | 220/1600 [02:49<15:12,  1.51it/s, loss=0.0524, recon_loss=0.0434, kl_loss=9.03]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108079.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0005548342014662921/0.5265002846717834\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/061/061010.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001673.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001642.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087190.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069221.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  14%|        | 221/1600 [02:50<16:51,  1.36it/s, loss=0.0545, recon_loss=0.0461, kl_loss=8.41]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127331.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113032.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0003968938544858247/0.5372575521469116\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126300.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047707.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120468.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  14%|        | 222/1600 [02:51<18:17,  1.26it/s, loss=0.0496, recon_loss=0.0416, kl_loss=7.97]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128711.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.944804823026061e-05/0.5274308323860168\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  14%|        | 223/1600 [02:51<14:48,  1.55it/s, loss=0.0533, recon_loss=0.0456, kl_loss=7.71]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045387.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134447.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135369.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00035014943568967283/0.5250937342643738\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084136.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  14%|        | 224/1600 [02:52<15:12,  1.51it/s, loss=0.0539, recon_loss=0.0462, kl_loss=7.7]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049029.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072786.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143309.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0004639100225176662/0.5297859907150269\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/095/095564.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073776.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054664.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120304.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117614.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  14%|        | 225/1600 [02:53<19:48,  1.16it/s, loss=0.0542, recon_loss=0.0462, kl_loss=7.97]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073519.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00012172254355391487/0.5222919583320618\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121867.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  14%|        | 226/1600 [02:54<16:57,  1.35it/s, loss=0.0553, recon_loss=0.0469, kl_loss=8.45]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066650.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.934698906959966e-05/0.5197928547859192\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097407.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086788.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097587.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135372.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009962.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  14%|        | 228/1600 [02:55<14:39,  1.56it/s, loss=0.0521, recon_loss=0.0426, kl_loss=9.52]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00021628508693538606/0.5176634192466736\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115813.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060145.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00012547986989375204/0.5258244872093201\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060535.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071509.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  14%|        | 229/1600 [02:56<14:30,  1.57it/s, loss=0.0496, recon_loss=0.0401, kl_loss=9.44]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011777.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111937.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013362.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 0.00037227122811600566/0.520335853099823\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107021.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063064.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066690.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126017.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113027.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  14%|        | 230/1600 [02:57<19:01,  1.20it/s, loss=0.056, recon_loss=0.0469, kl_loss=9.15]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019442.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0006128332461230457/0.5319142937660217\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138317.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  14%|        | 231/1600 [02:58<16:29,  1.38it/s, loss=0.0538, recon_loss=0.0451, kl_loss=8.67]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/022/022348.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.801759784342721e-05/0.5274673104286194\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145551.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139536.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134930.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075433.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111389.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  14%|        | 232/1600 [02:59<19:21,  1.18it/s, loss=0.048, recon_loss=0.0394, kl_loss=8.61]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122365.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0002763363881967962/0.5204206109046936\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145780.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  15%|        | 233/1600 [02:59<16:40,  1.37it/s, loss=0.0513, recon_loss=0.0432, kl_loss=8.15]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133967.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0006635684403590858/0.5296787619590759\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092129.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141875.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070402.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075381.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033203.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  15%|        | 234/1600 [03:00<20:15,  1.12it/s, loss=0.0571, recon_loss=0.049, kl_loss=8.1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00012655447062570602/0.5305240750312805\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108460.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/031/031392.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  15%|        | 235/1600 [03:01<17:11,  1.32it/s, loss=0.0536, recon_loss=0.0447, kl_loss=8.84]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121595.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145260.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 0.0002030878240475431/0.5228340029716492\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108968.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  15%|        | 236/1600 [03:02<16:25,  1.38it/s, loss=0.0505, recon_loss=0.0411, kl_loss=9.35]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038782.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129972.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.553166243364103e-05/0.5266532301902771\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075746.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093518.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  15%|        | 237/1600 [03:02<16:13,  1.40it/s, loss=0.041, recon_loss=0.0311, kl_loss=9.83]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131797.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148078.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133560.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0001446067908545956/0.521209180355072\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073124.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004097.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132568.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  15%|        | 238/1600 [03:03<18:41,  1.21it/s, loss=0.0414, recon_loss=0.0318, kl_loss=9.55]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064630.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.713912004372105e-05/0.5170210599899292\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108884.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073769.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029243.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  15%|        | 239/1600 [03:04<19:09,  1.18it/s, loss=0.0482, recon_loss=0.0394, kl_loss=8.8]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118618.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00016861403128132224/0.5234899520874023\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125722.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/023/023172.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  15%|        | 240/1600 [03:05<17:14,  1.31it/s, loss=0.0526, recon_loss=0.0445, kl_loss=8.07]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053937.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00022614930639974773/0.52376788854599\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006406.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051998.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087097.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142362.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  15%|        | 241/1600 [03:06<18:33,  1.22it/s, loss=0.0558, recon_loss=0.0479, kl_loss=7.89]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121317.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00042714070877991617/0.5154298543930054\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131919.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/150/150287.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110447.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  15%|        | 242/1600 [03:07<18:32,  1.22it/s, loss=0.0485, recon_loss=0.0402, kl_loss=8.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.802887320285663e-05/0.5192106366157532\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127204.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026600.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  15%|        | 243/1600 [03:07<16:06,  1.40it/s, loss=0.0431, recon_loss=0.0341, kl_loss=9.03]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.0339286240632646e-05/0.5123386979103088\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126401.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075975.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126455.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  15%|        | 244/1600 [03:08<15:19,  1.48it/s, loss=0.0489, recon_loss=0.0395, kl_loss=9.38]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/022/022481.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011937.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010699.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052500.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064841.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/078/078847.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.000187783021829091/0.5198714733123779\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128500.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070301.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  15%|        | 245/1600 [03:09<19:48,  1.14it/s, loss=0.0468, recon_loss=0.037, kl_loss=9.81]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057936.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/078/078984.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00010551441664574668/0.5106966495513916\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109356.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  15%|        | 246/1600 [03:10<18:06,  1.25it/s, loss=0.0417, recon_loss=0.0317, kl_loss=10.1]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007391.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.41569053591229e-05/0.5120835900306702\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129675.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094630.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000716.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  15%|        | 247/1600 [03:10<17:53,  1.26it/s, loss=0.0411, recon_loss=0.0312, kl_loss=9.82]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.385195153299719e-05/0.5149519443511963\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060548.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131900.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  16%|        | 248/1600 [03:11<15:09,  1.49it/s, loss=0.0398, recon_loss=0.0305, kl_loss=9.28]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.3126540074590594e-05/0.5167216658592224\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131942.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056465.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124918.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  16%|        | 249/1600 [03:11<13:54,  1.62it/s, loss=0.0367, recon_loss=0.0284, kl_loss=8.39]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069198.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.000285295769572258/0.5055971145629883\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137176.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104066.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080751.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127275.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043022.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  16%|        | 250/1600 [03:12<15:48,  1.42it/s, loss=0.0423, recon_loss=0.0348, kl_loss=7.46]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5693934983573854e-05/0.5182284712791443\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004233.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121273.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125154.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040659.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014572.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  16%|        | 251/1600 [03:13<16:48,  1.34it/s, loss=0.0327, recon_loss=0.0256, kl_loss=7.03]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067598.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.424829502473585e-06/0.5135340094566345\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144472.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123439.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  16%|        | 252/1600 [03:14<16:01,  1.40it/s, loss=0.0344, recon_loss=0.0279, kl_loss=6.5]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119725.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083717.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0005290094413794577/0.5176355242729187\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130950.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  16%|        | 253/1600 [03:14<15:32,  1.44it/s, loss=0.0552, recon_loss=0.049, kl_loss=6.15]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069764.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036261.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00010071357246488333/0.5158925652503967\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121739.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048457.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  16%|        | 254/1600 [03:15<15:05,  1.49it/s, loss=0.0363, recon_loss=0.0297, kl_loss=6.67]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.000192659193999134/0.5099163055419922\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017644.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026322.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131979.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098026.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017588.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143106.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017608.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  16%|        | 255/1600 [03:16<18:47,  1.19it/s, loss=0.0416, recon_loss=0.0341, kl_loss=7.48]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109203.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0160145140835084e-05/0.5038512945175171\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064005.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  16%|        | 256/1600 [03:17<16:21,  1.37it/s, loss=0.0323, recon_loss=0.0235, kl_loss=8.74]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.393612344865687e-06/0.503869354724884\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108415.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126215.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  16%|        | 257/1600 [03:17<15:10,  1.48it/s, loss=0.0322, recon_loss=0.0227, kl_loss=9.47]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063874.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057627.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084054.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056034.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00018599331087898463/0.5124383568763733\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112789.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080758.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/005/005521.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092125.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052642.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  16%|        | 259/1600 [03:19<15:50,  1.41it/s, loss=0.0393, recon_loss=0.0295, kl_loss=9.81]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.986739703686908e-05/0.5130720138549805\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.184597855783068e-06/0.5117106437683105\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021672.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137723.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004099.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124877.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  16%|        | 260/1600 [03:20<16:05,  1.39it/s, loss=0.0366, recon_loss=0.0265, kl_loss=10.1]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/095/095506.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/025/025795.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116872.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00012213297304697335/0.501937985420227\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110764.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114400.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098681.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118195.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  16%|        | 261/1600 [03:21<19:10,  1.16it/s, loss=0.0379, recon_loss=0.028, kl_loss=9.84]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010695.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.0001710704673314467/0.5096403956413269\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010374.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  16%|        | 262/1600 [03:21<16:48,  1.33it/s, loss=0.0433, recon_loss=0.034, kl_loss=9.31]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125827.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.79808685061289e-05/0.505971372127533\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072131.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014538.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009152.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026658.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093364.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  16%|        | 263/1600 [03:22<19:27,  1.15it/s, loss=0.0365, recon_loss=0.027, kl_loss=9.48]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126666.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.800529369385913e-05/0.5101473331451416\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048439.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  16%|        | 264/1600 [03:23<17:01,  1.31it/s, loss=0.0429, recon_loss=0.0338, kl_loss=9.12]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087643.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.8379021134460345e-05/0.4997764825820923\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/065/065755.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084195.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  17%|        | 265/1600 [03:24<15:37,  1.42it/s, loss=0.0314, recon_loss=0.0226, kl_loss=8.84]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.817498923628591e-05/0.5039384365081787\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114297.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120319.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087237.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  17%|        | 266/1600 [03:24<13:54,  1.60it/s, loss=0.0254, recon_loss=0.0171, kl_loss=8.27]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.643643089570105e-05/0.5085040330886841\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114937.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127203.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148532.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  17%|        | 267/1600 [03:24<12:46,  1.74it/s, loss=0.0408, recon_loss=0.0337, kl_loss=7.08]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.6099000024260022e-05/0.5126734972000122\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036983.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043623.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105718.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115724.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  17%|        | 268/1600 [03:25<12:25,  1.79it/s, loss=0.0465, recon_loss=0.0398, kl_loss=6.69]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127912.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1326738786010537e-05/0.5120327472686768\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/147/147956.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114041.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120772.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097959.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098625.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003724.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134936.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  17%|        | 269/1600 [03:26<15:21,  1.44it/s, loss=0.0322, recon_loss=0.0249, kl_loss=7.36]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/016/016880.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.080763442791067e-05/0.5038750171661377\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148444.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118505.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012485.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  17%|        | 270/1600 [03:27<16:24,  1.35it/s, loss=0.0302, recon_loss=0.0222, kl_loss=8.02]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115811.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.964196002925746e-05/0.5136842131614685\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074908.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014317.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127867.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  17%|        | 271/1600 [03:28<16:18,  1.36it/s, loss=0.0348, recon_loss=0.0262, kl_loss=8.58]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.889337520173285e-05/0.5106831192970276\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083507.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133027.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  17%|        | 272/1600 [03:28<14:20,  1.54it/s, loss=0.0277, recon_loss=0.0187, kl_loss=9.08]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064857.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134796.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131552.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 0.00011329077824484557/0.5083920955657959\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068821.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/079/079975.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134943.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122168.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  17%|        | 273/1600 [03:29<18:04,  1.22it/s, loss=0.0361, recon_loss=0.0271, kl_loss=8.98]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054719.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.830599836073816e-05/0.49531325697898865\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107579.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  17%|        | 274/1600 [03:30<15:46,  1.40it/s, loss=0.0349, recon_loss=0.0257, kl_loss=9.26]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118955.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.563354534388054e-06/0.5140033960342407\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004093.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027552.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  17%|        | 275/1600 [03:30<15:05,  1.46it/s, loss=0.0431, recon_loss=0.0335, kl_loss=9.63]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/152/152253.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032438.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042851.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.621796609986632e-07/0.48060718178749084\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107597.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085422.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  17%|        | 276/1600 [03:31<15:57,  1.38it/s, loss=0.0233, recon_loss=0.0132, kl_loss=10.1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.990040957229212e-05/0.49542346596717834\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006783.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064858.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138579.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  17%|        | 277/1600 [03:32<14:17,  1.54it/s, loss=0.0279, recon_loss=0.0186, kl_loss=9.24]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122651.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.699807055250858e-06/0.512310266494751\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067233.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068543.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113969.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126230.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  17%|        | 278/1600 [03:32<15:58,  1.38it/s, loss=0.0346, recon_loss=0.0266, kl_loss=8.05]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135364.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024915.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144741.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.8690930776065215e-05/0.5166655778884888\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028692.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067358.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  17%|        | 279/1600 [03:33<17:13,  1.28it/s, loss=0.0347, recon_loss=0.0272, kl_loss=7.51]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145027.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.263577349978732e-06/0.5016115307807922\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104284.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028480.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006609.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  18%|        | 280/1600 [03:34<17:43,  1.24it/s, loss=0.0315, recon_loss=0.024, kl_loss=7.46]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048046.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.896971859125188e-06/0.5073978304862976\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145744.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  18%|        | 281/1600 [03:35<15:27,  1.42it/s, loss=0.026, recon_loss=0.0182, kl_loss=7.81]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124483.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040122.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6608419173280708e-06/0.4899846017360687\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073763.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068841.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  18%|        | 282/1600 [03:35<15:34,  1.41it/s, loss=0.0251, recon_loss=0.0172, kl_loss=7.88]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.151887545347563e-06/0.507685661315918\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084201.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086119.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143218.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  18%|        | 283/1600 [03:36<14:35,  1.51it/s, loss=0.0225, recon_loss=0.0148, kl_loss=7.66]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040237.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028266.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119719.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024963.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108037.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.830491757777054e-05/0.5079886317253113\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000704.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096936.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127191.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  18%|        | 284/1600 [03:37<20:13,  1.08it/s, loss=0.0275, recon_loss=0.0205, kl_loss=7]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.049249582749326e-06/0.508219301700592\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075763.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106568.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  18%|        | 285/1600 [03:38<17:09,  1.28it/s, loss=0.0303, recon_loss=0.0238, kl_loss=6.54]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144945.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.321364445379004e-05/0.5084345936775208\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/041/041054.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069763.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055480.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074370.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  18%|        | 286/1600 [03:39<18:11,  1.20it/s, loss=0.0365, recon_loss=0.0298, kl_loss=6.66]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.818625257030362e-06/0.5147322416305542\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075434.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087322.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  18%|        | 287/1600 [03:39<15:19,  1.43it/s, loss=0.0291, recon_loss=0.0217, kl_loss=7.46]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.796972229494713e-06/0.5001552104949951\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051991.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038887.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094449.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  18%|        | 288/1600 [03:40<14:14,  1.54it/s, loss=0.0268, recon_loss=0.0183, kl_loss=8.48]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130130.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.3967547804204514e-06/0.5008956789970398\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123938.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110691.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125237.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137724.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107049.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064918.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  18%|        | 289/1600 [03:41<17:20,  1.26it/s, loss=0.028, recon_loss=0.0187, kl_loss=9.33]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029526.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5541196262347512e-05/0.501011848449707\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126227.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057180.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131913.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  18%|        | 290/1600 [03:42<17:41,  1.23it/s, loss=0.0265, recon_loss=0.0166, kl_loss=9.91]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.3436956528021256e-06/0.5013147592544556\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126607.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111872.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  18%|        | 291/1600 [03:42<15:05,  1.45it/s, loss=0.0271, recon_loss=0.0171, kl_loss=9.95]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/078/078852.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.184467227081768e-06/0.5119744539260864\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108498.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114387.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149075.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  18%|        | 292/1600 [03:43<15:20,  1.42it/s, loss=0.0385, recon_loss=0.0288, kl_loss=9.65]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082929.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126587.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129039.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012986.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0337060959718656e-06/0.4949208199977875\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087099.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056010.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006342.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  18%|        | 293/1600 [03:44<18:33,  1.17it/s, loss=0.022, recon_loss=0.0115, kl_loss=10.5]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051919.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098550.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.832867486788018e-07/0.48457977175712585\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  18%|        | 294/1600 [03:45<15:58,  1.36it/s, loss=0.0221, recon_loss=0.0119, kl_loss=10.2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137895.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4673045143354102e-06/0.5005030632019043\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116586.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137419.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069181.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  18%|        | 295/1600 [03:45<16:31,  1.32it/s, loss=0.0265, recon_loss=0.0174, kl_loss=9.13]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109971.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116706.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128845.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063251.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3274918273964431e-05/0.5020737051963806\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114539.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  18%|        | 296/1600 [03:46<17:57,  1.21it/s, loss=0.0225, recon_loss=0.0145, kl_loss=8.04]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148066.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.448495461583661e-07/0.4965815246105194\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073171.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  19%|        | 297/1600 [03:47<15:27,  1.41it/s, loss=0.0266, recon_loss=0.0198, kl_loss=6.83]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080836.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011763.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072064.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2582768249558285e-06/0.4912048876285553\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135986.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070774.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099703.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093985.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  19%|        | 299/1600 [03:48<13:39,  1.59it/s, loss=0.0208, recon_loss=0.0155, kl_loss=5.24]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4181450751493685e-05/0.4882270395755768\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118957.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042016.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.011474862229079e-06/0.5043461918830872\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/095/095231.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098229.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085317.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  19%|        | 300/1600 [03:49<15:47,  1.37it/s, loss=0.0227, recon_loss=0.018, kl_loss=4.76]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108528.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119991.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.582595541549381e-05/0.5128337740898132\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073318.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004096.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113971.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073573.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  19%|        | 301/1600 [03:50<18:21,  1.18it/s, loss=0.0295, recon_loss=0.0249, kl_loss=4.6]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/154/154306.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.826868123724125e-06/0.4985184371471405\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125314.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096901.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  19%|        | 302/1600 [03:51<16:46,  1.29it/s, loss=0.0217, recon_loss=0.0165, kl_loss=5.14]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.6159164917771704e-05/0.5033847689628601\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082237.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062185.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038879.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055183.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108865.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040147.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  19%|        | 303/1600 [03:52<19:33,  1.11it/s, loss=0.0242, recon_loss=0.0183, kl_loss=5.88]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.746075378785463e-07/0.48245298862457275\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/150/150078.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091755.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  19%|        | 304/1600 [03:53<16:50,  1.28it/s, loss=0.0216, recon_loss=0.0148, kl_loss=6.74]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.68333006312605e-06/0.5007538795471191\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127279.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000207.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  19%|        | 305/1600 [03:53<14:36,  1.48it/s, loss=0.027, recon_loss=0.0194, kl_loss=7.56]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004511.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.008871762081981e-06/0.4993327558040619\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140789.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006443.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120782.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134918.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092953.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  19%|        | 306/1600 [03:54<16:13,  1.33it/s, loss=0.0222, recon_loss=0.0136, kl_loss=8.62]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055233.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.310988068325969e-06/0.509499728679657\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000203.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052127.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032694.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004785.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  19%|        | 307/1600 [03:55<16:55,  1.27it/s, loss=0.0265, recon_loss=0.0172, kl_loss=9.31]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118500.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.882226908695884e-06/0.4911741018295288\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047471.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/065/065780.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/095/095189.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  19%|        | 308/1600 [03:56<17:02,  1.26it/s, loss=0.0227, recon_loss=0.0128, kl_loss=9.91]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129044.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.2896101654623635e-06/0.49489110708236694\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026017.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107048.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  19%|        | 309/1600 [03:56<15:45,  1.37it/s, loss=0.0203, recon_loss=0.0104, kl_loss=9.93]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093915.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4863841713008696e-08/0.47325262427330017\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114275.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019707.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  19%|        | 310/1600 [03:57<14:36,  1.47it/s, loss=0.0172, recon_loss=0.00794, kl_loss=9.24]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.55920781455643e-07/0.4813191890716553\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067332.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149777.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146017.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054621.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055287.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059667.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  19%|        | 311/1600 [03:58<16:44,  1.28it/s, loss=0.0149, recon_loss=0.00703, kl_loss=7.88]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055549.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.641894122414669e-07/0.4948436915874481\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134509.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/150/150080.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  20%|        | 312/1600 [03:58<15:57,  1.35it/s, loss=0.0238, recon_loss=0.0176, kl_loss=6.17]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019425.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098624.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091894.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060476.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129624.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047195.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.152843055431731e-05/0.49518004059791565\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/018/018611.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  20%|        | 314/1600 [04:00<14:29,  1.48it/s, loss=0.0249, recon_loss=0.0203, kl_loss=4.6]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.638084523227008e-07/0.5061575770378113\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067707.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056646.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.310704288305715e-06/0.4808117747306824\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085963.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  20%|        | 315/1600 [04:00<13:34,  1.58it/s, loss=0.0191, recon_loss=0.0146, kl_loss=4.51]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2748988353905588e-07/0.5013303756713867\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062003.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046157.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049401.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032800.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126416.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128473.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  20%|        | 316/1600 [04:01<14:59,  1.43it/s, loss=0.021, recon_loss=0.0163, kl_loss=4.64]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.985163635254139e-06/0.49661391973495483\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129919.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082507.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030196.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  20%|        | 317/1600 [04:02<14:26,  1.48it/s, loss=0.0212, recon_loss=0.0161, kl_loss=5.09]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134919.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.6461253582965583e-05/0.5066227912902832\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143532.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139775.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137463.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043599.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/065/065777.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064864.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  20%|        | 318/1600 [04:03<17:17,  1.24it/s, loss=0.0273, recon_loss=0.0214, kl_loss=5.81]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6731133882785798e-06/0.476907879114151\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073761.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126231.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  20%|        | 319/1600 [04:03<14:57,  1.43it/s, loss=0.0177, recon_loss=0.0105, kl_loss=7.14]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4177999219100457e-07/0.47862789034843445\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119580.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/077/077521.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  20%|        | 320/1600 [04:04<13:13,  1.61it/s, loss=0.0151, recon_loss=0.00692, kl_loss=8.2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134940.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.8256416467465897e-07/0.5026374459266663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064249.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021401.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074546.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122910.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110689.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131426.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138010.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  20%|        | 321/1600 [04:05<17:57,  1.19it/s, loss=0.0184, recon_loss=0.0099, kl_loss=8.52]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.3349980337079614e-06/0.4841839671134949\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118276.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120309.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  20%|        | 322/1600 [04:06<15:19,  1.39it/s, loss=0.0202, recon_loss=0.0118, kl_loss=8.35]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.4732468634501856e-07/0.49022725224494934\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081650.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038781.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  20%|        | 323/1600 [04:06<13:30,  1.58it/s, loss=0.0183, recon_loss=0.0104, kl_loss=7.98]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.98153245998401e-07/0.49321597814559937\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105142.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017906.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132679.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126402.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011917.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135337.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068538.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  20%|        | 324/1600 [04:07<17:37,  1.21it/s, loss=0.0201, recon_loss=0.0127, kl_loss=7.42]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141282.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.3854689124600554e-07/0.49312373995780945\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132773.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047199.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073560.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  20%|        | 325/1600 [04:08<18:02,  1.18it/s, loss=0.0179, recon_loss=0.011, kl_loss=6.89]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012048.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2550674000522122e-05/0.4944016635417938\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012489.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108530.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122533.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  20%|        | 326/1600 [04:09<17:32,  1.21it/s, loss=0.0184, recon_loss=0.0122, kl_loss=6.26]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.140948763302731e-07/0.4946334660053253\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134510.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004095.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  20%|        | 327/1600 [04:09<15:10,  1.40it/s, loss=0.016, recon_loss=0.0102, kl_loss=5.72]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090074.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083438.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081365.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/152/152261.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.8247382058689254e-06/0.5081018209457397\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073366.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119575.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  20%|        | 328/1600 [04:11<18:06,  1.17it/s, loss=0.0192, recon_loss=0.014, kl_loss=5.18]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066782.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2439015151244348e-08/0.4954119026660919\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119894.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114036.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  21%|        | 329/1600 [04:11<16:05,  1.32it/s, loss=0.0183, recon_loss=0.0135, kl_loss=4.86]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046842.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.883431342112999e-08/0.5204203724861145\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/095/095310.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118986.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  21%|        | 330/1600 [04:12<14:51,  1.42it/s, loss=0.0239, recon_loss=0.0192, kl_loss=4.74]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.452824446663726e-06/0.5024137496948242\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/008/008056.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115471.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038827.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127036.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  21%|        | 331/1600 [04:12<14:49,  1.43it/s, loss=0.0184, recon_loss=0.0135, kl_loss=4.85]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/025/025601.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7134883819380775e-05/0.5079036355018616\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/058/058540.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064334.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036992.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  21%|        | 332/1600 [04:13<14:50,  1.42it/s, loss=0.0236, recon_loss=0.0185, kl_loss=5.14]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/058/058166.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.692063392511045e-06/0.49361658096313477\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135990.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068537.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059654.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  21%|        | 333/1600 [04:14<14:45,  1.43it/s, loss=0.0186, recon_loss=0.0126, kl_loss=5.97]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145703.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048488.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.484818075274234e-07/0.47230514883995056\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087153.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123501.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084768.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  21%|        | 334/1600 [04:15<16:00,  1.32it/s, loss=0.0184, recon_loss=0.0115, kl_loss=6.89]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069188.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/023/023014.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141289.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 3.1804341915631085e-07/0.48940443992614746\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036304.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119939.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  21%|        | 335/1600 [04:16<17:06,  1.23it/s, loss=0.0178, recon_loss=0.0101, kl_loss=7.78]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055240.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.64064573482392e-07/0.5018505454063416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142569.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054942.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  21%|        | 336/1600 [04:16<15:24,  1.37it/s, loss=0.0233, recon_loss=0.0149, kl_loss=8.41]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/039/039660.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.181761141808238e-07/0.4761454463005066\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110266.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137356.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  21%|        | 337/1600 [04:17<14:36,  1.44it/s, loss=0.015, recon_loss=0.00591, kl_loss=9.08]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119900.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4375292067825285e-09/0.48136842250823975\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094632.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130986.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006677.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067597.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046841.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122647.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  21%|        | 338/1600 [04:18<18:18,  1.15it/s, loss=0.0153, recon_loss=0.00632, kl_loss=8.97]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123523.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.172571894083376e-07/0.48048681020736694\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122809.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  21%|        | 339/1600 [04:19<16:01,  1.31it/s, loss=0.016, recon_loss=0.00768, kl_loss=8.29]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024748.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.709730536793359e-06/0.48528268933296204\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126105.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106564.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113267.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/100/100959.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  21%|       | 340/1600 [04:20<17:34,  1.19it/s, loss=0.0182, recon_loss=0.0109, kl_loss=7.3]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126216.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.901107099110959e-07/0.4786771237850189\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048442.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003264.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013711.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  21%|       | 341/1600 [04:20<17:01,  1.23it/s, loss=0.0153, recon_loss=0.00882, kl_loss=6.46]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.559342142191781e-08/0.46709755063056946\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116760.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084141.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  21%|       | 342/1600 [04:21<14:47,  1.42it/s, loss=0.0133, recon_loss=0.0077, kl_loss=5.62]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126584.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075419.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.157248218281893e-06/0.4938680827617645\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070772.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011921.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  21%|       | 343/1600 [04:22<14:38,  1.43it/s, loss=0.0201, recon_loss=0.0153, kl_loss=4.77]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104064.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4826684491708875e-05/0.4974648356437683\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122683.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122620.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  22%|       | 344/1600 [04:22<13:36,  1.54it/s, loss=0.0181, recon_loss=0.0138, kl_loss=4.37]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081491.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052036.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144933.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029816.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032882.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043860.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043695.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.918788231909275e-05/0.4976378083229065\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067638.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  22%|       | 345/1600 [04:23<18:03,  1.16it/s, loss=0.0174, recon_loss=0.0131, kl_loss=4.32]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145711.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134448.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.9364647414477076e-06/0.49695485830307007\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  22%|       | 346/1600 [04:24<15:42,  1.33it/s, loss=0.0142, recon_loss=0.00959, kl_loss=4.56]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011951.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.152827154437546e-06/0.49632152915000916\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130456.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137725.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010697.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010694.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148608.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  22%|       | 347/1600 [04:25<18:41,  1.12it/s, loss=0.0153, recon_loss=0.0105, kl_loss=4.8]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125158.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.763411544037808e-07/0.46571671962738037\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145199.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  22%|       | 348/1600 [04:26<16:10,  1.29it/s, loss=0.0118, recon_loss=0.00676, kl_loss=5.09]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/076/076121.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.100897503027227e-06/0.47679296135902405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111154.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133546.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  22%|       | 349/1600 [04:26<15:12,  1.37it/s, loss=0.0174, recon_loss=0.0123, kl_loss=5.16]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098584.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108341.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139521.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.205622528592357e-07/0.5049256086349487\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003880.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060037.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130683.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082915.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  22%|       | 350/1600 [04:27<18:17,  1.14it/s, loss=0.02, recon_loss=0.0146, kl_loss=5.41]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059723.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.445453237802212e-08/0.46578556299209595\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075439.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  22%|       | 351/1600 [04:28<15:13,  1.37it/s, loss=0.0164, recon_loss=0.0105, kl_loss=5.92]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003533.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.0250233723782003e-07/0.48449966311454773\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069785.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116345.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  22%|       | 352/1600 [04:28<14:21,  1.45it/s, loss=0.0162, recon_loss=0.00969, kl_loss=6.54]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139770.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038362.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.932190560997697e-07/0.5056124925613403\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140872.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130990.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  22%|       | 353/1600 [04:29<14:27,  1.44it/s, loss=0.0226, recon_loss=0.0154, kl_loss=7.19]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085494.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056498.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137899.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 6.872387103840083e-08/0.468266099691391\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108031.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  22%|       | 354/1600 [04:30<14:29,  1.43it/s, loss=0.0134, recon_loss=0.00526, kl_loss=8.14]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138410.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110653.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009491.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3559100509041855e-08/0.4947701394557953\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/018/018112.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030486.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074375.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  22%|       | 355/1600 [04:31<15:47,  1.31it/s, loss=0.0206, recon_loss=0.0121, kl_loss=8.52]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134931.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.320586910466773e-08/0.48060092329978943\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108864.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056471.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075927.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  22%|       | 356/1600 [04:32<15:51,  1.31it/s, loss=0.0151, recon_loss=0.00619, kl_loss=8.95]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019459.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.50480886418336e-07/0.47434139251708984\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114373.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052579.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  22%|       | 358/1600 [04:32<10:51,  1.91it/s, loss=0.0142, recon_loss=0.00601, kl_loss=8.17]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.631076251371269e-07/0.47897979617118835\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131932.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116458.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091624.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098585.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118886.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.043147656484507e-06/0.4855222702026367\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111220.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112790.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125287.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  22%|       | 359/1600 [04:33<14:56,  1.38it/s, loss=0.018, recon_loss=0.0107, kl_loss=7.24]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4505464385194955e-08/0.4440436065196991\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130964.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108474.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128835.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006331.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/065/065683.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  22%|       | 360/1600 [04:34<16:18,  1.27it/s, loss=0.0117, recon_loss=0.00511, kl_loss=6.54]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136134.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.75733951741131e-07/0.4759886860847473\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131914.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132420.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057177.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  23%|       | 361/1600 [04:35<16:14,  1.27it/s, loss=0.012, recon_loss=0.00637, kl_loss=5.64]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.031703161264886e-06/0.49114516377449036\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/016/016995.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121736.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  23%|       | 362/1600 [04:36<13:58,  1.48it/s, loss=0.0169, recon_loss=0.0122, kl_loss=4.71]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135370.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0317607152264827e-07/0.494695246219635\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114069.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038914.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053592.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107956.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/005/005157.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090587.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  23%|       | 363/1600 [04:37<17:14,  1.20it/s, loss=0.0177, recon_loss=0.0135, kl_loss=4.23]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040657.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4661916338809533e-06/0.513128399848938\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126408.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  23%|       | 364/1600 [04:37<15:05,  1.36it/s, loss=0.0216, recon_loss=0.0175, kl_loss=4.07]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.320613804040477e-07/0.49713048338890076\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038785.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/065/065234.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129742.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089484.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  23%|       | 365/1600 [04:38<15:47,  1.30it/s, loss=0.0165, recon_loss=0.012, kl_loss=4.49]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053729.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.336663832540168e-11/0.4561958312988281\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139117.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092888.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  23%|       | 366/1600 [04:39<14:32,  1.41it/s, loss=0.0112, recon_loss=0.0061, kl_loss=5.11]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.346644454424677e-07/0.47603821754455566\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/095/095724.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073367.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122358.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/154/154413.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080351.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083791.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121666.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  23%|       | 367/1600 [04:40<18:06,  1.13it/s, loss=0.0124, recon_loss=0.00685, kl_loss=5.59]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.518577559840196e-07/0.4865109920501709\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001681.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036388.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  23%|       | 368/1600 [04:40<15:36,  1.31it/s, loss=0.0118, recon_loss=0.0059, kl_loss=5.92]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.82471652010463e-07/0.4789278209209442\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046024.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110610.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063252.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075432.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  23%|       | 369/1600 [04:41<15:58,  1.28it/s, loss=0.0127, recon_loss=0.0067, kl_loss=6.04]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123488.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069206.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139522.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.0126665251373197e-07/0.4674282670021057\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085310.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115767.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  23%|       | 370/1600 [04:42<17:14,  1.19it/s, loss=0.0127, recon_loss=0.00669, kl_loss=5.98]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/025/025032.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2361605961075384e-08/0.49605169892311096\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087103.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124874.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108487.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  23%|       | 371/1600 [04:43<16:34,  1.24it/s, loss=0.014, recon_loss=0.00823, kl_loss=5.79]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.5479590659571727e-10/0.4964618682861328\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055100.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127212.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  23%|       | 372/1600 [04:43<14:06,  1.45it/s, loss=0.0108, recon_loss=0.00512, kl_loss=5.68]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.032393677443906e-08/0.46112295985221863\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/005/005169.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138053.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088878.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  23%|       | 373/1600 [04:44<13:02,  1.57it/s, loss=0.0101, recon_loss=0.00469, kl_loss=5.38]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043173.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3946814760856796e-06/0.5062358379364014\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121657.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057639.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116871.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143300.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134486.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007709.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010441.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  23%|       | 374/1600 [04:45<17:21,  1.18it/s, loss=0.0229, recon_loss=0.018, kl_loss=4.92]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126944.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.309691270989788e-07/0.4853857755661011\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059657.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  23%|       | 375/1600 [04:46<15:10,  1.34it/s, loss=0.0116, recon_loss=0.00656, kl_loss=5.05]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122082.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.686915802831209e-08/0.49270784854888916\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131323.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121653.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130955.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123762.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124755.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  24%|       | 376/1600 [04:47<17:07,  1.19it/s, loss=0.0147, recon_loss=0.00956, kl_loss=5.1]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141168.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.601871133516397e-07/0.49029797315597534\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021231.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  24%|       | 377/1600 [04:47<14:50,  1.37it/s, loss=0.0118, recon_loss=0.0065, kl_loss=5.28]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123899.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149689.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.255359165952541e-05/0.4780406653881073\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010388.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068355.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056020.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068839.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  24%|       | 378/1600 [04:48<17:37,  1.16it/s, loss=0.015, recon_loss=0.00962, kl_loss=5.36]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092948.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107613.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  24%|       | 379/1600 [04:49<15:17,  1.33it/s, loss=0.0176, recon_loss=0.012, kl_loss=5.57]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056648.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.258798859766102e-07/0.49883899092674255\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089843.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.9287787722532812e-07/0.47716712951660156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123966.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/023/023037.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087645.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137716.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  24%|       | 380/1600 [04:50<17:15,  1.18it/s, loss=0.0151, recon_loss=0.00906, kl_loss=6.09]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134934.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.0061803591461285e-09/0.45694106817245483\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091900.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  24%|       | 381/1600 [04:50<14:56,  1.36it/s, loss=0.00909, recon_loss=0.00243, kl_loss=6.66]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138022.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.766995935298837e-08/0.45633620023727417\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001649.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134825.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  24%|       | 382/1600 [04:51<14:10,  1.43it/s, loss=0.0122, recon_loss=0.00544, kl_loss=6.74]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060144.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010808.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/016/016994.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013668.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.167157261596003e-08/0.46651017665863037\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088854.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091868.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091085.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  24%|       | 383/1600 [04:52<16:54,  1.20it/s, loss=0.0119, recon_loss=0.0053, kl_loss=6.6]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145042.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.082375930167473e-08/0.4947720170021057\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072789.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  24%|       | 384/1600 [04:53<14:47,  1.37it/s, loss=0.0198, recon_loss=0.0136, kl_loss=6.22]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117967.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.42899351532833e-08/0.4941650331020355\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122578.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108882.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081195.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112315.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  24%|       | 385/1600 [04:54<16:09,  1.25it/s, loss=0.0142, recon_loss=0.00774, kl_loss=6.43]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019729.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112000.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.436352120748779e-07/0.4717108905315399\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086486.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  24%|       | 386/1600 [04:54<15:32,  1.30it/s, loss=0.0126, recon_loss=0.006, kl_loss=6.58]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042017.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.2314272147004885e-08/0.441804438829422\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134631.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/058/058135.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  24%|       | 387/1600 [04:55<13:48,  1.46it/s, loss=0.00908, recon_loss=0.00254, kl_loss=6.55]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033538.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5712771528342273e-08/0.4676072895526886\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/147/147022.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118000.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130752.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145020.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085835.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075429.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  24%|       | 388/1600 [04:56<17:00,  1.19it/s, loss=0.0102, recon_loss=0.00413, kl_loss=6.11]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013928.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.1285594559449237e-06/0.4945494830608368\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  24%|       | 389/1600 [04:56<13:36,  1.48it/s, loss=0.0127, recon_loss=0.00722, kl_loss=5.49]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085973.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024901.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7541838204238047e-08/0.501265287399292\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075788.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  24%|       | 390/1600 [04:57<13:15,  1.52it/s, loss=0.0183, recon_loss=0.0134, kl_loss=4.93]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073344.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112587.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073764.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.2572075977222994e-06/0.47007644176483154\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108473.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129442.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014542.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035537.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/039/039875.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  24%|       | 391/1600 [04:58<17:16,  1.17it/s, loss=0.0112, recon_loss=0.00645, kl_loss=4.8]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143219.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080402.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.0050955501792487e-07/0.5010871887207031\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  24%|       | 392/1600 [04:59<15:02,  1.34it/s, loss=0.0141, recon_loss=0.00943, kl_loss=4.65]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013929.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.86470828111851e-07/0.4614819884300232\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/079/079973.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/076/076654.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105918.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  25%|       | 393/1600 [05:00<15:36,  1.29it/s, loss=0.00929, recon_loss=0.00462, kl_loss=4.67]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148075.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066717.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108493.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.740200955031469e-07/0.4419141411781311\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048861.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040509.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  25%|       | 394/1600 [05:00<16:03,  1.25it/s, loss=0.00795, recon_loss=0.00337, kl_loss=4.58]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009557.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.364956171481026e-07/0.4648144543170929\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026014.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  25%|       | 395/1600 [05:01<13:39,  1.47it/s, loss=0.0091, recon_loss=0.00479, kl_loss=4.31]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145747.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074374.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027866.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.0477073664769705e-07/0.4558604061603546\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  25%|       | 396/1600 [05:01<12:53,  1.56it/s, loss=0.00863, recon_loss=0.00465, kl_loss=3.98]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066535.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113025.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067457.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.899399677540714e-07/0.486372709274292\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042789.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114559.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/095/095726.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/031/031391.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127207.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  25%|       | 397/1600 [05:03<17:13,  1.16it/s, loss=0.0108, recon_loss=0.00721, kl_loss=3.61]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068893.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0604498612565294e-07/0.4848191738128662\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001277.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  25%|       | 398/1600 [05:03<14:49,  1.35it/s, loss=0.0107, recon_loss=0.00732, kl_loss=3.37]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084056.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141180.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000997.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.9196627338023973e-09/0.4639119505882263\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/079/079978.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087490.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  25%|       | 399/1600 [05:04<15:54,  1.26it/s, loss=0.00886, recon_loss=0.00561, kl_loss=3.25]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137563.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.3322072091077644e-08/0.48022961616516113\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  25%|       | 400/1600 [05:04<12:42,  1.57it/s, loss=0.0107, recon_loss=0.00755, kl_loss=3.16]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003263.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021228.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121321.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117883.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011868.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049856.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.8831280474150844e-08/0.48838263750076294\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124875.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133023.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133974.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  25%|       | 401/1600 [05:06<18:52,  1.06it/s, loss=0.0104, recon_loss=0.00728, kl_loss=3.15]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003270.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.65952354034016e-07/0.46154406666755676\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  25%|       | 402/1600 [05:06<14:46,  1.35it/s, loss=0.00725, recon_loss=0.00404, kl_loss=3.21]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.81355073134182e-07/0.45932430028915405\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011200.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/050/050276.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  25%|       | 403/1600 [05:07<13:12,  1.51it/s, loss=0.00906, recon_loss=0.00586, kl_loss=3.19]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098838.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1152461638630484e-06/0.5105345249176025\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051333.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105720.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129808.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067237.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108308.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  25%|       | 404/1600 [05:08<14:26,  1.38it/s, loss=0.019, recon_loss=0.0158, kl_loss=3.18]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.083396981016449e-07/0.5084762573242188\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052125.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038321.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091899.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  25%|       | 405/1600 [05:08<13:23,  1.49it/s, loss=0.0181, recon_loss=0.0146, kl_loss=3.55]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052648.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135365.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045393.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.4921847575096763e-07/0.43758678436279297\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113809.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  25%|       | 406/1600 [05:09<13:36,  1.46it/s, loss=0.00803, recon_loss=0.0038, kl_loss=4.24]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110771.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012109.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120298.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137998.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038326.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.056923780306533e-07/0.4627678394317627\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/041/041961.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094263.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  25%|       | 407/1600 [05:10<17:48,  1.12it/s, loss=0.00961, recon_loss=0.00484, kl_loss=4.77]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.168386524838752e-09/0.44393256306648254\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097961.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137627.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  26%|       | 408/1600 [05:11<15:13,  1.30it/s, loss=0.00875, recon_loss=0.00358, kl_loss=5.18]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127722.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.064241920787026e-08/0.42411327362060547\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127269.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  26%|       | 409/1600 [05:11<13:59,  1.42it/s, loss=0.00799, recon_loss=0.00263, kl_loss=5.36]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133451.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115816.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140625.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042751.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085693.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  26%|       | 410/1600 [05:12<14:42,  1.35it/s, loss=0.0126, recon_loss=0.00728, kl_loss=5.27]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0488707147260357e-07/0.48812147974967957\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128471.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001686.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.11002820455542e-08/0.48039910197257996\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045128.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126406.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  26%|       | 411/1600 [05:13<14:39,  1.35it/s, loss=0.0121, recon_loss=0.00683, kl_loss=5.29]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126606.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5059686830909413e-08/0.4869542717933655\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055236.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130932.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067232.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019413.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032330.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  26%|       | 412/1600 [05:14<17:22,  1.14it/s, loss=0.00951, recon_loss=0.00419, kl_loss=5.32]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/025/025233.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140259.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 2.655216491120882e-09/0.46510857343673706\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127996.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130920.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  26%|       | 413/1600 [05:15<16:27,  1.20it/s, loss=0.0107, recon_loss=0.00547, kl_loss=5.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.929103678667616e-09/0.45131915807724\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067308.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112485.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  26%|       | 414/1600 [05:15<14:15,  1.39it/s, loss=0.00836, recon_loss=0.00333, kl_loss=5.03]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091960.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129970.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013596.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059719.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.8900260531372624e-06/0.4997541904449463\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145475.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  26%|       | 415/1600 [05:16<15:09,  1.30it/s, loss=0.0142, recon_loss=0.00949, kl_loss=4.7]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131796.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107950.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108302.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0740151285281172e-07/0.4666558504104614\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  26%|       | 416/1600 [05:17<13:49,  1.43it/s, loss=0.00936, recon_loss=0.00475, kl_loss=4.61]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110384.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052447.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.280607762055297e-07/0.48659202456474304\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109191.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073175.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  26%|       | 417/1600 [05:17<13:48,  1.43it/s, loss=0.015, recon_loss=0.0105, kl_loss=4.46]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141375.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117287.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045391.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.9347386859844846e-07/0.45669639110565186\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085308.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109480.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107578.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/152/152425.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  26%|       | 418/1600 [05:19<16:49,  1.17it/s, loss=0.00873, recon_loss=0.00405, kl_loss=4.68]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/016/016339.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.5869361642303375e-09/0.4887445867061615\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032326.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  26%|       | 419/1600 [05:19<14:23,  1.37it/s, loss=0.00819, recon_loss=0.00342, kl_loss=4.76]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.104689140163373e-08/0.4811505079269409\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/022/022001.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126233.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131019.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  26%|       | 420/1600 [05:20<13:34,  1.45it/s, loss=0.00869, recon_loss=0.00401, kl_loss=4.68]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123458.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004781.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133294.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.032747882997683e-09/0.4819577932357788\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115923.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021403.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  26%|       | 421/1600 [05:21<14:51,  1.32it/s, loss=0.0116, recon_loss=0.00709, kl_loss=4.48]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071216.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.8651459754437383e-07/0.49803924560546875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107249.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141590.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068549.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133567.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  26%|       | 423/1600 [05:22<11:24,  1.72it/s, loss=0.0104, recon_loss=0.00594, kl_loss=4.5]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.39139217480988e-06/0.47253280878067017\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028477.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074955.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.523642130356166e-07/0.45249953866004944\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057628.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137567.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085834.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  26%|       | 424/1600 [05:22<12:20,  1.59it/s, loss=0.00859, recon_loss=0.00402, kl_loss=4.57]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113018.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081999.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051118.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143221.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036147.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6407853964395258e-09/0.4735001027584076\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126357.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098025.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110684.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  27%|       | 425/1600 [05:24<16:21,  1.20it/s, loss=0.00766, recon_loss=0.00314, kl_loss=4.52]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055828.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.670022401067399e-08/0.5018590092658997\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128827.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  27%|       | 427/1600 [05:24<10:18,  1.90it/s, loss=0.00966, recon_loss=0.00536, kl_loss=4.29]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.5608512522221645e-09/0.5076500773429871\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067017.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/095/095722.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126601.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.992078750845394e-06/0.49642279744148254\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074348.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121592.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108812.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056645.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075304.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086730.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126218.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081660.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  27%|       | 429/1600 [05:26<13:05,  1.49it/s, loss=0.00769, recon_loss=0.00346, kl_loss=4.23]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.2421522294944225e-08/0.450283408164978\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027258.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.372098499378808e-08/0.4705115854740143\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084417.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108457.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051006.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033465.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  27%|       | 430/1600 [05:27<15:26,  1.26it/s, loss=0.00971, recon_loss=0.00558, kl_loss=4.13]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054297.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7220533266026905e-07/0.4425183832645416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141179.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053157.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003492.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024739.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  27%|       | 431/1600 [05:28<16:16,  1.20it/s, loss=0.00764, recon_loss=0.00358, kl_loss=4.06]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129695.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0296885949733223e-08/0.45581525564193726\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/065/065038.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/050/050754.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114231.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  27%|       | 432/1600 [05:29<16:14,  1.20it/s, loss=0.00883, recon_loss=0.00495, kl_loss=3.88]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118923.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  27%|       | 433/1600 [05:29<12:30,  1.55it/s, loss=0.0108, recon_loss=0.0071, kl_loss=3.73]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.069211521098623e-06/0.4902396500110626\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052638.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127913.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5481420589935624e-08/0.46961626410484314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012532.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092561.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043773.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099274.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116514.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019179.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099345.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  27%|       | 435/1600 [05:31<13:59,  1.39it/s, loss=0.00672, recon_loss=0.00302, kl_loss=3.7]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0454956012040384e-08/0.4398879408836365\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011793.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085840.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044805.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082157.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.397086511038651e-07/0.5136784911155701\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/101/101118.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064253.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108050.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  27%|       | 436/1600 [05:32<17:21,  1.12it/s, loss=0.0171, recon_loss=0.0135, kl_loss=3.6]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/037/037727.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.2922837363003055e-06/0.5218988060951233\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121813.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  27%|       | 437/1600 [05:33<14:46,  1.31it/s, loss=0.0291, recon_loss=0.0251, kl_loss=4.03]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/103/103808.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4926197167142163e-08/0.4415827691555023\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014738.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  27%|       | 438/1600 [05:33<12:55,  1.50it/s, loss=0.00726, recon_loss=0.002, kl_loss=5.26]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124754.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110208.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138218.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/100/100536.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085600.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.2503228080950066e-07/0.4858410358428955\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064896.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139993.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052037.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  27%|       | 439/1600 [05:35<16:59,  1.14it/s, loss=0.0139, recon_loss=0.00764, kl_loss=6.29]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068897.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5378767148632733e-09/0.4165710210800171\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043030.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  28%|       | 440/1600 [05:35<14:31,  1.33it/s, loss=0.0086, recon_loss=0.00119, kl_loss=7.41]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148604.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.807269027296002e-10/0.4027344584465027\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088428.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096731.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083512.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021587.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133457.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  28%|       | 441/1600 [05:36<16:51,  1.15it/s, loss=0.0092, recon_loss=0.00121, kl_loss=7.99]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118502.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.646226479579127e-07/0.45720285177230835\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126489.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  28%|       | 442/1600 [05:37<14:29,  1.33it/s, loss=0.0122, recon_loss=0.00428, kl_loss=7.96]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012490.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.193644625478555e-08/0.3957357704639435\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125195.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087158.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  28%|       | 443/1600 [05:37<13:45,  1.40it/s, loss=0.00911, recon_loss=0.00151, kl_loss=7.6]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/076/076129.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071937.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026640.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 3.34817645830654e-10/0.47675585746765137\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038966.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107574.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/076/076437.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123427.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  28%|       | 444/1600 [05:39<17:06,  1.13it/s, loss=0.00898, recon_loss=0.00226, kl_loss=6.72]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007011.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.446490482948093e-09/0.4631844162940979\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143989.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  28%|       | 445/1600 [05:39<14:30,  1.33it/s, loss=0.00811, recon_loss=0.00257, kl_loss=5.54]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047077.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6484125175963982e-09/0.49317508935928345\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133025.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141164.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113203.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056874.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/050/050449.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  28%|       | 446/1600 [05:40<17:07,  1.12it/s, loss=0.0115, recon_loss=0.00728, kl_loss=4.22]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4219222066458315e-07/0.4692997634410858\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032759.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089441.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  28%|       | 447/1600 [05:41<14:26,  1.33it/s, loss=0.0072, recon_loss=0.00374, kl_loss=3.47]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.436485370883929e-09/0.47321271896362305\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114879.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127208.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122456.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047072.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  28%|       | 448/1600 [05:41<14:27,  1.33it/s, loss=0.00857, recon_loss=0.00583, kl_loss=2.75]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059678.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.950387039708403e-08/0.48651280999183655\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072787.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085436.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132456.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/076/076079.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  28%|       | 449/1600 [05:42<15:04,  1.27it/s, loss=0.00855, recon_loss=0.00616, kl_loss=2.39]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/058/058054.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.9533116214538495e-09/0.5076501965522766\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038557.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021996.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126887.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  28%|       | 450/1600 [05:43<15:35,  1.23it/s, loss=0.0247, recon_loss=0.0224, kl_loss=2.3]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074377.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5635521322110435e-08/0.43847790360450745\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056799.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/061/061821.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027978.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  28%|       | 451/1600 [05:44<15:58,  1.20it/s, loss=0.00606, recon_loss=0.00283, kl_loss=3.23]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019415.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2928514259158419e-08/0.5151553153991699\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047868.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111368.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062426.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  28%|       | 452/1600 [05:45<15:43,  1.22it/s, loss=0.0149, recon_loss=0.0108, kl_loss=4.07]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040235.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.138452578521083e-09/0.4691382646560669\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000602.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088876.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/023/023355.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  28%|       | 453/1600 [05:46<16:01,  1.19it/s, loss=0.00786, recon_loss=0.00269, kl_loss=5.16]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122810.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1746482186936191e-07/0.45017722249031067\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080754.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127267.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  28%|       | 454/1600 [05:46<14:55,  1.28it/s, loss=0.0091, recon_loss=0.00308, kl_loss=6.03]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032334.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.144030922390243e-10/0.4038707911968231\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109963.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036333.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/016/016744.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/018/018876.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042045.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  28%|       | 455/1600 [05:48<17:22,  1.10it/s, loss=0.00771, recon_loss=0.00109, kl_loss=6.62]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132122.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6374935851715122e-09/0.4566468894481659\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055242.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  28%|       | 456/1600 [05:48<14:54,  1.28it/s, loss=0.00925, recon_loss=0.00247, kl_loss=6.78]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099411.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056273.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4859411479051232e-08/0.45126423239707947\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064333.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049039.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116517.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  29%|       | 457/1600 [05:49<15:33,  1.22it/s, loss=0.00906, recon_loss=0.00242, kl_loss=6.64]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085822.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134938.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.638718185238758e-09/0.4222429096698761\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148208.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  29%|       | 458/1600 [05:49<14:04,  1.35it/s, loss=0.0084, recon_loss=0.00214, kl_loss=6.26]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001075.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116467.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.87175288601793e-08/0.48636025190353394\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092955.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  29%|       | 459/1600 [05:50<13:12,  1.44it/s, loss=0.0138, recon_loss=0.00808, kl_loss=5.7]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096694.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030690.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064628.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060331.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.276117510608856e-08/0.4498705565929413\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043536.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145458.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107432.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  29%|       | 460/1600 [05:51<15:58,  1.19it/s, loss=0.00775, recon_loss=0.00234, kl_loss=5.41]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7737225732616935e-07/0.43291643261909485\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136138.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108015.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  29%|       | 461/1600 [05:52<13:35,  1.40it/s, loss=0.00736, recon_loss=0.00239, kl_loss=4.97]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044797.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.509322414416374e-09/0.4643949866294861\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092508.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  29%|       | 462/1600 [05:52<12:07,  1.56it/s, loss=0.00908, recon_loss=0.00461, kl_loss=4.47]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040658.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133434.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067640.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108837.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3418281763488693e-10/0.43307116627693176\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127910.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085837.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  29%|       | 463/1600 [05:53<14:16,  1.33it/s, loss=0.00576, recon_loss=0.00174, kl_loss=4.02]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.7386353185221424e-09/0.44790300726890564\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141074.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063161.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048815.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049070.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071249.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  29%|       | 464/1600 [05:54<14:43,  1.29it/s, loss=0.0067, recon_loss=0.00316, kl_loss=3.54]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097692.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.523041827857014e-09/0.4378560483455658\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013218.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  29%|       | 465/1600 [05:54<12:36,  1.50it/s, loss=0.00528, recon_loss=0.00218, kl_loss=3.1]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132775.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043765.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131950.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 4.860909257331514e-07/0.4554111957550049\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141591.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007492.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127798.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108464.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  29%|       | 466/1600 [05:56<15:45,  1.20it/s, loss=0.00724, recon_loss=0.00456, kl_loss=2.68]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092538.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.9402222051212448e-07/0.47331857681274414\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111386.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  29%|       | 467/1600 [05:56<13:23,  1.41it/s, loss=0.00668, recon_loss=0.00432, kl_loss=2.36]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/025/025215.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5930977781408728e-07/0.5024474859237671\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/022/022093.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/025/025216.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  29%|       | 468/1600 [05:57<12:48,  1.47it/s, loss=0.0109, recon_loss=0.0088, kl_loss=2.13]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/039/039605.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.645350492107127e-09/0.47820764780044556\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045154.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084095.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107434.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036990.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098680.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  29%|       | 470/1600 [05:58<11:05,  1.70it/s, loss=0.0117, recon_loss=0.00966, kl_loss=2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.8391671119388775e-07/0.4975397288799286\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049073.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143059.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0897872604331837e-09/0.5005632042884827\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049064.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011673.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123936.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  29%|       | 471/1600 [05:59<11:56,  1.58it/s, loss=0.0142, recon_loss=0.0121, kl_loss=2.07]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.972736971671111e-09/0.46654433012008667\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131787.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116451.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033992.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071695.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007713.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/100/100958.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140609.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  30%|       | 472/1600 [06:00<15:00,  1.25it/s, loss=0.00728, recon_loss=0.005, kl_loss=2.28]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6018852022625651e-07/0.47277942299842834\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139876.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108059.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129362.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  30%|       | 473/1600 [06:00<14:09,  1.33it/s, loss=0.00841, recon_loss=0.00589, kl_loss=2.52]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075443.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003265.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.7463686880224714e-10/0.4588939845561981\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134981.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135336.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122352.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  30%|       | 474/1600 [06:01<15:17,  1.23it/s, loss=0.00606, recon_loss=0.00325, kl_loss=2.8]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121313.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0544414408286684e-07/0.4509035348892212\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137152.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096168.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086038.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  30%|       | 475/1600 [06:02<15:28,  1.21it/s, loss=0.00533, recon_loss=0.00228, kl_loss=3.05]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004846.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108318.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107799.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036799.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.48932829297155e-08/0.42496585845947266\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  30%|       | 476/1600 [06:03<15:29,  1.21it/s, loss=0.00484, recon_loss=0.00162, kl_loss=3.22]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126672.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012513.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.281900748357657e-07/0.4665413498878479\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073372.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084485.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  30%|       | 477/1600 [06:04<15:14,  1.23it/s, loss=0.00866, recon_loss=0.00538, kl_loss=3.29]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148032.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.741646636967744e-08/0.46883323788642883\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021409.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064407.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  30%|       | 478/1600 [06:04<14:02,  1.33it/s, loss=0.00664, recon_loss=0.00324, kl_loss=3.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021676.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044952.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.661540321469147e-08/0.48175275325775146\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098549.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054665.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001195.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  30%|       | 479/1600 [06:05<15:16,  1.22it/s, loss=0.0068, recon_loss=0.00334, kl_loss=3.46]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138039.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0225047475387328e-08/0.4786236882209778\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107047.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109975.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/020/020361.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  30%|       | 480/1600 [06:06<15:22,  1.21it/s, loss=0.00856, recon_loss=0.00509, kl_loss=3.47]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118279.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0400552241662808e-07/0.4312443137168884\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043608.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145257.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011503.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  30%|       | 481/1600 [06:07<14:52,  1.25it/s, loss=0.00552, recon_loss=0.002, kl_loss=3.52]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084057.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.034570314092605e-11/0.4810558557510376\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130682.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  30%|       | 482/1600 [06:07<12:51,  1.45it/s, loss=0.00717, recon_loss=0.00368, kl_loss=3.48]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069761.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097037.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122649.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048493.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.55324390916212e-07/0.49392735958099365\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/005/005006.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144944.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  30%|       | 483/1600 [06:08<15:02,  1.24it/s, loss=0.00984, recon_loss=0.00641, kl_loss=3.43]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098302.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.357819136657781e-07/0.5082310438156128\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129268.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145760.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088846.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  30%|       | 484/1600 [06:09<14:57,  1.24it/s, loss=0.0206, recon_loss=0.0172, kl_loss=3.46]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.2989475212398247e-08/0.4202880561351776\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118496.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130689.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  30%|       | 485/1600 [06:10<12:53,  1.44it/s, loss=0.00525, recon_loss=0.0014, kl_loss=3.85]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.405093865349045e-08/0.4763079881668091\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118058.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085957.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115597.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  30%|       | 486/1600 [06:10<12:10,  1.52it/s, loss=0.00891, recon_loss=0.0048, kl_loss=4.11]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075211.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118734.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119097.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011786.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042247.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110743.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.512823560341104e-10/0.48690712451934814\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120184.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056895.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  30%|       | 487/1600 [06:12<15:34,  1.19it/s, loss=0.00984, recon_loss=0.00547, kl_loss=4.37]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131446.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.107134880612875e-09/0.45807287096977234\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125002.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  30%|       | 488/1600 [06:12<13:29,  1.37it/s, loss=0.00787, recon_loss=0.00322, kl_loss=4.66]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105022.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.395425013901331e-08/0.47830700874328613\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064995.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144475.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105916.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131444.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089456.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  31%|       | 489/1600 [06:13<15:11,  1.22it/s, loss=0.011, recon_loss=0.00615, kl_loss=4.86]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7550301489865916e-10/0.47078463435173035\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096692.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125721.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  31%|       | 490/1600 [06:13<13:03,  1.42it/s, loss=0.00832, recon_loss=0.00321, kl_loss=5.12]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011918.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.954333054918436e-10/0.43672317266464233\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127185.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089857.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064631.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/076/076074.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  31%|       | 491/1600 [06:15<14:49,  1.25it/s, loss=0.00665, recon_loss=0.00136, kl_loss=5.29]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009477.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2051295517068183e-09/0.39803963899612427\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086576.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068869.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129884.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  31%|       | 492/1600 [06:15<14:52,  1.24it/s, loss=0.00613, recon_loss=0.000879, kl_loss=5.25]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/018/018607.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.704185206984903e-09/0.47789138555526733\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001687.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012349.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139520.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  31%|       | 493/1600 [06:16<15:05,  1.22it/s, loss=0.00701, recon_loss=0.002, kl_loss=5.02]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043594.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.337063744396801e-08/0.4726049602031708\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066073.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033072.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087152.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  31%|       | 494/1600 [06:17<15:02,  1.23it/s, loss=0.00841, recon_loss=0.00374, kl_loss=4.67]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.915224588979527e-09/0.4713839888572693\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054236.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  31%|       | 495/1600 [06:17<12:19,  1.50it/s, loss=0.00784, recon_loss=0.0035, kl_loss=4.34]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070657.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032686.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083600.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066537.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  31%|       | 496/1600 [06:18<12:32,  1.47it/s, loss=0.0061, recon_loss=0.00208, kl_loss=4.02]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 2.256216724561e-08/0.4477490782737732\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116709.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/103/103520.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109445.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3415331068244996e-08/0.4680178463459015\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004232.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084142.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  31%|       | 497/1600 [06:19<13:35,  1.35it/s, loss=0.00682, recon_loss=0.00316, kl_loss=3.66]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108494.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.511486515594413e-10/0.45909583568573\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085318.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069784.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047506.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  31%|       | 498/1600 [06:20<13:16,  1.38it/s, loss=0.00647, recon_loss=0.00316, kl_loss=3.32]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.267134423585617e-10/0.40183648467063904\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117991.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141561.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043911.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  31%|       | 499/1600 [06:20<12:13,  1.50it/s, loss=0.00405, recon_loss=0.00105, kl_loss=3]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080775.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.444468044122573e-10/0.5057775974273682\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004079.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/150/150018.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  31%|      | 500/1600 [06:21<11:39,  1.57it/s, loss=0.0123, recon_loss=0.00965, kl_loss=2.65]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090583.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109071.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142566.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063292.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132561.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/031/031042.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3733467696397383e-09/0.48614197969436646\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010993.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122080.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099704.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  31%|      | 501/1600 [06:22<16:13,  1.13it/s, loss=0.00952, recon_loss=0.00703, kl_loss=2.48]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012189.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128472.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 1.2317880049295127e-08/0.5162138342857361\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129374.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  31%|      | 502/1600 [06:23<14:49,  1.23it/s, loss=0.0051, recon_loss=0.00271, kl_loss=2.39]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4433692285820143e-07/0.5141241550445557\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119592.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056692.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  31%|      | 503/1600 [06:23<12:37,  1.45it/s, loss=0.0136, recon_loss=0.0113, kl_loss=2.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2292943551983626e-08/0.4351779818534851\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071722.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062531.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107953.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127180.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140934.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057943.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  32%|      | 504/1600 [06:24<14:22,  1.27it/s, loss=0.00431, recon_loss=0.00194, kl_loss=2.37]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056499.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125194.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127520.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091936.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0941820366715547e-06/0.5051655173301697\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000200.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  32%|      | 505/1600 [06:25<15:35,  1.17it/s, loss=0.0164, recon_loss=0.014, kl_loss=2.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087644.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.775558615222053e-09/0.4617464244365692\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109976.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  32%|      | 507/1600 [06:26<09:47,  1.86it/s, loss=0.00479, recon_loss=0.00181, kl_loss=2.98]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072210.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.593011944578393e-08/0.40013980865478516\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111938.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073772.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129185.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.56922230765133e-09/0.45737165212631226\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074372.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090570.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069197.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  32%|      | 508/1600 [06:27<12:30,  1.45it/s, loss=0.00467, recon_loss=0.00148, kl_loss=3.19]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.806345406585308e-09/0.3938351571559906\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013561.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129910.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/050/050264.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127330.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141283.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080753.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  32%|      | 509/1600 [06:28<13:48,  1.32it/s, loss=0.0045, recon_loss=0.00119, kl_loss=3.31]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105196.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.185188456380274e-07/0.4922984838485718\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120773.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125193.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128882.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  32%|      | 510/1600 [06:28<13:49,  1.31it/s, loss=0.0108, recon_loss=0.00745, kl_loss=3.33]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7471558066972648e-07/0.4581974744796753\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044092.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035462.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  32%|      | 511/1600 [06:29<11:46,  1.54it/s, loss=0.00538, recon_loss=0.00191, kl_loss=3.47]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0244064263531527e-08/0.4875774383544922\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118629.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085692.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148286.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  32%|      | 512/1600 [06:29<11:21,  1.60it/s, loss=0.00694, recon_loss=0.00342, kl_loss=3.52]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111372.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.858975361481498e-09/0.3868733048439026\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126781.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148235.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010192.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075937.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099363.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  32%|      | 513/1600 [06:30<12:27,  1.45it/s, loss=0.00478, recon_loss=0.00123, kl_loss=3.55]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131327.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.483857943185285e-07/0.4962542951107025\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107531.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009155.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116753.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138020.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  32%|      | 514/1600 [06:31<13:29,  1.34it/s, loss=0.00936, recon_loss=0.00589, kl_loss=3.48]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.8517590067167475e-08/0.5120429396629333\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049473.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024216.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  32%|      | 515/1600 [06:32<11:40,  1.55it/s, loss=0.0168, recon_loss=0.0134, kl_loss=3.47]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5541343145741848e-07/0.5076387524604797\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129973.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130945.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/103/103521.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129399.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  32%|      | 516/1600 [06:32<12:28,  1.45it/s, loss=0.0101, recon_loss=0.00648, kl_loss=3.67]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.261008713588808e-09/0.45094093680381775\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/018/018124.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122686.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111378.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141878.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024917.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118062.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  32%|      | 517/1600 [06:33<14:42,  1.23it/s, loss=0.00639, recon_loss=0.00246, kl_loss=3.92]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063999.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7097942853205872e-11/0.35640472173690796\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116487.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054433.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  32%|      | 518/1600 [06:34<13:25,  1.34it/s, loss=0.00474, recon_loss=0.000644, kl_loss=4.09]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.505547212043439e-09/0.40449416637420654\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/018/018039.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110927.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  32%|      | 519/1600 [06:34<11:30,  1.56it/s, loss=0.00515, recon_loss=0.00104, kl_loss=4.11]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/095/095912.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067763.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122132.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.548673574582111e-11/0.42187243700027466\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091093.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067556.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134073.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046058.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112211.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  32%|      | 520/1600 [06:36<15:48,  1.14it/s, loss=0.00513, recon_loss=0.00113, kl_loss=4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007381.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.919124192895083e-09/0.43543094396591187\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003598.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  33%|      | 521/1600 [06:36<13:50,  1.30it/s, loss=0.00569, recon_loss=0.0019, kl_loss=3.79]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127402.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115817.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 1.629625856480743e-08/0.49080100655555725\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109468.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071512.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/150/150015.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107182.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  33%|      | 522/1600 [06:38<16:09,  1.11it/s, loss=0.0129, recon_loss=0.00933, kl_loss=3.53]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0660864191436303e-08/0.4231521487236023\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090590.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054061.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  33%|      | 523/1600 [06:38<13:37,  1.32it/s, loss=0.00519, recon_loss=0.00176, kl_loss=3.43]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071694.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.31723170335863e-08/0.4768955707550049\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043535.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066076.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139226.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114535.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  33%|      | 524/1600 [06:39<15:16,  1.17it/s, loss=0.00723, recon_loss=0.00396, kl_loss=3.27]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149369.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.045360630338223e-09/0.4665362238883972\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013666.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125192.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  33%|      | 525/1600 [06:40<13:29,  1.33it/s, loss=0.00497, recon_loss=0.00183, kl_loss=3.14]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091329.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.164618871982384e-07/0.44103559851646423\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029480.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096401.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144213.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  33%|      | 526/1600 [06:40<13:23,  1.34it/s, loss=0.00607, recon_loss=0.00311, kl_loss=2.96]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/023/023156.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.1004336048235928e-09/0.4904319941997528\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043867.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/015/015772.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  33%|      | 527/1600 [06:41<12:02,  1.49it/s, loss=0.00867, recon_loss=0.00588, kl_loss=2.8]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109900.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117057.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055810.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.118871686058071e-10/0.49501410126686096\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084156.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045103.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060143.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  33%|      | 529/1600 [06:42<10:10,  1.75it/s, loss=0.00647, recon_loss=0.00379, kl_loss=2.68]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.56866488874175e-09/0.47861146926879883\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134795.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007376.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.3829455741974925e-08/0.43681415915489197\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035534.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140564.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094419.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000194.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  33%|      | 530/1600 [06:43<11:54,  1.50it/s, loss=0.00485, recon_loss=0.0022, kl_loss=2.65]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118484.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.443752363973545e-10/0.449856698513031\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012488.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116735.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144180.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060170.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111187.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  33%|      | 531/1600 [06:44<13:02,  1.37it/s, loss=0.00502, recon_loss=0.00242, kl_loss=2.59]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2790702896836592e-07/0.46673205494880676\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051112.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132678.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  33%|      | 532/1600 [06:44<11:27,  1.55it/s, loss=0.0059, recon_loss=0.00338, kl_loss=2.52]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126291.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014743.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029813.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.531025320555273e-08/0.47981488704681396\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085596.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131540.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  33%|      | 533/1600 [06:45<12:52,  1.38it/s, loss=0.00594, recon_loss=0.00349, kl_loss=2.45]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108497.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0368445657604752e-07/0.5086801052093506\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042139.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114384.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051276.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059721.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  33%|      | 534/1600 [06:46<14:16,  1.24it/s, loss=0.016, recon_loss=0.0136, kl_loss=2.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036984.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2518465153377178e-09/0.43790972232818604\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111399.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  33%|      | 535/1600 [06:46<12:22,  1.44it/s, loss=0.00476, recon_loss=0.00224, kl_loss=2.52]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131436.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051115.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026654.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073522.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046928.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.154567883636219e-10/0.4746584892272949\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085787.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071515.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  34%|      | 536/1600 [06:48<15:32,  1.14it/s, loss=0.00887, recon_loss=0.00626, kl_loss=2.61]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121315.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.686914355569229e-10/0.42797911167144775\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/058/058116.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  34%|      | 537/1600 [06:48<13:37,  1.30it/s, loss=0.00452, recon_loss=0.00173, kl_loss=2.8]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091161.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.843757673787195e-09/0.48787832260131836\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052040.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/152/152545.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/005/005170.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  34%|      | 538/1600 [06:49<13:50,  1.28it/s, loss=0.00663, recon_loss=0.00371, kl_loss=2.92]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.140793485873928e-09/0.45259764790534973\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012654.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116372.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123965.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130948.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055241.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  34%|      | 539/1600 [06:50<14:21,  1.23it/s, loss=0.00623, recon_loss=0.00319, kl_loss=3.03]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3445524871258385e-07/0.43736860156059265\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014661.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129090.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  34%|      | 540/1600 [06:50<12:19,  1.43it/s, loss=0.00506, recon_loss=0.00193, kl_loss=3.12]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.3623634837786085e-07/0.49468132853507996\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006368.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140623.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064601.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  34%|      | 541/1600 [06:51<11:08,  1.58it/s, loss=0.00828, recon_loss=0.00513, kl_loss=3.15]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.631803042163483e-08/0.42240262031555176\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125777.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/079/079988.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/039/039357.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  34%|      | 542/1600 [06:51<10:34,  1.67it/s, loss=0.00495, recon_loss=0.00172, kl_loss=3.23]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.357734256250524e-09/0.4019293487071991\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010438.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145746.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007481.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/103/103800.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043598.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  34%|      | 543/1600 [06:52<11:25,  1.54it/s, loss=0.00431, recon_loss=0.00108, kl_loss=3.23]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/101/101873.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.4738255294541887e-07/0.43715453147888184\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/018/018159.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000620.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072514.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142573.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/103/103522.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  34%|      | 544/1600 [06:53<13:18,  1.32it/s, loss=0.00549, recon_loss=0.00233, kl_loss=3.15]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056688.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004069.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/100/100799.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.803775795394813e-08/0.41609638929367065\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030090.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017573.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  34%|      | 545/1600 [06:54<13:52,  1.27it/s, loss=0.00457, recon_loss=0.00152, kl_loss=3.05]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0951142215276377e-08/0.448734313249588\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  34%|      | 546/1600 [06:54<10:47,  1.63it/s, loss=0.00545, recon_loss=0.00256, kl_loss=2.89]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084058.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030636.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.895245820866421e-09/0.47792482376098633\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096167.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123097.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032081.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  34%|      | 547/1600 [06:55<11:06,  1.58it/s, loss=0.00683, recon_loss=0.0041, kl_loss=2.73]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/100/100549.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/031/031999.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107908.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125001.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.9487442770582675e-08/0.41183459758758545\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120178.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012692.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138070.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126667.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  34%|      | 548/1600 [06:56<14:03,  1.25it/s, loss=0.00408, recon_loss=0.00147, kl_loss=2.61]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132040.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.5355655353109796e-09/0.4446246922016144\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135375.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  34%|      | 550/1600 [06:57<08:59,  1.95it/s, loss=0.00812, recon_loss=0.00581, kl_loss=2.31]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.165030294458802e-09/0.4835678040981293\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012146.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098206.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001736.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.245832379481726e-07/0.486738920211792\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021565.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115591.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  34%|      | 551/1600 [06:57<10:20,  1.69it/s, loss=0.00839, recon_loss=0.00614, kl_loss=2.25]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/031/031568.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138040.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063805.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127866.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.144080907765192e-12/0.47219201922416687\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055235.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051918.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010383.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110687.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056467.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  34%|      | 552/1600 [06:59<14:52,  1.17it/s, loss=0.00581, recon_loss=0.00356, kl_loss=2.25]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107126.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.622105734597426e-06/0.4970722496509552\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/078/078851.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010669.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  35%|      | 553/1600 [06:59<13:36,  1.28it/s, loss=0.0131, recon_loss=0.0108, kl_loss=2.27]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.39618422273702e-09/0.48643288016319275\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144939.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108496.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084096.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113167.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  35%|      | 554/1600 [07:00<13:22,  1.30it/s, loss=0.00924, recon_loss=0.00678, kl_loss=2.45]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.370877685985988e-09/0.463286429643631\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112977.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105672.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  35%|      | 555/1600 [07:01<11:24,  1.53it/s, loss=0.00562, recon_loss=0.00288, kl_loss=2.73]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.686659644230872e-09/0.42675235867500305\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110637.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032335.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108428.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127916.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135228.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104625.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  35%|      | 556/1600 [07:02<13:18,  1.31it/s, loss=0.00454, recon_loss=0.00154, kl_loss=2.99]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027667.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3838470647176138e-10/0.4207911491394043\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001924.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091309.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112588.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  35%|      | 557/1600 [07:02<13:31,  1.29it/s, loss=0.00461, recon_loss=0.00143, kl_loss=3.18]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087323.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.147798187721264e-09/0.42476993799209595\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148610.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111402.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  35%|      | 558/1600 [07:03<12:21,  1.41it/s, loss=0.00482, recon_loss=0.00153, kl_loss=3.29]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085347.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108967.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.723765017506821e-09/0.4486674964427948\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135989.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  35%|      | 559/1600 [07:04<11:32,  1.50it/s, loss=0.00422, recon_loss=0.000904, kl_loss=3.32]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146483.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113303.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064515.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.606868900391419e-08/0.44176581501960754\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115765.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089817.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129969.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133545.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  35%|      | 560/1600 [07:05<14:51,  1.17it/s, loss=0.00584, recon_loss=0.00258, kl_loss=3.26]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080517.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.411388397964402e-08/0.38535770773887634\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086793.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  35%|      | 561/1600 [07:05<12:59,  1.33it/s, loss=0.0044, recon_loss=0.00123, kl_loss=3.17]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.209745003118769e-08/0.4436163604259491\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086117.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066783.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  35%|      | 562/1600 [07:06<11:10,  1.55it/s, loss=0.00451, recon_loss=0.00148, kl_loss=3.03]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.76440411964785e-10/0.4524243474006653\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059078.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066539.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030041.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017634.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046161.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006519.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131425.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  35%|      | 563/1600 [07:07<14:16,  1.21it/s, loss=0.00502, recon_loss=0.00218, kl_loss=2.85]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038522.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.533192227678228e-08/0.45554208755493164\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113697.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044347.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  35%|      | 564/1600 [07:08<13:36,  1.27it/s, loss=0.0046, recon_loss=0.00195, kl_loss=2.66]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051262.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053228.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074387.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.023603767360328e-08/0.45580965280532837\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134801.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  35%|      | 565/1600 [07:08<13:33,  1.27it/s, loss=0.00499, recon_loss=0.00253, kl_loss=2.47]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3807233134599528e-10/0.45566755533218384\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097542.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035550.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091791.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  35%|      | 566/1600 [07:09<11:55,  1.44it/s, loss=0.00405, recon_loss=0.00176, kl_loss=2.29]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/095/095914.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080773.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024428.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087430.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2348720268562374e-08/0.4817570745944977\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119413.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  35%|      | 567/1600 [07:10<12:54,  1.33it/s, loss=0.00541, recon_loss=0.00331, kl_loss=2.11]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/065/065077.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110982.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.938296272958496e-09/0.4008024036884308\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113037.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056801.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 568/1600 [07:11<12:43,  1.35it/s, loss=0.00283, recon_loss=0.000869, kl_loss=1.96]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148439.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2765134504988396e-09/0.43894660472869873\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021404.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 569/1600 [07:11<10:56,  1.57it/s, loss=0.0032, recon_loss=0.0014, kl_loss=1.79]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048317.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044851.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/076/076440.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.286317801747373e-09/0.46004751324653625\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133275.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/061/061174.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019689.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 570/1600 [07:12<12:45,  1.35it/s, loss=0.00462, recon_loss=0.00299, kl_loss=1.63]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132019.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/065/065745.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141902.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.230363530119632e-10/0.45593026280403137\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046160.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072130.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 571/1600 [07:13<13:35,  1.26it/s, loss=0.00397, recon_loss=0.00248, kl_loss=1.5]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115761.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.894543519957551e-09/0.43410348892211914\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106876.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 572/1600 [07:13<11:33,  1.48it/s, loss=0.00393, recon_loss=0.00254, kl_loss=1.39]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026466.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0534134675665996e-09/0.38320600986480713\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141297.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021087.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 573/1600 [07:14<10:56,  1.56it/s, loss=0.00201, recon_loss=0.000711, kl_loss=1.3]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142534.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126321.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087966.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0530485372584053e-09/0.456768274307251\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007527.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071508.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085951.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133574.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114414.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 574/1600 [07:15<14:38,  1.17it/s, loss=0.00518, recon_loss=0.00398, kl_loss=1.2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086118.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.679392423488025e-07/0.42328986525535583\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097374.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 575/1600 [07:16<12:39,  1.35it/s, loss=0.00382, recon_loss=0.00268, kl_loss=1.14]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055186.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.102690187579583e-09/0.500476598739624\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109548.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 576/1600 [07:16<11:09,  1.53it/s, loss=0.00703, recon_loss=0.00594, kl_loss=1.1]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134791.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/078/078213.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108533.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.341239213725203e-07/0.4935034513473511\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125778.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003908.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052389.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062586.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 577/1600 [07:17<13:31,  1.26it/s, loss=0.00957, recon_loss=0.00848, kl_loss=1.1]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028375.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054154.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.017412986139334e-09/0.4800771176815033\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084159.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069793.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 578/1600 [07:18<13:30,  1.26it/s, loss=0.00364, recon_loss=0.00247, kl_loss=1.17]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3899144057916146e-08/0.515495777130127\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063456.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107127.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 579/1600 [07:18<11:50,  1.44it/s, loss=0.0115, recon_loss=0.0103, kl_loss=1.23]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.774614202953444e-10/0.44524085521698\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127206.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127210.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125809.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004239.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 580/1600 [07:19<12:04,  1.41it/s, loss=0.00424, recon_loss=0.00286, kl_loss=1.38]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068582.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004685.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131020.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033422.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 581/1600 [07:20<12:06,  1.40it/s, loss=0.0047, recon_loss=0.00317, kl_loss=1.53]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.280270254255811e-07/0.4380163848400116\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120321.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112316.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.747181093720741e-10/0.4781712591648102\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/022/022474.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125240.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131899.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140421.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006390.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 582/1600 [07:21<15:02,  1.13it/s, loss=0.00795, recon_loss=0.00626, kl_loss=1.69]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0651127091421131e-08/0.5033197999000549\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059664.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054576.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 583/1600 [07:22<12:35,  1.35it/s, loss=0.0103, recon_loss=0.00842, kl_loss=1.92]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0865763844236653e-09/0.47705191373825073\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133459.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/078/078843.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  36%|      | 584/1600 [07:22<11:08,  1.52it/s, loss=0.00581, recon_loss=0.00356, kl_loss=2.25]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064409.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1268242587902932e-06/0.48546886444091797\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004236.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087185.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/147/147886.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001704.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064627.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  37%|      | 585/1600 [07:23<13:17,  1.27it/s, loss=0.00914, recon_loss=0.00654, kl_loss=2.59]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127294.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.415638965582502e-09/0.44524213671684265\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123502.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057626.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092206.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013767.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  37%|      | 586/1600 [07:24<14:07,  1.20it/s, loss=0.00523, recon_loss=0.00221, kl_loss=3.02]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3857502385167253e-12/0.4910682141780853\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038880.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108418.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012045.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051272.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  37%|      | 587/1600 [07:25<13:52,  1.22it/s, loss=0.00711, recon_loss=0.00371, kl_loss=3.4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.516574195345129e-10/0.4644082188606262\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073774.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032332.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  37%|      | 588/1600 [07:25<11:39,  1.45it/s, loss=0.00661, recon_loss=0.00282, kl_loss=3.78]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001701.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.2132088989555996e-08/0.4722527861595154\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131933.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105919.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029744.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  37%|      | 589/1600 [07:26<11:35,  1.45it/s, loss=0.0105, recon_loss=0.00634, kl_loss=4.11]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.556931294999231e-08/0.42669764161109924\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146151.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113035.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122626.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081085.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148602.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085040.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  37%|      | 590/1600 [07:27<13:10,  1.28it/s, loss=0.00587, recon_loss=0.00132, kl_loss=4.55]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038961.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.0723299460078124e-09/0.4618176817893982\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012487.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059675.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072067.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  37%|      | 591/1600 [07:28<13:33,  1.24it/s, loss=0.00914, recon_loss=0.00431, kl_loss=4.83]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133024.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.1923289012247835e-10/0.3404676914215088\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118222.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  37%|      | 592/1600 [07:28<11:33,  1.45it/s, loss=0.00538, recon_loss=0.000264, kl_loss=5.11]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/152/152418.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062458.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092886.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.988494310495753e-09/0.4693613648414612\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141594.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132138.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  37%|      | 593/1600 [07:29<12:14,  1.37it/s, loss=0.00889, recon_loss=0.0037, kl_loss=5.18]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.475810339356958e-12/0.4659609794616699\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071715.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084483.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121452.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  37%|      | 594/1600 [07:30<11:13,  1.49it/s, loss=0.00604, recon_loss=0.000818, kl_loss=5.23]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098656.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071693.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109962.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117609.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.72266062262672e-11/0.48769253492355347\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084055.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148611.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  37%|      | 595/1600 [07:31<12:57,  1.29it/s, loss=0.0073, recon_loss=0.00222, kl_loss=5.08]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.4557763034802633e-10/0.3439098596572876\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/023/023329.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001893.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  37%|      | 596/1600 [07:31<11:05,  1.51it/s, loss=0.00527, recon_loss=0.000407, kl_loss=4.86]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014320.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.8355804376479767e-10/0.46738365292549133\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091088.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003573.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060544.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141903.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043025.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064521.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  37%|      | 597/1600 [07:32<13:49,  1.21it/s, loss=0.00764, recon_loss=0.00313, kl_loss=4.51]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142078.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1379029662972329e-10/0.4374181628227234\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  37%|      | 598/1600 [07:33<11:08,  1.50it/s, loss=0.00599, recon_loss=0.00182, kl_loss=4.17]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115268.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.351181110389234e-09/0.4599233567714691\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030487.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140935.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  37%|      | 599/1600 [07:33<10:49,  1.54it/s, loss=0.00702, recon_loss=0.0032, kl_loss=3.81]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046238.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118063.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038892.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109684.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.986038248944169e-09/0.40356266498565674\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036987.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047196.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120325.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/153/153337.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  38%|      | 600/1600 [07:34<13:36,  1.22it/s, loss=0.00462, recon_loss=0.00113, kl_loss=3.49]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.03477370905614e-10/0.4749920964241028\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124393.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027406.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  38%|      | 601/1600 [07:35<11:39,  1.43it/s, loss=0.00736, recon_loss=0.00422, kl_loss=3.14]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123333.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.877626042481097e-08/0.4825645387172699\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/152/152258.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142572.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  38%|      | 602/1600 [07:35<11:12,  1.48it/s, loss=0.0113, recon_loss=0.00842, kl_loss=2.88]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114070.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087070.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011768.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.976716013096791e-10/0.4769126772880554\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119193.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107476.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014585.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045127.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  38%|      | 603/1600 [07:37<14:22,  1.16it/s, loss=0.00483, recon_loss=0.00199, kl_loss=2.84]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125291.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089846.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1542959643673356e-10/0.4792341887950897\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  38%|      | 604/1600 [07:37<12:35,  1.32it/s, loss=0.00544, recon_loss=0.00267, kl_loss=2.77]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2412020300445192e-09/0.4687720835208893\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091162.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108020.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  38%|      | 605/1600 [07:38<10:55,  1.52it/s, loss=0.00566, recon_loss=0.00297, kl_loss=2.69]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133433.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.319924140627762e-10/0.36032700538635254\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140344.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081988.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048865.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013930.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/039/039658.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108526.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139663.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  38%|      | 606/1600 [07:39<15:01,  1.10it/s, loss=0.0031, recon_loss=0.000482, kl_loss=2.61]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139329.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3503913578460924e-06/0.48549818992614746\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126224.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  38%|      | 607/1600 [07:40<12:52,  1.29it/s, loss=0.00859, recon_loss=0.00611, kl_loss=2.48]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071822.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107425.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.240429619604356e-09/0.38251757621765137\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073675.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  38%|      | 608/1600 [07:40<11:52,  1.39it/s, loss=0.00319, recon_loss=0.000748, kl_loss=2.45]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3447569813251903e-07/0.4155329763889313\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057273.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032333.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064338.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143186.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142551.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  38%|      | 609/1600 [07:41<12:49,  1.29it/s, loss=0.00388, recon_loss=0.00152, kl_loss=2.36]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001706.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003534.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097987.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.039895085128364e-09/0.4618677496910095\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137214.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043520.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  38%|      | 610/1600 [07:42<13:53,  1.19it/s, loss=0.00846, recon_loss=0.00621, kl_loss=2.25]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091455.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098031.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.995604392845962e-08/0.38980767130851746\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127194.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122503.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  38%|      | 612/1600 [07:43<10:15,  1.61it/s, loss=0.0053, recon_loss=0.00309, kl_loss=2.21]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.8379884281216619e-09/0.46036237478256226\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054234.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/031/031040.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/152/152569.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116235.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086484.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105719.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.05681129451008e-12/0.42925363779067993\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/023/023155.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142575.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/100/100552.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081554.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  38%|      | 614/1600 [07:45<11:39,  1.41it/s, loss=0.00789, recon_loss=0.00577, kl_loss=2.12]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.340950681194002e-11/0.49606776237487793\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.763813650690338e-09/0.44919225573539734\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024842.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111400.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149139.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051784.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137426.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  38%|      | 615/1600 [07:46<13:13,  1.24it/s, loss=0.00489, recon_loss=0.00276, kl_loss=2.13]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045519.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.28275839634307e-09/0.4228019118309021\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110611.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133026.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122499.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  38%|      | 616/1600 [07:47<12:28,  1.31it/s, loss=0.00403, recon_loss=0.00189, kl_loss=2.14]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069787.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3008045161855275e-11/0.4590833783149719\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124424.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  39%|      | 617/1600 [07:47<10:57,  1.50it/s, loss=0.00422, recon_loss=0.00209, kl_loss=2.13]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/022/022478.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/020/020296.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 1.8372149668266502e-07/0.44458961486816406\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125160.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130369.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/005/005264.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069827.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097847.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  39%|      | 618/1600 [07:48<13:10,  1.24it/s, loss=0.00403, recon_loss=0.00193, kl_loss=2.1]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146681.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1103563402059535e-08/0.4616168439388275\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/154/154414.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014604.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  39%|      | 619/1600 [07:49<12:00,  1.36it/s, loss=0.00438, recon_loss=0.00233, kl_loss=2.05]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0969871233612594e-08/0.4928344190120697\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133535.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130137.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  39%|      | 620/1600 [07:49<10:21,  1.58it/s, loss=0.00944, recon_loss=0.00744, kl_loss=2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122511.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130170.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108297.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.0433117831352163e-11/0.46062156558036804\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080756.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125616.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024430.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027177.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054480.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  39%|      | 621/1600 [07:50<13:42,  1.19it/s, loss=0.00397, recon_loss=0.0019, kl_loss=2.07]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126187.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.62176835796879e-09/0.4950271546840668\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001039.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  39%|      | 622/1600 [07:51<11:39,  1.40it/s, loss=0.00646, recon_loss=0.00435, kl_loss=2.11]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/050/050283.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/023/023010.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.1830098617670046e-08/0.5242234468460083\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099214.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112821.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  39%|      | 623/1600 [07:52<12:12,  1.33it/s, loss=0.014, recon_loss=0.0118, kl_loss=2.17]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043843.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122457.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142517.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096696.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.0026208186484382e-09/0.4964592456817627\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114198.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  39%|      | 624/1600 [07:53<12:54,  1.26it/s, loss=0.00436, recon_loss=0.002, kl_loss=2.37]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010805.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.932070142236398e-09/0.4086662232875824\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142132.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133446.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  39%|      | 625/1600 [07:53<12:00,  1.35it/s, loss=0.0035, recon_loss=0.000981, kl_loss=2.52]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067121.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7983572964119787e-10/0.3864562511444092\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092954.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004521.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  39%|      | 626/1600 [07:54<11:43,  1.38it/s, loss=0.0036, recon_loss=0.00099, kl_loss=2.61]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133272.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108429.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2379028913045431e-09/0.3963753283023834\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085425.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003765.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  39%|      | 627/1600 [07:55<11:49,  1.37it/s, loss=0.00382, recon_loss=0.00119, kl_loss=2.63]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049066.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036099.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.185219102364023e-11/0.3517908453941345\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115475.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075398.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  39%|      | 628/1600 [07:55<11:46,  1.38it/s, loss=0.00308, recon_loss=0.000485, kl_loss=2.6]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.957080186798521e-08/0.4737701117992401\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119988.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087155.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040598.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127188.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  39%|      | 629/1600 [07:56<12:00,  1.35it/s, loss=0.00516, recon_loss=0.00262, kl_loss=2.53]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126220.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.876890085687592e-09/0.44306081533432007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112529.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027802.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125190.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126403.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/102/102114.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126103.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  39%|      | 630/1600 [07:57<14:28,  1.12it/s, loss=0.00361, recon_loss=0.00114, kl_loss=2.47]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014386.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.810176618657124e-09/0.4081120491027832\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098556.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  39%|      | 631/1600 [07:58<12:25,  1.30it/s, loss=0.00319, recon_loss=0.00082, kl_loss=2.38]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133100.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.773714619623945e-09/0.4036012291908264\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098575.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133975.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145759.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051120.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123934.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 632/1600 [07:59<14:29,  1.11it/s, loss=0.00339, recon_loss=0.00114, kl_loss=2.25]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075418.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.278418033886737e-09/0.47622114419937134\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141566.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 633/1600 [08:00<12:30,  1.29it/s, loss=0.00736, recon_loss=0.00526, kl_loss=2.11]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053158.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.638028189811848e-08/0.42350301146507263\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014541.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120297.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124178.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075194.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122500.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 634/1600 [08:01<14:17,  1.13it/s, loss=0.00338, recon_loss=0.00133, kl_loss=2.05]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017633.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117450.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.874575847997221e-08/0.44699615240097046\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119095.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 635/1600 [08:01<13:13,  1.22it/s, loss=0.0046, recon_loss=0.00263, kl_loss=1.97]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.66689672357279e-08/0.4358901381492615\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017635.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004777.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 636/1600 [08:02<11:09,  1.44it/s, loss=0.00464, recon_loss=0.00273, kl_loss=1.91]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115269.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.282346103920645e-08/0.4639052152633667\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108314.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011778.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045392.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029530.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024218.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/150/150073.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 637/1600 [08:03<13:17,  1.21it/s, loss=0.00326, recon_loss=0.0014, kl_loss=1.86]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.517431204779768e-09/0.39797186851501465\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051785.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/037/037730.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 638/1600 [08:03<11:10,  1.44it/s, loss=0.00272, recon_loss=0.000914, kl_loss=1.8]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140924.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.728659147052895e-08/0.48014891147613525\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132589.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009678.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 639/1600 [08:04<10:09,  1.58it/s, loss=0.00713, recon_loss=0.00541, kl_loss=1.73]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.333847117432015e-08/0.4875493049621582\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124555.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047075.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072058.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 640/1600 [08:04<09:33,  1.67it/s, loss=0.0063, recon_loss=0.0046, kl_loss=1.7]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106465.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.469282247209776e-08/0.4447266161441803\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139003.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146879.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104283.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126900.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019418.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 641/1600 [08:05<11:25,  1.40it/s, loss=0.00353, recon_loss=0.00182, kl_loss=1.71]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.843680537358068e-09/0.5065361261367798\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/078/078850.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085490.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/147/147265.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 642/1600 [08:06<10:22,  1.54it/s, loss=0.0069, recon_loss=0.00518, kl_loss=1.72]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024368.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127186.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069830.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.058313147342618e-12/0.496949166059494\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145707.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004838.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 643/1600 [08:07<11:42,  1.36it/s, loss=0.00487, recon_loss=0.00311, kl_loss=1.76]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.348170096728609e-08/0.5266613364219666\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127298.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114389.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/095/095910.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064364.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073469.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 644/1600 [08:08<12:36,  1.26it/s, loss=0.0212, recon_loss=0.0194, kl_loss=1.81]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.861489656336147e-10/0.3759022355079651\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054463.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130133.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 645/1600 [08:08<11:02,  1.44it/s, loss=0.00267, recon_loss=0.000674, kl_loss=2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148305.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136705.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000002.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.53661666408334e-09/0.472141295671463\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148607.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 646/1600 [08:09<11:20,  1.40it/s, loss=0.00612, recon_loss=0.00397, kl_loss=2.15]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086483.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098668.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109537.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/058/058474.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0692257035316288e-07/0.49715328216552734\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110647.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/034/034510.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 647/1600 [08:10<12:55,  1.23it/s, loss=0.00784, recon_loss=0.00552, kl_loss=2.32]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071507.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.614947700711582e-09/0.3918369710445404\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/150/150079.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  40%|      | 648/1600 [08:10<11:21,  1.40it/s, loss=0.00339, recon_loss=0.00087, kl_loss=2.52]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.6356141147896324e-10/0.38001129031181335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096718.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075390.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040229.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125289.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123932.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/153/153452.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  41%|      | 649/1600 [08:12<13:16,  1.19it/s, loss=0.00321, recon_loss=0.000544, kl_loss=2.66]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135091.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.388085692876541e-14/0.45543041825294495\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073365.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054436.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124185.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  41%|      | 650/1600 [08:12<13:16,  1.19it/s, loss=0.00435, recon_loss=0.00162, kl_loss=2.73]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126243.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139534.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.310668965170407e-08/0.4773980677127838\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/041/041018.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083954.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  41%|      | 651/1600 [08:13<13:08,  1.20it/s, loss=0.00822, recon_loss=0.00546, kl_loss=2.76]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.081687406312426e-09/0.4276570677757263\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107593.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057819.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  41%|      | 652/1600 [08:14<11:20,  1.39it/s, loss=0.00386, recon_loss=0.001, kl_loss=2.86]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.076060709072408e-09/0.44002217054367065\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003763.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057272.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113342.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068587.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/100/100550.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  41%|      | 653/1600 [08:15<12:16,  1.29it/s, loss=0.00452, recon_loss=0.00162, kl_loss=2.9]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/015/015469.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.9542409912531866e-09/0.4990052282810211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007491.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135043.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134979.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085955.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  41%|      | 654/1600 [08:15<12:54,  1.22it/s, loss=0.00651, recon_loss=0.00361, kl_loss=2.89]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112215.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001510.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099373.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.477164138374292e-09/0.3902362287044525\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092366.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  41%|      | 655/1600 [08:16<12:55,  1.22it/s, loss=0.00336, recon_loss=0.000473, kl_loss=2.88]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134453.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.667318265205722e-08/0.4357599914073944\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144471.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116241.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048863.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  41%|      | 656/1600 [08:17<13:06,  1.20it/s, loss=0.00506, recon_loss=0.00225, kl_loss=2.81]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116491.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.0519716882080345e-11/0.45123767852783203\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104067.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072149.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033069.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  41%|      | 657/1600 [08:18<13:12,  1.19it/s, loss=0.00434, recon_loss=0.00162, kl_loss=2.72]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.860078312018956e-11/0.4944418966770172\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038902.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/050/050543.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145777.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118327.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  41%|      | 658/1600 [08:19<13:16,  1.18it/s, loss=0.00834, recon_loss=0.00573, kl_loss=2.61]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.205263404148898e-13/0.4488397240638733\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011792.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122363.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  41%|      | 659/1600 [08:19<11:09,  1.41it/s, loss=0.00478, recon_loss=0.00221, kl_loss=2.57]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.816547770682746e-09/0.5039183497428894\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110109.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084200.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144182.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006389.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  41%|     | 660/1600 [08:20<11:43,  1.34it/s, loss=0.00602, recon_loss=0.0035, kl_loss=2.52]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054037.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113281.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/050/050446.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127915.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144173.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.025115377259141e-11/0.3745976686477661\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108027.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  41%|     | 661/1600 [08:21<12:49,  1.22it/s, loss=0.0033, recon_loss=0.000799, kl_loss=2.5]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114430.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.253293022284723e-11/0.42522045969963074\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085419.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110985.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  41%|     | 662/1600 [08:22<12:00,  1.30it/s, loss=0.00383, recon_loss=0.0014, kl_loss=2.43]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121570.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.6204591563327995e-07/0.4647909700870514\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007379.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026464.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  41%|     | 663/1600 [08:22<11:09,  1.40it/s, loss=0.00504, recon_loss=0.00269, kl_loss=2.35]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134449.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.59570431815348e-09/0.46196144819259644\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127496.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108745.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114545.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126559.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116464.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113023.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051291.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  42%|     | 665/1600 [08:24<10:47,  1.44it/s, loss=0.00379, recon_loss=0.00154, kl_loss=2.25]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.8777452481799628e-08/0.4207158386707306\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.964117726937502e-09/0.44450613856315613\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148585.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024425.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  42%|     | 666/1600 [08:24<09:40,  1.61it/s, loss=0.00431, recon_loss=0.00211, kl_loss=2.2]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119896.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062187.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2893712764139309e-08/0.4101204574108124\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092554.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107257.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007528.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107909.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082886.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133454.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  42%|     | 667/1600 [08:26<12:15,  1.27it/s, loss=0.00331, recon_loss=0.00117, kl_loss=2.15]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.881198153976584e-07/0.47837671637535095\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116755.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116457.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  42%|     | 668/1600 [08:26<10:48,  1.44it/s, loss=0.0048, recon_loss=0.00273, kl_loss=2.07]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.7149763326406173e-08/0.48021945357322693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/058/058341.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139804.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080520.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  42%|     | 669/1600 [08:27<10:21,  1.50it/s, loss=0.00838, recon_loss=0.00638, kl_loss=2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148028.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051111.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122622.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135363.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040139.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106456.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.600332807555787e-09/0.46344712376594543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148429.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125819.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  42%|     | 670/1600 [08:28<13:54,  1.11it/s, loss=0.00548, recon_loss=0.00346, kl_loss=2.03]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.8303658083927985e-08/0.39680060744285583\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/039/039664.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044849.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  42%|     | 671/1600 [08:29<12:06,  1.28it/s, loss=0.00379, recon_loss=0.00172, kl_loss=2.07]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143303.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.368528530393714e-12/0.40423092246055603\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107125.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126505.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062186.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  42%|     | 672/1600 [08:29<12:11,  1.27it/s, loss=0.00284, recon_loss=0.000749, kl_loss=2.09]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120300.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060994.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144733.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045517.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.5038092366667115e-08/0.39918482303619385\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004835.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  42%|     | 673/1600 [08:30<12:27,  1.24it/s, loss=0.00276, recon_loss=0.000685, kl_loss=2.08]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030059.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.8630677445230504e-08/0.48041677474975586\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111385.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127277.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024362.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  42%|     | 674/1600 [08:31<12:06,  1.27it/s, loss=0.0057, recon_loss=0.00367, kl_loss=2.03]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.0735394784819903e-10/0.4342614710330963\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142361.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111793.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  42%|     | 675/1600 [08:31<10:42,  1.44it/s, loss=0.00403, recon_loss=0.00203, kl_loss=2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/147/147087.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011788.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/005/005940.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.1548271847415812e-11/0.36096587777137756\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083898.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070303.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064859.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038888.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  42%|     | 676/1600 [08:33<13:21,  1.15it/s, loss=0.00238, recon_loss=0.000404, kl_loss=1.98]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107427.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.484866225761834e-09/0.5017400979995728\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062525.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  42%|     | 677/1600 [08:33<11:18,  1.36it/s, loss=0.00964, recon_loss=0.00773, kl_loss=1.91]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134826.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.3092318097469615e-08/0.4127865135669708\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085291.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130953.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112769.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  42%|     | 678/1600 [08:34<11:35,  1.33it/s, loss=0.0029, recon_loss=0.000955, kl_loss=1.95]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113269.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009553.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028481.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.527132416309314e-10/0.424532949924469\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126186.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044949.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  42%|     | 679/1600 [08:35<12:33,  1.22it/s, loss=0.00301, recon_loss=0.00106, kl_loss=1.95]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091459.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.38239457214695e-07/0.5095458030700684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120778.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075787.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040655.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  42%|     | 680/1600 [08:36<12:07,  1.27it/s, loss=0.00893, recon_loss=0.007, kl_loss=1.93]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.735584416768688e-07/0.46942996978759766\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080766.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104276.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  43%|     | 681/1600 [08:36<10:36,  1.44it/s, loss=0.00527, recon_loss=0.00328, kl_loss=1.99]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.9143005220742e-09/0.4051137864589691\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090526.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129923.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014578.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148130.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119726.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  43%|     | 682/1600 [08:37<11:14,  1.36it/s, loss=0.00325, recon_loss=0.00118, kl_loss=2.06]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.391326439787349e-10/0.4210559129714966\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006467.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128666.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048763.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  43%|     | 683/1600 [08:37<10:19,  1.48it/s, loss=0.00283, recon_loss=0.000723, kl_loss=2.11]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.962440236511156e-09/0.44855034351348877\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124753.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056888.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137211.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072738.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024365.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027197.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010693.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  43%|     | 684/1600 [08:39<12:58,  1.18it/s, loss=0.0032, recon_loss=0.00109, kl_loss=2.11]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.868758369218739e-10/0.4757464528083801\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080516.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144171.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  43%|     | 685/1600 [08:39<11:06,  1.37it/s, loss=0.00687, recon_loss=0.00478, kl_loss=2.08]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.9253752753533036e-09/0.43631285429000854\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056029.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135028.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  43%|     | 686/1600 [08:40<09:43,  1.57it/s, loss=0.00374, recon_loss=0.00164, kl_loss=2.1]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108845.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.8600591339689174e-10/0.4995255768299103\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/079/079087.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116881.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145758.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027856.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048864.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/078/078516.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059671.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  43%|     | 688/1600 [08:41<09:53,  1.54it/s, loss=0.00263, recon_loss=0.000387, kl_loss=2.24]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.0673430375521837e-12/0.3379058837890625\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087101.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064592.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127302.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0461385924198652e-10/0.4232901930809021\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111747.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  43%|     | 689/1600 [08:42<10:02,  1.51it/s, loss=0.00374, recon_loss=0.00141, kl_loss=2.33]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098620.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055715.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136708.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5964927158051978e-08/0.4484238624572754\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032689.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126425.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117632.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116707.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083960.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  43%|     | 690/1600 [08:43<13:09,  1.15it/s, loss=0.00377, recon_loss=0.00138, kl_loss=2.39]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.2090389240059238e-10/0.45021557807922363\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046718.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038829.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  43%|     | 691/1600 [08:44<11:21,  1.33it/s, loss=0.00493, recon_loss=0.00252, kl_loss=2.41]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.152389383918262e-08/0.37603676319122314\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045389.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087192.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  43%|     | 692/1600 [08:44<09:57,  1.52it/s, loss=0.00323, recon_loss=0.000794, kl_loss=2.43]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.282613235735312e-10/0.47695785760879517\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148510.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107910.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121651.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011671.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114534.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074384.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  43%|     | 693/1600 [08:45<11:32,  1.31it/s, loss=0.00568, recon_loss=0.00328, kl_loss=2.41]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098622.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.829505962864687e-09/0.4428452253341675\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116736.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117170.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044802.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115470.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  43%|     | 694/1600 [08:46<12:07,  1.24it/s, loss=0.00378, recon_loss=0.00139, kl_loss=2.39]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145710.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.091470108211979e-08/0.4331825375556946\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/020/020372.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/034/034167.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  43%|     | 695/1600 [08:47<11:19,  1.33it/s, loss=0.00372, recon_loss=0.00137, kl_loss=2.35]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027455.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.072643747387588e-10/0.410645991563797\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116383.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  44%|     | 696/1600 [08:47<09:53,  1.52it/s, loss=0.00288, recon_loss=0.000596, kl_loss=2.28]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066638.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144467.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 9.552080371122429e-08/0.4639620780944824\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129620.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104725.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093918.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135341.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124509.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/050/050323.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  44%|     | 697/1600 [08:48<12:59,  1.16it/s, loss=0.00644, recon_loss=0.00426, kl_loss=2.18]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108477.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.896543615018345e-08/0.4917331635951996\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/147/147191.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  44%|     | 698/1600 [08:49<11:05,  1.35it/s, loss=0.00575, recon_loss=0.00362, kl_loss=2.14]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003762.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2311836883327487e-07/0.4574178159236908\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105716.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099135.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108525.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071254.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026016.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  44%|     | 699/1600 [08:50<12:48,  1.17it/s, loss=0.00617, recon_loss=0.00404, kl_loss=2.12]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.2488608197868132e-11/0.3775345981121063\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108491.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052375.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  44%|     | 700/1600 [08:50<10:53,  1.38it/s, loss=0.00274, recon_loss=0.000592, kl_loss=2.15]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113972.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7704280708130682e-08/0.4867246150970459\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064990.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122645.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017637.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062742.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  44%|     | 701/1600 [08:51<11:46,  1.27it/s, loss=0.00469, recon_loss=0.00256, kl_loss=2.13]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.3852229080745246e-09/0.4449629485607147\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133440.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082505.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  44%|     | 702/1600 [08:52<10:16,  1.46it/s, loss=0.00468, recon_loss=0.00257, kl_loss=2.12]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.02983074979602e-08/0.464046448469162\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124915.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011933.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021995.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138063.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044110.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124876.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  44%|     | 703/1600 [08:53<12:06,  1.23it/s, loss=0.00443, recon_loss=0.00232, kl_loss=2.11]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098553.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2778157872095353e-11/0.38618478178977966\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006448.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148132.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  44%|     | 704/1600 [08:53<10:42,  1.39it/s, loss=0.00258, recon_loss=0.000481, kl_loss=2.1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.6380152496361404e-10/0.3792317807674408\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119828.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144550.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  44%|     | 705/1600 [08:54<09:24,  1.58it/s, loss=0.00265, recon_loss=0.000604, kl_loss=2.04]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072146.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.12988568396122e-09/0.4061504602432251\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107659.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146689.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  44%|     | 706/1600 [08:54<08:56,  1.67it/s, loss=0.00318, recon_loss=0.00122, kl_loss=1.96]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098577.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093950.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111226.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137484.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.128119206001315e-10/0.4378490746021271\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135339.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120299.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  44%|     | 707/1600 [08:55<09:52,  1.51it/s, loss=0.00408, recon_loss=0.00221, kl_loss=1.86]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092540.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.073538728555093e-10/0.46205174922943115\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/050/050447.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055709.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116029.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142091.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  44%|     | 708/1600 [08:56<10:41,  1.39it/s, loss=0.00351, recon_loss=0.00173, kl_loss=1.78]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033424.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0351325130386613e-07/0.45647549629211426\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029272.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075427.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140871.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139681.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  44%|     | 709/1600 [08:57<11:43,  1.27it/s, loss=0.00338, recon_loss=0.00168, kl_loss=1.7]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.214247060323032e-09/0.43205076456069946\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042029.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132965.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  44%|     | 710/1600 [08:57<10:15,  1.45it/s, loss=0.00407, recon_loss=0.00245, kl_loss=1.62]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027799.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097586.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.7374413419953854e-11/0.4637458324432373\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/039/039488.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124756.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131925.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073566.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125825.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  44%|     | 711/1600 [08:59<13:00,  1.14it/s, loss=0.00295, recon_loss=0.00139, kl_loss=1.56]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.393023335045541e-09/0.3936367928981781\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112768.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087108.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  44%|     | 712/1600 [08:59<10:59,  1.35it/s, loss=0.00216, recon_loss=0.000673, kl_loss=1.49]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/039/039659.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2081956768383861e-08/0.34070074558258057\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026025.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049479.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143056.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  45%|     | 713/1600 [09:00<11:12,  1.32it/s, loss=0.00195, recon_loss=0.000539, kl_loss=1.41]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071719.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.066618597420302e-09/0.4360989034175873\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125622.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109896.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073371.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006675.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  45%|     | 714/1600 [09:01<11:58,  1.23it/s, loss=0.00298, recon_loss=0.00166, kl_loss=1.32]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.942492360880067e-10/0.49567940831184387\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104062.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043027.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059673.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069985.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  45%|     | 715/1600 [09:02<11:47,  1.25it/s, loss=0.00392, recon_loss=0.00268, kl_loss=1.24]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.294980732704289e-09/0.483538419008255\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048466.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124231.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  45%|     | 716/1600 [09:02<10:35,  1.39it/s, loss=0.00393, recon_loss=0.00276, kl_loss=1.18]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.3685502128500957e-06/0.4668269157409668\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019889.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051269.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069195.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  45%|     | 717/1600 [09:03<09:43,  1.51it/s, loss=0.00796, recon_loss=0.00682, kl_loss=1.14]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.305568929690139e-09/0.4940245449542999\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106951.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113266.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026298.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063191.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019423.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144466.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  45%|     | 718/1600 [09:04<11:34,  1.27it/s, loss=0.00582, recon_loss=0.00467, kl_loss=1.15]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091869.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011683.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069207.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046043.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124485.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  45%|     | 719/1600 [09:05<12:21,  1.19it/s, loss=0.00247, recon_loss=0.00126, kl_loss=1.21]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.002865509697642e-10/0.4020082652568817\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093921.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129914.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.8888972164177176e-08/0.40618008375167847\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027975.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114296.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  45%|     | 720/1600 [09:06<12:19,  1.19it/s, loss=0.00229, recon_loss=0.00103, kl_loss=1.26]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056640.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028482.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0122588323113746e-09/0.43091851472854614\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069564.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043600.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  45%|     | 721/1600 [09:06<12:19,  1.19it/s, loss=0.00318, recon_loss=0.00189, kl_loss=1.29]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.659045060156132e-13/0.476815789937973\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141137.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064591.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125298.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052649.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  45%|     | 722/1600 [09:07<12:09,  1.20it/s, loss=0.00254, recon_loss=0.00122, kl_loss=1.31]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.8517399835715764e-09/0.395204097032547\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/100/100745.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098626.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  45%|     | 723/1600 [09:08<10:17,  1.42it/s, loss=0.0023, recon_loss=0.000971, kl_loss=1.32]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.4612058047732717e-08/0.4892674386501312\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094035.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055102.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069823.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  45%|     | 724/1600 [09:08<09:33,  1.53it/s, loss=0.00609, recon_loss=0.00477, kl_loss=1.32]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121474.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136995.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123978.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097585.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121737.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/016/016878.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0636382512529963e-06/0.4498607814311981\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010389.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014576.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  45%|     | 725/1600 [09:10<12:38,  1.15it/s, loss=0.00507, recon_loss=0.00372, kl_loss=1.35]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044804.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.074883291378285e-10/0.4176656901836395\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086680.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  45%|     | 726/1600 [09:10<10:47,  1.35it/s, loss=0.00214, recon_loss=0.000738, kl_loss=1.41]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.8692087994386384e-07/0.4458152651786804\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040121.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072069.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  45%|     | 727/1600 [09:10<09:34,  1.52it/s, loss=0.0042, recon_loss=0.00276, kl_loss=1.44]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097590.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063159.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.10739662773085e-07/0.3847508132457733\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112252.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006778.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105671.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/147/147269.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  46%|     | 728/1600 [09:12<11:20,  1.28it/s, loss=0.00267, recon_loss=0.0012, kl_loss=1.47]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.52782148335973e-08/0.4700329601764679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108478.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062445.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040180.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028608.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051117.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  46%|     | 729/1600 [09:12<12:06,  1.20it/s, loss=0.00453, recon_loss=0.00304, kl_loss=1.49]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082931.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.913560390842122e-09/0.4658966362476349\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070302.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056469.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110681.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  46%|     | 731/1600 [09:13<08:59,  1.61it/s, loss=0.00557, recon_loss=0.00401, kl_loss=1.56]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6220857901316776e-07/0.4832693040370941\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115262.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112528.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129882.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075391.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142402.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0005484218922334e-09/0.4397321045398712\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/031/031807.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013804.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  46%|     | 732/1600 [09:14<10:59,  1.32it/s, loss=0.00351, recon_loss=0.00188, kl_loss=1.63]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004103.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.6094401306409054e-08/0.4491405189037323\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055076.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123461.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040182.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122399.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033064.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  46%|     | 733/1600 [09:16<12:32,  1.15it/s, loss=0.00469, recon_loss=0.00301, kl_loss=1.68]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.5982669621681396e-10/0.42758896946907043\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141877.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/058/058068.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  46%|     | 734/1600 [09:16<10:55,  1.32it/s, loss=0.00233, recon_loss=0.000589, kl_loss=1.75]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054150.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.694979135686726e-11/0.41228947043418884\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063755.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125196.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  46%|     | 735/1600 [09:17<10:34,  1.36it/s, loss=0.00229, recon_loss=0.000517, kl_loss=1.77]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012047.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012050.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019420.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062534.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  46%|     | 736/1600 [09:17<10:26,  1.38it/s, loss=0.00534, recon_loss=0.00358, kl_loss=1.77]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.1123088812564674e-09/0.46626514196395874\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125779.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.823237737342721e-12/0.3451727330684662\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089447.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062532.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085491.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123468.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115002.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107533.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  46%|     | 737/1600 [09:19<12:41,  1.13it/s, loss=0.00199, recon_loss=0.000212, kl_loss=1.78]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/037/037111.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112770.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.370455937736551e-07/0.413673996925354\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138060.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  46%|     | 738/1600 [09:19<11:56,  1.20it/s, loss=0.00371, recon_loss=0.00196, kl_loss=1.76]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4113860080655627e-09/0.38409969210624695\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088874.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108012.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  46%|     | 739/1600 [09:20<10:12,  1.41it/s, loss=0.00269, recon_loss=0.000959, kl_loss=1.73]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117627.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.789850933078043e-10/0.4777907431125641\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120329.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143318.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004066.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105917.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043517.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  46%|     | 740/1600 [09:21<11:50,  1.21it/s, loss=0.00336, recon_loss=0.00167, kl_loss=1.69]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139936.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106339.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.2149739698515987e-08/0.4185963273048401\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106954.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063803.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  46%|     | 741/1600 [09:22<11:31,  1.24it/s, loss=0.00286, recon_loss=0.00122, kl_loss=1.64]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/018/018033.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.785282170516325e-10/0.43987131118774414\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052631.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134933.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  46%|     | 742/1600 [09:22<10:32,  1.36it/s, loss=0.0032, recon_loss=0.00162, kl_loss=1.58]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074386.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044946.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.8491970378327096e-08/0.40905386209487915\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024371.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056497.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047202.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  46%|     | 743/1600 [09:23<11:43,  1.22it/s, loss=0.00287, recon_loss=0.00136, kl_loss=1.52]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131939.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/061/061587.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 3.323359643037094e-11/0.38814038038253784\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/034/034263.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090804.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  46%|     | 744/1600 [09:24<11:34,  1.23it/s, loss=0.00195, recon_loss=0.000499, kl_loss=1.45]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073342.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.4609042621223125e-08/0.42527875304222107\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000193.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035198.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122799.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114294.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  47%|     | 745/1600 [09:25<11:58,  1.19it/s, loss=0.00275, recon_loss=0.00138, kl_loss=1.37]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144943.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.601765522087135e-09/0.49704551696777344\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081895.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  47%|     | 746/1600 [09:26<10:28,  1.36it/s, loss=0.00761, recon_loss=0.00632, kl_loss=1.29]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075420.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.8394104562300413e-10/0.4217678904533386\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125189.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131789.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136321.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142535.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109448.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  47%|     | 747/1600 [09:27<12:13,  1.16it/s, loss=0.00309, recon_loss=0.00182, kl_loss=1.27]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.876406052758739e-08/0.4829959571361542\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053379.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/154/154309.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  47%|     | 748/1600 [09:27<10:19,  1.38it/s, loss=0.00542, recon_loss=0.00416, kl_loss=1.25]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092874.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3183520941595361e-09/0.45929548144340515\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145609.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  47%|     | 749/1600 [09:28<09:30,  1.49it/s, loss=0.00254, recon_loss=0.00128, kl_loss=1.26]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026021.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083903.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069792.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063908.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109974.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071620.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.779829084114226e-08/0.4966053366661072\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094101.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087642.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  47%|     | 750/1600 [09:29<12:25,  1.14it/s, loss=0.0055, recon_loss=0.00423, kl_loss=1.27]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116466.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069833.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0082583773728402e-07/0.5000215768814087\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054019.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  47%|     | 751/1600 [09:30<11:38,  1.22it/s, loss=0.00789, recon_loss=0.00658, kl_loss=1.31]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111994.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.254220614148153e-09/0.44832006096839905\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047835.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  47%|     | 752/1600 [09:30<10:07,  1.40it/s, loss=0.00305, recon_loss=0.00165, kl_loss=1.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117171.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056691.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115321.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7106543737099855e-08/0.4663814306259155\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088864.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138210.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  47%|     | 753/1600 [09:31<11:05,  1.27it/s, loss=0.00425, recon_loss=0.00277, kl_loss=1.48]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115592.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032435.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141287.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122190.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117612.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.294319037676189e-10/0.38916388154029846\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067007.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  47%|     | 754/1600 [09:32<12:46,  1.10it/s, loss=0.00221, recon_loss=0.000646, kl_loss=1.57]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1539881272781827e-09/0.4240248501300812\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124175.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006439.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  47%|     | 756/1600 [09:33<08:11,  1.72it/s, loss=0.00206, recon_loss=0.000401, kl_loss=1.66]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.812438890253404e-11/0.3992220461368561\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/022/022472.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129040.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006393.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003535.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069204.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116455.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003766.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0100956987789687e-07/0.4492213726043701\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064567.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036371.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059660.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053723.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  47%|     | 758/1600 [09:35<09:59,  1.40it/s, loss=0.00401, recon_loss=0.00234, kl_loss=1.68]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0547780366086954e-08/0.4699552357196808\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.575160434365898e-08/0.4463042914867401\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122153.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098228.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085426.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064252.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  47%|     | 759/1600 [09:36<10:32,  1.33it/s, loss=0.00409, recon_loss=0.00239, kl_loss=1.7]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105824.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090592.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007548.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097988.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069726.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.833970889186247e-11/0.41573548316955566\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/152/152254.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  48%|     | 760/1600 [09:37<12:01,  1.16it/s, loss=0.00308, recon_loss=0.00135, kl_loss=1.73]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141143.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.099688697527085e-10/0.3552197515964508\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068541.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094423.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089486.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  48%|     | 761/1600 [09:37<11:20,  1.23it/s, loss=0.00212, recon_loss=0.00037, kl_loss=1.75]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.789893625645804e-13/0.4059508144855499\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/095/095248.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/050/050539.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  48%|     | 762/1600 [09:38<09:48,  1.42it/s, loss=0.00254, recon_loss=0.000815, kl_loss=1.73]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003722.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/020/020365.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010458.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.068243212948744e-11/0.42730724811553955\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109068.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/076/076128.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075782.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009888.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  48%|     | 763/1600 [09:39<12:19,  1.13it/s, loss=0.00287, recon_loss=0.00119, kl_loss=1.68]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057891.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5413054166302231e-10/0.4300305247306824\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060478.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  48%|     | 764/1600 [09:40<10:26,  1.33it/s, loss=0.00295, recon_loss=0.00132, kl_loss=1.63]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.041554478919409e-10/0.4844258427619934\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116882.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052633.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  48%|     | 765/1600 [09:40<09:05,  1.53it/s, loss=0.00444, recon_loss=0.00287, kl_loss=1.57]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0413273293939938e-09/0.4566890299320221\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129889.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149701.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040231.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  48%|     | 766/1600 [09:41<09:12,  1.51it/s, loss=0.00349, recon_loss=0.00196, kl_loss=1.52]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067412.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000690.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116390.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/008/008345.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064538.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110636.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012482.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.475363210385222e-12/0.4623211622238159\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038352.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098617.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  48%|     | 767/1600 [09:42<12:23,  1.12it/s, loss=0.00242, recon_loss=0.000931, kl_loss=1.48]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/018/018197.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.9367822890490345e-10/0.386281818151474\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000890.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  48%|     | 768/1600 [09:43<10:28,  1.32it/s, loss=0.00219, recon_loss=0.000756, kl_loss=1.43]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.215018962859917e-12/0.4586583077907562\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070775.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043023.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  48%|     | 769/1600 [09:43<09:05,  1.52it/s, loss=0.00329, recon_loss=0.00191, kl_loss=1.37]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5476361170385644e-07/0.45058467984199524\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080035.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136276.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057437.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064007.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006333.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/039/039316.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067765.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/050/050448.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  48%|     | 771/1600 [09:44<08:30,  1.62it/s, loss=0.00437, recon_loss=0.00309, kl_loss=1.28]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3810641519285127e-08/0.45489004254341125\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099362.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055237.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080755.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145917.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073467.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.6496523964378866e-08/0.4330005943775177\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012351.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139523.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073572.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  48%|     | 772/1600 [09:46<11:49,  1.17it/s, loss=0.003, recon_loss=0.00174, kl_loss=1.26]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113020.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011787.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.0123437905492665e-09/0.4834171235561371\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  48%|     | 773/1600 [09:46<10:16,  1.34it/s, loss=0.00552, recon_loss=0.00428, kl_loss=1.24]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.881129555047494e-10/0.43972864747047424\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086481.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014690.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  48%|     | 774/1600 [09:47<09:14,  1.49it/s, loss=0.0033, recon_loss=0.00205, kl_loss=1.26]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118972.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/020/020704.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/039/039359.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130993.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.316937221726107e-10/0.46054548025131226\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056247.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116880.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120775.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  48%|     | 775/1600 [09:48<11:22,  1.21it/s, loss=0.00202, recon_loss=0.000745, kl_loss=1.27]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105920.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.615755492906828e-08/0.4224250018596649\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130758.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  48%|     | 776/1600 [09:49<10:06,  1.36it/s, loss=0.0023, recon_loss=0.00102, kl_loss=1.27]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071513.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139123.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072046.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123094.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.07314363617661e-07/0.4501294195652008\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/065/065037.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099389.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106277.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  49%|     | 777/1600 [09:50<12:55,  1.06it/s, loss=0.00325, recon_loss=0.00199, kl_loss=1.26]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119893.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.968023693483701e-07/0.42996343970298767\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090530.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051992.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  49%|     | 778/1600 [09:51<11:47,  1.16it/s, loss=0.00372, recon_loss=0.00247, kl_loss=1.25]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047666.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.529272512598936e-09/0.381420761346817\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064093.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118196.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055238.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  49%|     | 779/1600 [09:51<11:40,  1.17it/s, loss=0.00207, recon_loss=0.000823, kl_loss=1.25]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119897.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6559104665248014e-07/0.4764861464500427\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045474.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134054.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130921.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  49%|     | 780/1600 [09:52<11:45,  1.16it/s, loss=0.00428, recon_loss=0.00304, kl_loss=1.23]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055809.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1109524411523353e-09/0.37158140540122986\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046733.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096698.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059725.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  49%|     | 781/1600 [09:53<11:52,  1.15it/s, loss=0.00159, recon_loss=0.000358, kl_loss=1.23]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.927965389673773e-07/0.4195932149887085\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091102.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112785.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  49%|     | 782/1600 [09:54<09:57,  1.37it/s, loss=0.00387, recon_loss=0.00265, kl_loss=1.21]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.536440746325752e-08/0.485980361700058\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013566.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136466.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014569.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126506.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146725.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108499.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042761.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  49%|     | 783/1600 [09:55<12:07,  1.12it/s, loss=0.00484, recon_loss=0.00364, kl_loss=1.21]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127278.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.4983502206209494e-11/0.3745203912258148\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092535.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  49%|     | 784/1600 [09:55<10:22,  1.31it/s, loss=0.00201, recon_loss=0.000783, kl_loss=1.22]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137173.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.603637636715121e-09/0.41290637850761414\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017499.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038830.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040236.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142092.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094467.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  49%|     | 785/1600 [09:57<12:02,  1.13it/s, loss=0.00208, recon_loss=0.000858, kl_loss=1.22]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089376.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.697666975005959e-11/0.4436701536178589\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131911.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  49%|     | 786/1600 [09:57<10:14,  1.32it/s, loss=0.00341, recon_loss=0.0022, kl_loss=1.21]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012387.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.791018059473572e-07/0.5028577446937561\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062007.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140874.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040161.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  49%|     | 787/1600 [09:58<10:08,  1.34it/s, loss=0.00977, recon_loss=0.00856, kl_loss=1.21]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0007934198318367e-10/0.44467276334762573\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072513.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091185.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001735.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  49%|     | 788/1600 [09:58<08:59,  1.51it/s, loss=0.0029, recon_loss=0.00161, kl_loss=1.3]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085489.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7374208738374364e-09/0.47444623708724976\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069182.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029045.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/039/039318.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  49%|     | 789/1600 [09:59<08:48,  1.53it/s, loss=0.00695, recon_loss=0.00557, kl_loss=1.37]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.52419649626745e-08/0.4941460192203522\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114049.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098552.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123979.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  49%|     | 790/1600 [09:59<08:16,  1.63it/s, loss=0.00716, recon_loss=0.00567, kl_loss=1.5]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099134.mp3: Failed to open the input \"/content/drive/MyDrive/DL4AM_datasets/fma_small/099/099134.mp3\" (Invalid argument).\n",
            "Exception raised from get_input_format_context at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_reader/stream_reader.cpp:42 (most recent call first):\n",
            "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x79bfa736c1b6 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\n",
            "frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x79bfa7315a76 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\n",
            "frame #2: <unknown function> + 0x42034 (0x79bfa72a8034 in /usr/local/lib/python3.11/dist-packages/torio/lib/libtorio_ffmpeg4.so)\n",
            "frame #3: torio::io::StreamingMediaDecoder::StreamingMediaDecoder(std::string const&, std::optional<std::string> const&, std::optional<std::map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<std::string const, std::string> > > > const&) + 0x14 (0x79bfa72aaa34 in /usr/local/lib/python3.11/dist-packages/torio/lib/libtorio_ffmpeg4.so)\n",
            "frame #4: <unknown function> + 0x3bfee (0x79be7af58fee in /usr/local/lib/python3.11/dist-packages/torio/lib/_torio_ffmpeg4.so)\n",
            "frame #5: <unknown function> + 0x330c7 (0x79be7af500c7 in /usr/local/lib/python3.11/dist-packages/torio/lib/_torio_ffmpeg4.so)\n",
            "frame #6: /usr/bin/python3() [0x55560b]\n",
            "frame #7: _PyObject_MakeTpCall + 0x27c (0x52f6dc in /usr/bin/python3)\n",
            "frame #8: /usr/bin/python3() [0x5853fd]\n",
            "frame #9: /usr/bin/python3() [0x56e2a9]\n",
            "frame #10: /usr/bin/python3() [0x52fac0]\n",
            "frame #11: <unknown function> + 0xfc6b (0x79bfa7751c6b in /usr/local/lib/python3.11/dist-packages/torchaudio/lib/_torchaudio.so)\n",
            "frame #12: _PyObject_MakeTpCall + 0x27c (0x52f6dc in /usr/bin/python3)\n",
            "frame #13: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #14: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #15: /usr/bin/python3() [0x56df36]\n",
            "frame #16: _PyObject_MakeTpCall + 0x23b (0x52f69b in /usr/bin/python3)\n",
            "frame #17: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #18: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #19: _PyEval_EvalFrameDefault + 0x4aab (0x541c5b in /usr/bin/python3)\n",
            "frame #20: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #21: /usr/bin/python3() [0x56df36]\n",
            "frame #22: _PyObject_MakeTpCall + 0x23b (0x52f69b in /usr/bin/python3)\n",
            "frame #23: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #24: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #25: /usr/bin/python3() [0x56df36]\n",
            "frame #26: _PyObject_MakeTpCall + 0x23b (0x52f69b in /usr/bin/python3)\n",
            "frame #27: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #28: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #29: PyObject_CallOneArg + 0x47 (0x56bde7 in /usr/bin/python3)\n",
            "frame #30: /usr/bin/python3() [0x6566fd]\n",
            "frame #31: PyObject_GetIter + 0x18 (0x52c1a8 in /usr/bin/python3)\n",
            "frame #32: _PyEval_EvalFrameDefault + 0x232a (0x53f4da in /usr/bin/python3)\n",
            "frame #33: /usr/bin/python3() [0x583367]\n",
            "frame #34: /usr/bin/python3() [0x5b95f5]\n",
            "frame #35: _PyEval_EvalFrameDefault + 0x549 (0x53d6f9 in /usr/bin/python3)\n",
            "frame #36: /usr/bin/python3() [0x613a24]\n",
            "frame #37: PyEval_EvalCode + 0x97 (0x613087 in /usr/bin/python3)\n",
            "frame #38: /usr/bin/python3() [0x62cde3]\n",
            "frame #39: _PyEval_EvalFrameDefault + 0x3801 (0x5409b1 in /usr/bin/python3)\n",
            "frame #40: /usr/bin/python3() [0x6288d0]\n",
            "frame #41: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #42: /usr/bin/python3() [0x6288d0]\n",
            "frame #43: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #44: /usr/bin/python3() [0x6288d0]\n",
            "frame #45: /usr/bin/python3() [0x62ae9c]\n",
            "frame #46: _PyEval_EvalFrameDefault + 0x3a8a (0x540c3a in /usr/bin/python3)\n",
            "frame #47: /usr/bin/python3() [0x585b17]\n",
            "frame #48: /usr/bin/python3() [0x5852fe]\n",
            "frame #49: PyObject_Call + 0xf4 (0x570784 in /usr/bin/python3)\n",
            "frame #50: _PyEval_EvalFrameDefault + 0x4aab (0x541c5b in /usr/bin/python3)\n",
            "frame #51: /usr/bin/python3() [0x6288d0]\n",
            "frame #52: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #53: /usr/bin/python3() [0x6288d0]\n",
            "frame #54: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #55: /usr/bin/python3() [0x6288d0]\n",
            "frame #56: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #57: /usr/bin/python3() [0x6288d0]\n",
            "frame #58: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #59: /usr/bin/python3() [0x6288d0]\n",
            "frame #60: <unknown function> + 0x745f (0x79c037bfa45f in /usr/lib/python3.11/lib-dynload/_asyncio.cpython-311-x86_64-linux-gnu.so)\n",
            "frame #61: /usr/bin/python3() [0x553a8f]\n",
            "frame #62: /usr/bin/python3() [0x4d0cb0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.8061282464353354e-11/0.4102681577205658\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118068.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105412.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108925.mp3: Failed to open the input \"/content/drive/MyDrive/DL4AM_datasets/fma_small/108/108925.mp3\" (Invalid argument).\n",
            "Exception raised from get_input_format_context at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_reader/stream_reader.cpp:42 (most recent call first):\n",
            "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x79bfa736c1b6 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\n",
            "frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x79bfa7315a76 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\n",
            "frame #2: <unknown function> + 0x42034 (0x79bfa72a8034 in /usr/local/lib/python3.11/dist-packages/torio/lib/libtorio_ffmpeg4.so)\n",
            "frame #3: torio::io::StreamingMediaDecoder::StreamingMediaDecoder(std::string const&, std::optional<std::string> const&, std::optional<std::map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<std::string const, std::string> > > > const&) + 0x14 (0x79bfa72aaa34 in /usr/local/lib/python3.11/dist-packages/torio/lib/libtorio_ffmpeg4.so)\n",
            "frame #4: <unknown function> + 0x3bfee (0x79be7af58fee in /usr/local/lib/python3.11/dist-packages/torio/lib/_torio_ffmpeg4.so)\n",
            "frame #5: <unknown function> + 0x330c7 (0x79be7af500c7 in /usr/local/lib/python3.11/dist-packages/torio/lib/_torio_ffmpeg4.so)\n",
            "frame #6: /usr/bin/python3() [0x55560b]\n",
            "frame #7: _PyObject_MakeTpCall + 0x27c (0x52f6dc in /usr/bin/python3)\n",
            "frame #8: /usr/bin/python3() [0x5853fd]\n",
            "frame #9: /usr/bin/python3() [0x56e2a9]\n",
            "frame #10: /usr/bin/python3() [0x52fac0]\n",
            "frame #11: <unknown function> + 0xfc6b (0x79bfa7751c6b in /usr/local/lib/python3.11/dist-packages/torchaudio/lib/_torchaudio.so)\n",
            "frame #12: _PyObject_MakeTpCall + 0x27c (0x52f6dc in /usr/bin/python3)\n",
            "frame #13: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #14: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #15: /usr/bin/python3() [0x56df36]\n",
            "frame #16: _PyObject_MakeTpCall + 0x23b (0x52f69b in /usr/bin/python3)\n",
            "frame #17: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #18: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #19: _PyEval_EvalFrameDefault + 0x4aab (0x541c5b in /usr/bin/python3)\n",
            "frame #20: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #21: /usr/bin/python3() [0x56df36]\n",
            "frame #22: _PyObject_MakeTpCall + 0x23b (0x52f69b in /usr/bin/python3)\n",
            "frame #23: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #24: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #25: /usr/bin/python3() [0x56df36]\n",
            "frame #26: _PyObject_MakeTpCall + 0x23b (0x52f69b in /usr/bin/python3)\n",
            "frame #27: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #28: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #29: PyObject_CallOneArg + 0x47 (0x56bde7 in /usr/bin/python3)\n",
            "frame #30: /usr/bin/python3() [0x6566fd]\n",
            "frame #31: PyObject_GetIter + 0x18 (0x52c1a8 in /usr/bin/python3)\n",
            "frame #32: _PyEval_EvalFrameDefault + 0x232a (0x53f4da in /usr/bin/python3)\n",
            "frame #33: /usr/bin/python3() [0x583367]\n",
            "frame #34: /usr/bin/python3() [0x5b95f5]\n",
            "frame #35: _PyEval_EvalFrameDefault + 0x549 (0x53d6f9 in /usr/bin/python3)\n",
            "frame #36: /usr/bin/python3() [0x613a24]\n",
            "frame #37: PyEval_EvalCode + 0x97 (0x613087 in /usr/bin/python3)\n",
            "frame #38: /usr/bin/python3() [0x62cde3]\n",
            "frame #39: _PyEval_EvalFrameDefault + 0x3801 (0x5409b1 in /usr/bin/python3)\n",
            "frame #40: /usr/bin/python3() [0x6288d0]\n",
            "frame #41: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #42: /usr/bin/python3() [0x6288d0]\n",
            "frame #43: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #44: /usr/bin/python3() [0x6288d0]\n",
            "frame #45: /usr/bin/python3() [0x62ae9c]\n",
            "frame #46: _PyEval_EvalFrameDefault + 0x3a8a (0x540c3a in /usr/bin/python3)\n",
            "frame #47: /usr/bin/python3() [0x585b17]\n",
            "frame #48: /usr/bin/python3() [0x5852fe]\n",
            "frame #49: PyObject_Call + 0xf4 (0x570784 in /usr/bin/python3)\n",
            "frame #50: _PyEval_EvalFrameDefault + 0x4aab (0x541c5b in /usr/bin/python3)\n",
            "frame #51: /usr/bin/python3() [0x6288d0]\n",
            "frame #52: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #53: /usr/bin/python3() [0x6288d0]\n",
            "frame #54: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #55: /usr/bin/python3() [0x6288d0]\n",
            "frame #56: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #57: /usr/bin/python3() [0x6288d0]\n",
            "frame #58: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #59: /usr/bin/python3() [0x6288d0]\n",
            "frame #60: <unknown function> + 0x745f (0x79c037bfa45f in /usr/lib/python3.11/lib-dynload/_asyncio.cpython-311-x86_64-linux-gnu.so)\n",
            "frame #61: /usr/bin/python3() [0x553a8f]\n",
            "frame #62: /usr/bin/python3() [0x4d0cb0]\n",
            "\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032525.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114239.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131918.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000821.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  49%|     | 791/1600 [10:00<10:04,  1.34it/s, loss=0.00275, recon_loss=0.00108, kl_loss=1.67]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027945.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.300803183176498e-11/0.32885172963142395\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134446.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  50%|     | 792/1600 [10:01<08:59,  1.50it/s, loss=0.00199, recon_loss=0.000173, kl_loss=1.81]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/034/034147.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.172561673954078e-08/0.3802300691604614\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042984.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019441.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  50%|     | 793/1600 [10:01<08:40,  1.55it/s, loss=0.00268, recon_loss=0.000766, kl_loss=1.92]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/061/061013.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013768.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/058/058212.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134794.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.092148119307694e-09/0.4237782061100006\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118499.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019417.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019422.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  50%|     | 794/1600 [10:03<11:07,  1.21it/s, loss=0.00298, recon_loss=0.001, kl_loss=1.98]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117173.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6765078214575624e-10/0.46317633986473083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130931.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  50%|     | 795/1600 [10:03<09:49,  1.37it/s, loss=0.00315, recon_loss=0.00114, kl_loss=2.01]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090589.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.421208732452442e-09/0.4561491012573242\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035299.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129096.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  50%|     | 796/1600 [10:04<09:23,  1.43it/s, loss=0.00446, recon_loss=0.00245, kl_loss=2.01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.499644463111906e-10/0.3874083459377289\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060146.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114064.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113272.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126229.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  50%|     | 797/1600 [10:05<09:29,  1.41it/s, loss=0.00267, recon_loss=0.000654, kl_loss=2.02]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123764.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.425099036671099e-09/0.4205424189567566\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014583.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  50%|     | 798/1600 [10:05<08:33,  1.56it/s, loss=0.00275, recon_loss=0.000763, kl_loss=1.99]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007490.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116236.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5023573496364406e-08/0.3787159025669098\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/022/022480.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116488.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149842.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  50%|     | 799/1600 [10:06<08:47,  1.52it/s, loss=0.00242, recon_loss=0.00049, kl_loss=1.93]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027551.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0441718670262112e-11/0.43090957403182983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021997.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137632.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070409.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010480.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141292.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141286.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126412.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  50%|     | 800/1600 [10:07<11:25,  1.17it/s, loss=0.0029, recon_loss=0.00106, kl_loss=1.84]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126409.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.259395088215598e-10/0.3115420937538147\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055717.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  50%|     | 801/1600 [10:08<09:52,  1.35it/s, loss=0.00196, recon_loss=0.000209, kl_loss=1.75]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/008/008416.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113530.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.456516240949668e-08/0.40615731477737427\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082242.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  50%|     | 802/1600 [10:08<09:27,  1.41it/s, loss=0.0034, recon_loss=0.00177, kl_loss=1.63]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027612.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075430.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127280.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051113.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2737999890988227e-11/0.4582688808441162\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064992.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126589.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126668.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  50%|     | 803/1600 [10:09<11:08,  1.19it/s, loss=0.00316, recon_loss=0.00163, kl_loss=1.53]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129042.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.0392436656256905e-07/0.40871337056159973\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087431.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  50%|     | 804/1600 [10:10<09:36,  1.38it/s, loss=0.00245, recon_loss=0.00101, kl_loss=1.44]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/023/023505.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7024225362760603e-09/0.4508395195007324\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013706.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131656.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  50%|     | 805/1600 [10:10<09:12,  1.44it/s, loss=0.00239, recon_loss=0.00105, kl_loss=1.34]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069744.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.985655888134488e-09/0.4894491136074066\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113264.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/015/015770.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/076/076071.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042048.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109670.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  50%|     | 806/1600 [10:11<10:11,  1.30it/s, loss=0.00566, recon_loss=0.00441, kl_loss=1.25]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.6417640297538014e-10/0.4093562662601471\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003779.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140621.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032331.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  50%|     | 807/1600 [10:12<09:43,  1.36it/s, loss=0.00175, recon_loss=0.000546, kl_loss=1.21]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140873.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092282.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045100.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126188.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.3300672155612823e-11/0.4541563093662262\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/022/022091.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033123.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  50%|     | 808/1600 [10:13<10:49,  1.22it/s, loss=0.00271, recon_loss=0.00156, kl_loss=1.15]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.9761269010043492e-10/0.46327483654022217\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044853.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060857.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  51%|     | 809/1600 [10:14<09:26,  1.40it/s, loss=0.00396, recon_loss=0.00287, kl_loss=1.1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.305663736658971e-08/0.39933401346206665\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091130.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038399.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  51%|     | 810/1600 [10:14<08:11,  1.61it/s, loss=0.00183, recon_loss=0.000764, kl_loss=1.07]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091183.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.18199773991546e-08/0.43175265192985535\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109973.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143319.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118087.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126055.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014869.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059445.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069208.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  51%|     | 811/1600 [10:15<10:43,  1.23it/s, loss=0.00255, recon_loss=0.00152, kl_loss=1.03]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118478.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.225712153996028e-08/0.4423730671405792\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117884.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056015.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  51%|     | 812/1600 [10:16<09:49,  1.34it/s, loss=0.00338, recon_loss=0.00238, kl_loss=0.994]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141972.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.804119058121614e-08/0.41397830843925476\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108492.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133970.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  51%|     | 813/1600 [10:16<09:31,  1.38it/s, loss=0.0019, recon_loss=0.000926, kl_loss=0.974]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052122.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.783028911149509e-12/0.38881421089172363\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090987.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113702.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  51%|     | 814/1600 [10:17<08:56,  1.47it/s, loss=0.00142, recon_loss=0.000475, kl_loss=0.949]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.123863801842263e-12/0.4414888620376587\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105141.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043593.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014733.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048450.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068896.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122534.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146988.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  51%|     | 815/1600 [10:18<11:06,  1.18it/s, loss=0.00313, recon_loss=0.00221, kl_loss=0.916]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2064962362501319e-08/0.46093839406967163\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099370.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141141.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  51%|     | 816/1600 [10:19<09:30,  1.37it/s, loss=0.00352, recon_loss=0.00263, kl_loss=0.892]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047192.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.387951196311747e-10/0.48946183919906616\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110104.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110980.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  51%|     | 817/1600 [10:19<09:04,  1.44it/s, loss=0.00894, recon_loss=0.00806, kl_loss=0.884]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.129807968349496e-09/0.47946441173553467\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029971.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127066.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/037/037731.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122475.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/065/065265.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  51%|     | 818/1600 [10:20<09:57,  1.31it/s, loss=0.0055, recon_loss=0.00457, kl_loss=0.927]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.790838919494945e-09/0.40738147497177124\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010807.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042235.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040238.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110774.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043518.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  51%|     | 819/1600 [10:21<10:33,  1.23it/s, loss=0.00184, recon_loss=0.000841, kl_loss=0.998]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/008/008256.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/015/015476.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006332.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.586276164924129e-08/0.41000279784202576\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121318.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  51%|    | 820/1600 [10:22<10:33,  1.23it/s, loss=0.00289, recon_loss=0.00184, kl_loss=1.06]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093944.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126411.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 9.922020982600088e-10/0.3986111581325531\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054623.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126605.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  51%|    | 821/1600 [10:23<10:43,  1.21it/s, loss=0.00161, recon_loss=0.000492, kl_loss=1.11]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114074.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.487530678280564e-10/0.3625647723674774\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108847.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056275.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094026.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  51%|    | 822/1600 [10:24<10:53,  1.19it/s, loss=0.00141, recon_loss=0.000264, kl_loss=1.15]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.837614196011145e-09/0.48129159212112427\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070773.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137423.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  51%|    | 823/1600 [10:24<09:29,  1.37it/s, loss=0.00602, recon_loss=0.00485, kl_loss=1.16]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.702714578452287e-07/0.47903504967689514\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028179.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059681.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123981.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144476.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115812.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  52%|    | 824/1600 [10:25<10:07,  1.28it/s, loss=0.00571, recon_loss=0.0045, kl_loss=1.21]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0943744577218695e-08/0.38858914375305176\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120109.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/037/037911.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135044.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110085.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132449.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  52%|    | 825/1600 [10:26<10:18,  1.25it/s, loss=0.0018, recon_loss=0.000524, kl_loss=1.28]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067361.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.682872997855675e-13/0.41753602027893066\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080693.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072135.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149700.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  52%|    | 826/1600 [10:27<10:28,  1.23it/s, loss=0.00232, recon_loss=0.000998, kl_loss=1.32]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086259.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.4812183691279586e-10/0.4140680730342865\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/037/037859.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038901.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126588.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  52%|    | 827/1600 [10:28<10:34,  1.22it/s, loss=0.00202, recon_loss=0.000666, kl_loss=1.35]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091160.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.1533434757525782e-12/0.4323183298110962\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073193.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  52%|    | 828/1600 [10:28<09:10,  1.40it/s, loss=0.00259, recon_loss=0.00123, kl_loss=1.36]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/037/037592.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091089.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098569.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.318069566470854e-10/0.47620341181755066\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142094.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114067.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146148.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  52%|    | 829/1600 [10:29<10:20,  1.24it/s, loss=0.00474, recon_loss=0.00339, kl_loss=1.36]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068601.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027198.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066469.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.0570942161366474e-09/0.3808014392852783\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  52%|    | 830/1600 [10:30<09:22,  1.37it/s, loss=0.00195, recon_loss=0.00058, kl_loss=1.37]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092466.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108505.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0301726832695479e-10/0.3624931573867798\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029042.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  52%|    | 831/1600 [10:30<08:52,  1.45it/s, loss=0.00173, recon_loss=0.000362, kl_loss=1.37]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060534.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107584.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.940737217244532e-08/0.46614161133766174\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/020/020818.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085952.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122623.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122359.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/065/065756.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  52%|    | 832/1600 [10:32<11:08,  1.15it/s, loss=0.00287, recon_loss=0.00152, kl_loss=1.35]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004848.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113165.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.337113056531507e-09/0.4341578483581543\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  52%|    | 833/1600 [10:32<09:43,  1.32it/s, loss=0.0025, recon_loss=0.00119, kl_loss=1.32]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126716.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044950.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5784640261529148e-09/0.4290398061275482\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056800.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  52%|    | 834/1600 [10:33<09:14,  1.38it/s, loss=0.00224, recon_loss=0.000953, kl_loss=1.28]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129925.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126292.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033068.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7034437194141105e-09/0.4096243679523468\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045515.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128477.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010485.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114415.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  52%|    | 835/1600 [10:34<11:14,  1.13it/s, loss=0.00199, recon_loss=0.000749, kl_loss=1.24]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081543.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6375126948853236e-11/0.4747532308101654\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038955.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  52%|    | 836/1600 [10:34<09:44,  1.31it/s, loss=0.00233, recon_loss=0.00113, kl_loss=1.19]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116454.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105714.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063149.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.732828448068439e-11/0.3961970806121826\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135225.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145043.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133453.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  52%|    | 837/1600 [10:36<11:11,  1.14it/s, loss=0.00189, recon_loss=0.000751, kl_loss=1.14]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107188.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075903.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.787390094409318e-10/0.3988989591598511\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  52%|    | 838/1600 [10:36<09:40,  1.31it/s, loss=0.00153, recon_loss=0.000453, kl_loss=1.08]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036258.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.282970618632362e-09/0.436152845621109\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093943.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124518.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  52%|    | 839/1600 [10:37<09:06,  1.39it/s, loss=0.0023, recon_loss=0.00128, kl_loss=1.01]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071243.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123273.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.460093653932631e-11/0.4698612689971924\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085966.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126430.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  52%|    | 840/1600 [10:37<08:51,  1.43it/s, loss=0.00281, recon_loss=0.00185, kl_loss=0.955]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.282172477194536e-10/0.5092838406562805\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000714.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105712.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105683.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  53%|    | 841/1600 [10:38<08:17,  1.53it/s, loss=0.0129, recon_loss=0.012, kl_loss=0.906]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071303.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113946.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134929.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116489.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029255.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.581505498255865e-07/0.5059713125228882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133632.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049849.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113787.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  53%|    | 842/1600 [10:39<11:00,  1.15it/s, loss=0.00784, recon_loss=0.00691, kl_loss=0.929]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.8882283231723704e-09/0.4871242344379425\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048462.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048808.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  53%|    | 843/1600 [10:40<09:23,  1.34it/s, loss=0.0046, recon_loss=0.0036, kl_loss=0.998]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/079/079741.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.028078289166956e-09/0.4315049648284912\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057820.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  53%|    | 844/1600 [10:40<08:14,  1.53it/s, loss=0.00239, recon_loss=0.00131, kl_loss=1.08]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059676.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114880.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.5436071027229445e-09/0.45676136016845703\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107595.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059656.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114223.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  53%|    | 845/1600 [10:41<08:50,  1.42it/s, loss=0.00321, recon_loss=0.00205, kl_loss=1.16]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/016/016895.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139862.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135340.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055719.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116879.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2967056595147852e-10/0.41171371936798096\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107804.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  53%|    | 846/1600 [10:42<10:23,  1.21it/s, loss=0.00189, recon_loss=0.000654, kl_loss=1.23]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107189.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2195605636478035e-09/0.4199594557285309\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137551.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122959.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  53%|    | 847/1600 [10:43<09:12,  1.36it/s, loss=0.00204, recon_loss=0.000753, kl_loss=1.29]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.788184458983437e-10/0.42249366641044617\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/025/025124.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/005/005268.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027609.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133731.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126557.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113335.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  53%|    | 848/1600 [10:44<10:55,  1.15it/s, loss=0.00238, recon_loss=0.00105, kl_loss=1.32]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.870280623237022e-09/0.4278741776943207\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149141.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138062.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  53%|    | 849/1600 [10:44<09:08,  1.37it/s, loss=0.00255, recon_loss=0.00121, kl_loss=1.34]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113564.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.928919216164786e-09/0.41422712802886963\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070423.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045102.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091086.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134941.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  53%|    | 850/1600 [10:45<10:00,  1.25it/s, loss=0.00217, recon_loss=0.000818, kl_loss=1.35]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110086.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073587.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.913016991130007e-10/0.467581570148468\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072059.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085956.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  53%|    | 851/1600 [10:46<10:02,  1.24it/s, loss=0.00332, recon_loss=0.00197, kl_loss=1.35]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091622.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097813.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.344765575619135e-10/0.33233699202537537\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126520.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075373.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  53%|    | 852/1600 [10:47<10:03,  1.24it/s, loss=0.00166, recon_loss=0.000314, kl_loss=1.34]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126294.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4411113413714816e-09/0.35795482993125916\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119922.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  53%|    | 853/1600 [10:47<08:32,  1.46it/s, loss=0.00186, recon_loss=0.000545, kl_loss=1.32]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133028.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127497.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017606.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2328021270491263e-08/0.35821613669395447\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044342.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128443.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092573.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  53%|    | 854/1600 [10:48<09:39,  1.29it/s, loss=0.00186, recon_loss=0.000581, kl_loss=1.28]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054874.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.111442481440463e-08/0.5020555257797241\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028260.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/078/078841.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072927.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  53%|    | 855/1600 [10:49<09:54,  1.25it/s, loss=0.0125, recon_loss=0.0113, kl_loss=1.23]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125826.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.0866380029692664e-07/0.42715784907341003\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123935.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114061.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111934.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  54%|    | 856/1600 [10:50<10:08,  1.22it/s, loss=0.00262, recon_loss=0.00134, kl_loss=1.29]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.972056212247054e-10/0.44207605719566345\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051004.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120779.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  54%|    | 857/1600 [10:50<08:30,  1.46it/s, loss=0.00198, recon_loss=0.000645, kl_loss=1.34]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.54656127904218e-08/0.49077096581459045\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082916.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004022.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085424.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  54%|    | 858/1600 [10:51<07:28,  1.65it/s, loss=0.00866, recon_loss=0.00729, kl_loss=1.37]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1872937355494884e-10/0.455714613199234\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006605.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082881.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126181.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  54%|    | 859/1600 [10:51<07:02,  1.76it/s, loss=0.00373, recon_loss=0.00224, kl_loss=1.48]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139991.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/018/018146.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113274.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 6.58314469603738e-09/0.4572915732860565\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094102.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000666.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099419.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  54%|    | 860/1600 [10:52<07:58,  1.55it/s, loss=0.00313, recon_loss=0.00153, kl_loss=1.6]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053863.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036618.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056466.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.556774087418944e-08/0.3663102090358734\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/015/015540.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148234.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134951.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045514.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  54%|    | 861/1600 [10:53<10:17,  1.20it/s, loss=0.00247, recon_loss=0.000762, kl_loss=1.7]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148212.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0542929862467076e-09/0.4612366259098053\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091186.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  54%|    | 862/1600 [10:54<08:57,  1.37it/s, loss=0.00421, recon_loss=0.00243, kl_loss=1.78]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006517.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.1104799685645048e-08/0.37142080068588257\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140791.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013378.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045516.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033415.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  54%|    | 863/1600 [10:55<09:46,  1.26it/s, loss=0.00264, recon_loss=0.000788, kl_loss=1.85]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112198.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2944566252226508e-10/0.40843087434768677\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029040.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/018/018887.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  54%|    | 864/1600 [10:55<09:01,  1.36it/s, loss=0.00324, recon_loss=0.00135, kl_loss=1.89]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.79358310612588e-08/0.44468650221824646\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139110.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097986.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  54%|    | 865/1600 [10:56<08:01,  1.53it/s, loss=0.00475, recon_loss=0.00284, kl_loss=1.91]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099437.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088871.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 3.221536648556622e-10/0.44241586327552795\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126603.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120332.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149118.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084486.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  54%|    | 866/1600 [10:57<09:31,  1.29it/s, loss=0.00247, recon_loss=0.000521, kl_loss=1.95]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/031/031389.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098655.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0915677250977751e-09/0.41919761896133423\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116238.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074347.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  54%|    | 867/1600 [10:58<09:18,  1.31it/s, loss=0.00322, recon_loss=0.00128, kl_loss=1.94]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045055.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.0249758253830805e-09/0.43440404534339905\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118672.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032439.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  54%|    | 868/1600 [10:58<08:55,  1.37it/s, loss=0.00285, recon_loss=0.000929, kl_loss=1.92]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108495.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.935879829859324e-12/0.3306225538253784\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062195.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070005.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066648.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051203.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  54%|    | 869/1600 [10:59<09:12,  1.32it/s, loss=0.00223, recon_loss=0.000353, kl_loss=1.88]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143299.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0418051693837924e-09/0.3413749039173126\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047659.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032328.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054039.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104063.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  54%|    | 870/1600 [11:00<09:39,  1.26it/s, loss=0.0021, recon_loss=0.000292, kl_loss=1.81]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4722074670459051e-09/0.4255851209163666\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092564.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075754.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  54%|    | 871/1600 [11:00<08:09,  1.49it/s, loss=0.00262, recon_loss=0.000912, kl_loss=1.71]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.727978093946092e-09/0.4010407626628876\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131903.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119940.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123484.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  55%|    | 872/1600 [11:01<07:33,  1.60it/s, loss=0.0025, recon_loss=0.000896, kl_loss=1.6]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.978636418215501e-09/0.40904343128204346\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052452.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027550.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111311.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  55%|    | 873/1600 [11:01<07:04,  1.71it/s, loss=0.00224, recon_loss=0.000749, kl_loss=1.49]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038859.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4228919431591436e-10/0.39809390902519226\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114532.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071240.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142567.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123975.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132141.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  55%|    | 874/1600 [11:02<08:11,  1.48it/s, loss=0.00228, recon_loss=0.000893, kl_loss=1.38]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062183.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108527.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091164.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127519.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052632.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2405783067492848e-09/0.3698761761188507\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086762.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123763.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012346.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  55%|    | 875/1600 [11:04<11:07,  1.09it/s, loss=0.00182, recon_loss=0.000543, kl_loss=1.28]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.883660311063906e-10/0.31807804107666016\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046846.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  55%|    | 876/1600 [11:04<08:52,  1.36it/s, loss=0.0013, recon_loss=0.000124, kl_loss=1.17]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108836.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0894928010051217e-09/0.4788123369216919\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055831.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075931.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011672.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010679.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  55%|    | 877/1600 [11:05<09:42,  1.24it/s, loss=0.00509, recon_loss=0.00403, kl_loss=1.06]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110768.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.7205084851544825e-09/0.3791736662387848\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126979.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071245.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059561.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  55%|    | 878/1600 [11:06<09:46,  1.23it/s, loss=0.00171, recon_loss=0.00071, kl_loss=0.995]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075386.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6821080639495278e-10/0.3652854263782501\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114385.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  55%|    | 879/1600 [11:06<08:36,  1.40it/s, loss=0.00146, recon_loss=0.000536, kl_loss=0.928]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012521.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097844.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129406.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.8917163668863424e-10/0.4520871639251709\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014736.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113970.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070873.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124554.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  55%|    | 880/1600 [11:07<10:19,  1.16it/s, loss=0.00184, recon_loss=0.000977, kl_loss=0.86]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024418.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3326178383010756e-08/0.3828332722187042\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/016/016354.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  55%|    | 881/1600 [11:08<09:05,  1.32it/s, loss=0.00146, recon_loss=0.000663, kl_loss=0.8]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098576.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142539.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.154262875199043e-12/0.4319843351840973\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139461.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148121.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125817.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049477.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  55%|    | 882/1600 [11:09<10:52,  1.10it/s, loss=0.00181, recon_loss=0.00107, kl_loss=0.741]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.572393572243598e-11/0.32075294852256775\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142563.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/061/061453.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  55%|    | 884/1600 [11:10<06:58,  1.71it/s, loss=0.00221, recon_loss=0.00157, kl_loss=0.635]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.9826956904344115e-08/0.40136778354644775\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126234.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032327.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122911.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.1643095072838605e-09/0.4437497556209564\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/025/025668.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114077.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069822.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075425.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125823.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071251.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094628.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075612.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  55%|    | 886/1600 [11:12<08:50,  1.35it/s, loss=0.00206, recon_loss=0.00151, kl_loss=0.552]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.6659148488761275e-07/0.4219358265399933\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121738.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.202655556895252e-09/0.5118916630744934\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109357.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126508.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  55%|    | 887/1600 [11:13<08:24,  1.41it/s, loss=0.0135, recon_loss=0.013, kl_loss=0.52]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/015/015625.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107590.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117885.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.2618682888351245e-11/0.39430302381515503\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/022/022476.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085488.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113453.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086419.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  56%|    | 888/1600 [11:14<09:57,  1.19it/s, loss=0.00106, recon_loss=0.000514, kl_loss=0.548]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108049.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133562.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111397.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.725646652823599e-10/0.3325793147087097\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060775.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071511.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  56%|    | 889/1600 [11:15<10:38,  1.11it/s, loss=0.000931, recon_loss=0.000361, kl_loss=0.57]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087191.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.346242585943742e-10/0.4435822665691376\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113262.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  56%|    | 890/1600 [11:15<09:04,  1.30it/s, loss=0.00216, recon_loss=0.00157, kl_loss=0.585]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040986.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.098855547837957e-08/0.41399702429771423\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072136.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097691.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  56%|    | 891/1600 [11:16<08:36,  1.37it/s, loss=0.00179, recon_loss=0.00119, kl_loss=0.601]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142550.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089179.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072206.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009846.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  56%|    | 892/1600 [11:17<08:30,  1.39it/s, loss=0.000793, recon_loss=0.000179, kl_loss=0.613]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.1354283752671464e-11/0.2991333603858948\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063289.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.820189911773468e-09/0.44631537795066833\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116447.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033216.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001544.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028484.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069554.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  56%|    | 893/1600 [11:18<09:26,  1.25it/s, loss=0.00349, recon_loss=0.00288, kl_loss=0.615]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129915.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.8750183506408575e-08/0.4337066113948822\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046844.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132677.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021232.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  56%|    | 894/1600 [11:18<09:27,  1.24it/s, loss=0.00293, recon_loss=0.0023, kl_loss=0.628]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.889221306645595e-09/0.38285931944847107\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131767.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081782.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  56%|    | 895/1600 [11:19<07:56,  1.48it/s, loss=0.00117, recon_loss=0.000525, kl_loss=0.646]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.729695219334417e-09/0.3997170925140381\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052045.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148289.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131934.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054235.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080833.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  56%|    | 896/1600 [11:20<08:37,  1.36it/s, loss=0.00147, recon_loss=0.000816, kl_loss=0.654]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.913648294329164e-10/0.4029586613178253\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089178.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080776.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120322.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081555.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071231.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  56%|    | 897/1600 [11:21<09:14,  1.27it/s, loss=0.00161, recon_loss=0.000952, kl_loss=0.655]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142671.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.91185258922178e-09/0.5155376195907593\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148133.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087377.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142129.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  56%|    | 899/1600 [11:21<06:55,  1.69it/s, loss=0.000762, recon_loss=0.000102, kl_loss=0.66]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006855.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.464763449640006e-14/0.3398626148700714\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/034/034996.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006329.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028553.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012062.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135342.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.1452480417072373e-11/0.3654078245162964\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056649.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118084.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  56%|    | 900/1600 [11:23<09:11,  1.27it/s, loss=0.00107, recon_loss=0.000412, kl_loss=0.655]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057648.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/150/150268.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.595981094648096e-09/0.40857598185539246\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090625.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  56%|    | 901/1600 [11:23<08:26,  1.38it/s, loss=0.00167, recon_loss=0.00103, kl_loss=0.643]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085816.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.2092288826390813e-09/0.438498854637146\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127190.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114392.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096560.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004780.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109686.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  56%|    | 902/1600 [11:25<10:13,  1.14it/s, loss=0.00158, recon_loss=0.000953, kl_loss=0.628]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5447228999404539e-12/0.2673710286617279\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/005/005159.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075751.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  56%|    | 903/1600 [11:25<08:53,  1.31it/s, loss=0.0007, recon_loss=8.8e-5, kl_loss=0.612]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.965811335935541e-08/0.47107547521591187\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124913.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054160.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126219.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  56%|    | 904/1600 [11:26<08:31,  1.36it/s, loss=0.00322, recon_loss=0.00263, kl_loss=0.59]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064078.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2519532077703843e-09/0.30578264594078064\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/025/025605.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134388.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113973.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012350.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114048.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  57%|    | 905/1600 [11:27<09:48,  1.18it/s, loss=0.000873, recon_loss=0.000292, kl_loss=0.581]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053496.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.4455396214762004e-06/0.49763473868370056\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054476.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/018/018031.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  57%|    | 906/1600 [11:27<08:54,  1.30it/s, loss=0.00974, recon_loss=0.00917, kl_loss=0.567]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.078673675524726e-10/0.3424954414367676\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145705.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042046.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  57%|    | 907/1600 [11:28<07:41,  1.50it/s, loss=0.000853, recon_loss=0.000252, kl_loss=0.601]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.906077594706403e-08/0.3804984986782074\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043019.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089639.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113696.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  57%|    | 908/1600 [11:28<07:13,  1.60it/s, loss=0.00142, recon_loss=0.00079, kl_loss=0.626]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011019.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009550.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119584.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075415.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038912.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/058/058333.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148190.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.671169420855108e-11/0.4411589801311493\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081512.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137170.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  57%|    | 909/1600 [11:30<10:27,  1.10it/s, loss=0.002, recon_loss=0.00136, kl_loss=0.645]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.267057818196918e-09/0.4486633837223053\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072056.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040525.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  57%|    | 910/1600 [11:30<09:04,  1.27it/s, loss=0.00329, recon_loss=0.00263, kl_loss=0.663]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119026.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.020585336357186e-11/0.3831406235694885\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134385.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112001.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/061/061742.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  57%|    | 911/1600 [11:31<08:55,  1.29it/s, loss=0.00134, recon_loss=0.000647, kl_loss=0.689]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064626.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115849.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.707176953251292e-09/0.37620460987091064\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/065/065685.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004101.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084158.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  57%|    | 912/1600 [11:32<09:30,  1.21it/s, loss=0.00133, recon_loss=0.000627, kl_loss=0.706]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085839.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115290.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7610821689828526e-09/0.51267009973526\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071276.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107532.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  57%|    | 913/1600 [11:33<09:31,  1.20it/s, loss=0.00679, recon_loss=0.00607, kl_loss=0.716]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117613.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071133.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.895294291098253e-08/0.47928890585899353\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056031.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108019.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  57%|    | 914/1600 [11:34<09:31,  1.20it/s, loss=0.00326, recon_loss=0.00251, kl_loss=0.751]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032695.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.2305819958343704e-10/0.3557499349117279\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127868.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/061/061159.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133580.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  57%|    | 915/1600 [11:35<09:16,  1.23it/s, loss=0.00115, recon_loss=0.000359, kl_loss=0.792]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.819620672146812e-10/0.3750338852405548\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142089.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071228.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  57%|    | 916/1600 [11:35<08:04,  1.41it/s, loss=0.00125, recon_loss=0.000428, kl_loss=0.82]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029741.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052001.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120305.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2264682425211504e-07/0.3817293047904968\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107851.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116446.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110651.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114006.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  57%|    | 917/1600 [11:36<10:01,  1.14it/s, loss=0.00182, recon_loss=0.000984, kl_loss=0.836]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011764.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.514686829295897e-07/0.39175862073898315\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085307.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  57%|    | 918/1600 [11:37<08:36,  1.32it/s, loss=0.00191, recon_loss=0.00106, kl_loss=0.846]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.1752171244782126e-11/0.44613632559776306\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142568.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116758.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  57%|    | 919/1600 [11:37<07:26,  1.52it/s, loss=0.00153, recon_loss=0.000682, kl_loss=0.849]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116877.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.493631743431649e-10/0.38427403569221497\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108023.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133638.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  57%|    | 920/1600 [11:38<07:02,  1.61it/s, loss=0.00144, recon_loss=0.000591, kl_loss=0.844]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087972.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003778.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026902.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133564.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070002.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145729.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.204772086069397e-09/0.3484222888946533\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111387.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013539.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026657.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  58%|    | 921/1600 [11:39<09:57,  1.14it/s, loss=0.00124, recon_loss=0.000409, kl_loss=0.831]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105411.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.110700398841702e-12/0.453183650970459\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059374.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  58%|    | 922/1600 [11:40<08:34,  1.32it/s, loss=0.00178, recon_loss=0.000969, kl_loss=0.81]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057662.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.3689897094291155e-08/0.43738916516304016\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054437.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091443.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063044.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  58%|    | 923/1600 [11:40<08:32,  1.32it/s, loss=0.00214, recon_loss=0.00135, kl_loss=0.787]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113263.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137630.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121985.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.031016354044681e-10/0.34645652770996094\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030056.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115948.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  58%|    | 925/1600 [11:41<06:38,  1.69it/s, loss=0.00105, recon_loss=0.000309, kl_loss=0.739]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.3011952066109842e-10/0.35520800948143005\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132954.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132791.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122935.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.050354381249008e-08/0.35350045561790466\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073770.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/147/147409.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091083.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  58%|    | 926/1600 [11:42<07:42,  1.46it/s, loss=0.00122, recon_loss=0.000515, kl_loss=0.707]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.498406174808679e-09/0.4554756283760071\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068573.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011681.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116344.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109535.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117253.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126789.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  58%|    | 927/1600 [11:43<08:53,  1.26it/s, loss=0.00251, recon_loss=0.00184, kl_loss=0.673]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099093.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.18839009136218e-08/0.41747725009918213\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004071.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141304.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  58%|    | 928/1600 [11:44<08:26,  1.33it/s, loss=0.00154, recon_loss=0.000895, kl_loss=0.648]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054064.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.312486616228853e-09/0.3646146059036255\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006469.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107809.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133020.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  58%|    | 929/1600 [11:45<08:27,  1.32it/s, loss=0.00136, recon_loss=0.000735, kl_loss=0.623]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.816937572618471e-10/0.41010719537734985\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114884.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075786.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122832.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059709.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128828.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  58%|    | 930/1600 [11:46<08:59,  1.24it/s, loss=0.0016, recon_loss=0.001, kl_loss=0.598]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134452.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7920939177074047e-09/0.44820472598075867\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/152/152324.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/025/025104.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069563.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  58%|    | 931/1600 [11:47<09:02,  1.23it/s, loss=0.003, recon_loss=0.00243, kl_loss=0.574]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112526.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.995379830954107e-10/0.44889700412750244\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062596.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145183.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073099.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  58%|    | 932/1600 [11:47<08:54,  1.25it/s, loss=0.00174, recon_loss=0.00118, kl_loss=0.559]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1545293367165588e-11/0.4256601631641388\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057658.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062436.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  58%|    | 933/1600 [11:48<07:36,  1.46it/s, loss=0.00148, recon_loss=0.000934, kl_loss=0.544]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7219052850236949e-09/0.462152361869812\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089860.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099390.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098348.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  58%|    | 934/1600 [11:48<07:09,  1.55it/s, loss=0.00348, recon_loss=0.00295, kl_loss=0.529]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113808.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125620.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113024.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.078374389784642e-09/0.37914445996284485\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/034/034258.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146458.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064834.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060074.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056516.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  58%|    | 935/1600 [11:50<09:35,  1.16it/s, loss=0.000883, recon_loss=0.000358, kl_loss=0.524]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109972.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.394984152282348e-10/0.4523484408855438\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073340.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  58%|    | 936/1600 [11:50<08:22,  1.32it/s, loss=0.00199, recon_loss=0.00147, kl_loss=0.515]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082930.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.5802593395241047e-09/0.3680753707885742\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/100/100835.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143097.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  59%|    | 937/1600 [11:51<07:55,  1.39it/s, loss=0.00105, recon_loss=0.000538, kl_loss=0.51]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121594.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001073.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007388.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.882744182779561e-09/0.4405709505081177\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080341.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089815.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119992.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/041/041825.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  59%|    | 938/1600 [11:52<09:47,  1.13it/s, loss=0.00274, recon_loss=0.00224, kl_loss=0.502]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094037.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114066.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.01489519011011e-08/0.3754628896713257\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  59%|    | 939/1600 [11:53<08:27,  1.30it/s, loss=0.000843, recon_loss=0.000342, kl_loss=0.501]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073465.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.5240807222104422e-09/0.4246503412723541\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081814.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145918.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  59%|    | 940/1600 [11:53<07:52,  1.40it/s, loss=0.00135, recon_loss=0.000853, kl_loss=0.495]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.9213958469286325e-11/0.37828633189201355\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098557.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000256.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128668.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098346.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  59%|    | 941/1600 [11:54<07:48,  1.41it/s, loss=0.00136, recon_loss=0.000874, kl_loss=0.489]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047663.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057691.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126354.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.888077890183919e-13/0.4251348078250885\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129403.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024745.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051999.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059454.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  59%|    | 942/1600 [11:55<09:39,  1.14it/s, loss=0.00232, recon_loss=0.00183, kl_loss=0.481]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091179.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.705087430778576e-09/0.39745011925697327\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126414.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  59%|    | 943/1600 [11:56<08:13,  1.33it/s, loss=0.00116, recon_loss=0.000681, kl_loss=0.478]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.121091133959311e-11/0.4078482985496521\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084736.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133639.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  59%|    | 944/1600 [11:56<07:02,  1.55it/s, loss=0.00152, recon_loss=0.00104, kl_loss=0.473]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.340694914617416e-09/0.45630553364753723\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/039/039298.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127484.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125999.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134454.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098238.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062748.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  59%|    | 945/1600 [11:57<08:25,  1.29it/s, loss=0.00289, recon_loss=0.00242, kl_loss=0.468]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.897108413752903e-08/0.4393329322338104\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145887.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043886.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043691.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070770.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128887.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  59%|    | 946/1600 [11:58<09:01,  1.21it/s, loss=0.00217, recon_loss=0.0017, kl_loss=0.472]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/037/037784.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.532090188050006e-08/0.42518219351768494\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123834.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035571.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137901.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  59%|    | 947/1600 [11:59<09:05,  1.20it/s, loss=0.0011, recon_loss=0.000618, kl_loss=0.478]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070174.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0218665852667073e-08/0.4651375114917755\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012348.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085967.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099041.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  59%|    | 948/1600 [12:00<09:17,  1.17it/s, loss=0.00213, recon_loss=0.00165, kl_loss=0.48]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.9506717069693877e-09/0.38431254029273987\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123505.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111224.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  59%|    | 949/1600 [12:00<08:01,  1.35it/s, loss=0.00129, recon_loss=0.000809, kl_loss=0.484]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074945.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.375976002142124e-07/0.4055033028125763\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119571.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036302.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  59%|    | 950/1600 [12:01<07:31,  1.44it/s, loss=0.00166, recon_loss=0.00117, kl_loss=0.485]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.280863082264716e-09/0.3893570005893707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075764.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036144.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098227.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/020/020424.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122579.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148586.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055231.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  59%|    | 951/1600 [12:02<09:21,  1.16it/s, loss=0.00127, recon_loss=0.000786, kl_loss=0.486]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138351.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.2889438528481705e-11/0.4681280553340912\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126676.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127155.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  60%|    | 952/1600 [12:03<08:35,  1.26it/s, loss=0.00383, recon_loss=0.00335, kl_loss=0.485]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038825.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0205121470097112e-10/0.4075144827365875\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043021.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073771.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144492.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011785.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  60%|    | 953/1600 [12:04<09:15,  1.17it/s, loss=0.00173, recon_loss=0.00123, kl_loss=0.495]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104357.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053302.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.256710598037898e-08/0.454948365688324\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007373.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107046.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  60%|    | 954/1600 [12:05<09:13,  1.17it/s, loss=0.00453, recon_loss=0.00403, kl_loss=0.504]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138256.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.098339707163227e-12/0.4617088735103607\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111933.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119901.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075935.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  60%|    | 955/1600 [12:05<09:07,  1.18it/s, loss=0.00226, recon_loss=0.00173, kl_loss=0.527]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.69828487015667e-10/0.37568122148513794\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012985.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064809.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055294.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112788.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  60%|    | 956/1600 [12:06<09:12,  1.17it/s, loss=0.000932, recon_loss=0.000381, kl_loss=0.551]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112066.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0293998986554698e-09/0.37934520840644836\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148077.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130368.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062594.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  60%|    | 957/1600 [12:07<09:03,  1.18it/s, loss=0.00135, recon_loss=0.00078, kl_loss=0.566]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.292615264298803e-10/0.38649874925613403\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143039.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127205.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  60%|    | 958/1600 [12:08<07:42,  1.39it/s, loss=0.00119, recon_loss=0.000614, kl_loss=0.578]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116261.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.3041436132161834e-08/0.39384332299232483\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142549.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116526.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117472.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097841.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131567.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114050.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  60%|    | 960/1600 [12:09<07:03,  1.51it/s, loss=0.00655, recon_loss=0.00597, kl_loss=0.585]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.317551294732766e-07/0.49695253372192383\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133551.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/150/150064.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056552.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052953.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145068.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.302792043641706e-12/0.4777613580226898\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/101/101951.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064556.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129397.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  60%|    | 961/1600 [12:10<09:05,  1.17it/s, loss=0.00377, recon_loss=0.00316, kl_loss=0.61]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122648.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5031632882855916e-10/0.41675591468811035\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116239.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  60%|    | 962/1600 [12:11<07:56,  1.34it/s, loss=0.0014, recon_loss=0.000751, kl_loss=0.645]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.2939012911393775e-09/0.36722713708877563\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144546.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086993.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  60%|    | 963/1600 [12:11<06:53,  1.54it/s, loss=0.00121, recon_loss=0.00054, kl_loss=0.673]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.5058909381445744e-10/0.4470590651035309\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119745.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133444.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075784.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026904.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009512.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129095.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  60%|    | 964/1600 [12:12<07:57,  1.33it/s, loss=0.0014, recon_loss=0.000709, kl_loss=0.693]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.40753308797548e-09/0.471211314201355\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111153.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142418.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126225.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  60%|    | 965/1600 [12:13<07:30,  1.41it/s, loss=0.0042, recon_loss=0.00349, kl_loss=0.707]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139043.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040245.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053588.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.379239388312527e-10/0.4256557524204254\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127273.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/039/039188.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  60%|    | 966/1600 [12:14<08:03,  1.31it/s, loss=0.00211, recon_loss=0.00138, kl_loss=0.734]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024429.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123980.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120303.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.808747588152084e-12/0.4432186186313629\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/061/061592.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072565.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  60%|    | 967/1600 [12:15<08:22,  1.26it/s, loss=0.0034, recon_loss=0.00264, kl_loss=0.759]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001259.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.2278541511600025e-10/0.37886130809783936\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131452.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/023/023015.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122066.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111182.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  60%|    | 968/1600 [12:16<09:18,  1.13it/s, loss=0.00109, recon_loss=0.000302, kl_loss=0.791]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5387000562583353e-09/0.36520078778266907\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083969.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054468.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  61%|    | 969/1600 [12:16<08:14,  1.28it/s, loss=0.0012, recon_loss=0.000393, kl_loss=0.811]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128886.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.208673185627902e-10/0.4766167998313904\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118738.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139776.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  61%|    | 970/1600 [12:17<07:51,  1.33it/s, loss=0.00337, recon_loss=0.00255, kl_loss=0.82]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062655.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038881.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.044208049147073e-09/0.41997772455215454\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024983.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073564.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  61%|    | 971/1600 [12:18<07:48,  1.34it/s, loss=0.0018, recon_loss=0.000969, kl_loss=0.835]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027953.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099442.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/061/061452.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055436.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.500905556094949e-07/0.4340101182460785\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  61%|    | 972/1600 [12:18<07:46,  1.35it/s, loss=0.0023, recon_loss=0.00146, kl_loss=0.844]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104668.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132424.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/039/039378.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035541.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.3114932901080465e-07/0.418738454580307\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134827.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067334.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116453.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  61%|    | 973/1600 [12:20<09:22,  1.11it/s, loss=0.00293, recon_loss=0.00208, kl_loss=0.852]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001069.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.193753205290363e-10/0.40600478649139404\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131897.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  61%|    | 974/1600 [12:20<07:59,  1.30it/s, loss=0.0018, recon_loss=0.000931, kl_loss=0.864]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027195.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.09638900578102e-09/0.43523189425468445\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125239.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124971.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124996.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104010.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129887.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  61%|    | 975/1600 [12:21<09:21,  1.11it/s, loss=0.00204, recon_loss=0.00117, kl_loss=0.869]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.8903916199650723e-10/0.4251258969306946\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075869.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082462.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  61%|    | 976/1600 [12:22<07:53,  1.32it/s, loss=0.00203, recon_loss=0.00116, kl_loss=0.871]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7593745127442162e-08/0.3484487533569336\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080611.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138024.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  61%|    | 977/1600 [12:22<06:55,  1.50it/s, loss=0.00142, recon_loss=0.000548, kl_loss=0.869]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115273.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121869.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131449.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123278.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013710.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133780.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.032879305648223e-11/0.304921418428421\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/037/037416.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/029/029039.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  61%|    | 978/1600 [12:24<09:12,  1.13it/s, loss=0.00115, recon_loss=0.000292, kl_loss=0.858]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.594578134093808e-10/0.47053584456443787\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107616.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036959.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  61%|   | 980/1600 [12:24<05:59,  1.73it/s, loss=0.00133, recon_loss=0.000505, kl_loss=0.824]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0174550438279972e-11/0.3789125978946686\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047658.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003912.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.776895241003331e-09/0.3551633954048157\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047628.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085485.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123438.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  61%|   | 981/1600 [12:25<06:16,  1.65it/s, loss=0.00128, recon_loss=0.000473, kl_loss=0.804]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.653653573605254e-10/0.34020736813545227\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133793.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024422.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127276.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105825.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/105/105685.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/078/078038.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145727.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014579.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138066.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  61%|   | 982/1600 [12:26<08:58,  1.15it/s, loss=0.00101, recon_loss=0.000232, kl_loss=0.778]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128879.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.986974915828114e-09/0.3627842664718628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057360.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  61%|   | 983/1600 [12:27<07:49,  1.32it/s, loss=0.00123, recon_loss=0.000484, kl_loss=0.746]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044820.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042442.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6052602498130286e-13/0.35621705651283264\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133538.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052862.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 984/1600 [12:28<07:49,  1.31it/s, loss=0.00113, recon_loss=0.000421, kl_loss=0.711]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144936.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131774.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004070.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 985/1600 [12:28<07:09,  1.43it/s, loss=0.00201, recon_loss=0.00134, kl_loss=0.674]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.456900765641535e-09/0.4081999361515045\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024364.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140583.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059581.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127301.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6373757905085995e-10/0.2922753691673279\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108962.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038833.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 986/1600 [12:29<08:12,  1.25it/s, loss=0.000792, recon_loss=0.000152, kl_loss=0.641]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.270096080702615e-09/0.38917553424835205\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052044.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075750.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 987/1600 [12:30<07:18,  1.40it/s, loss=0.0017, recon_loss=0.00109, kl_loss=0.605]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009887.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069768.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000424.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081523.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.940709179608818e-13/0.4132246971130371\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146687.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116759.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044792.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 988/1600 [12:31<09:22,  1.09it/s, loss=0.00102, recon_loss=0.000449, kl_loss=0.573]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082917.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.02013151049141e-08/0.43119698762893677\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043587.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 989/1600 [12:32<08:08,  1.25it/s, loss=0.00153, recon_loss=0.00099, kl_loss=0.541]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043516.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.7272705755153623e-11/0.3978734314441681\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148513.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093942.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106343.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073822.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 990/1600 [12:33<08:42,  1.17it/s, loss=0.0017, recon_loss=0.00119, kl_loss=0.513]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085039.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053457.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/076/076036.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.592241362848085e-10/0.47025030851364136\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131982.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 991/1600 [12:33<08:37,  1.18it/s, loss=0.00169, recon_loss=0.0012, kl_loss=0.489]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113789.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6817215398035046e-09/0.4008544087409973\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136468.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094422.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 992/1600 [12:34<08:03,  1.26it/s, loss=0.00158, recon_loss=0.00112, kl_loss=0.468]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010382.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0569545239036415e-09/0.3662153482437134\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114062.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009918.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075374.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116119.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 993/1600 [12:35<08:24,  1.20it/s, loss=0.000726, recon_loss=0.000276, kl_loss=0.45]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064604.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.673969958434725e-11/0.3792661726474762\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144423.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060536.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 994/1600 [12:36<07:52,  1.28it/s, loss=0.000922, recon_loss=0.000492, kl_loss=0.43]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.196497663255805e-11/0.386717289686203\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115700.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042911.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 995/1600 [12:36<06:58,  1.45it/s, loss=0.000896, recon_loss=0.000485, kl_loss=0.411]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032693.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149687.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127911.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080001.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046855.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.181155333071729e-08/0.3714309334754944\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091793.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024366.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127422.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 996/1600 [12:38<09:16,  1.09it/s, loss=0.000988, recon_loss=0.000596, kl_loss=0.392]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.6709323988627354e-11/0.3577820062637329\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049072.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111306.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 997/1600 [12:38<07:57,  1.26it/s, loss=0.00064, recon_loss=0.000267, kl_loss=0.373]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/058/058117.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.283871422680832e-11/0.30733758211135864\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067661.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119579.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122473.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 998/1600 [12:39<07:42,  1.30it/s, loss=0.000474, recon_loss=0.00012, kl_loss=0.354]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.2082837476727946e-09/0.5256280899047852\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111579.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069201.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107534.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 999/1600 [12:39<06:40,  1.50it/s, loss=0.00853, recon_loss=0.0082, kl_loss=0.334]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.711190574966054e-10/0.3718535900115967\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043590.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/023/023041.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114037.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  62%|   | 1000/1600 [12:40<06:06,  1.64it/s, loss=0.000951, recon_loss=0.00062, kl_loss=0.331]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.749849650906526e-09/0.3890962302684784\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026656.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043766.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136322.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  63%|   | 1001/1600 [12:40<05:48,  1.72it/s, loss=0.00135, recon_loss=0.00102, kl_loss=0.328]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062753.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074383.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051265.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087324.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070299.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115891.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.624679388915865e-09/0.362532377243042\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071246.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131326.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035544.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  63%|   | 1002/1600 [12:42<08:12,  1.21it/s, loss=0.000642, recon_loss=0.000317, kl_loss=0.325]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4583470431261958e-07/0.3675413131713867\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085593.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014208.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  63%|   | 1003/1600 [12:42<07:06,  1.40it/s, loss=0.00117, recon_loss=0.000849, kl_loss=0.32]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.681243661961101e-12/0.3401264548301697\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136323.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122003.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  63%|   | 1004/1600 [12:42<06:09,  1.61it/s, loss=0.000742, recon_loss=0.000427, kl_loss=0.315]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.9992883671402524e-08/0.391213595867157\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119027.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091958.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067364.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  63%|   | 1005/1600 [12:43<05:47,  1.71it/s, loss=0.00145, recon_loss=0.00114, kl_loss=0.31]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074302.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088959.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/033/033124.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144942.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.455814883730369e-10/0.35149869322776794\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074421.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104008.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148609.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  63%|   | 1006/1600 [12:44<06:51,  1.44it/s, loss=0.000611, recon_loss=0.000306, kl_loss=0.305]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6980724382165135e-08/0.3600635230541229\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108488.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004092.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110756.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026302.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010535.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  63%|   | 1007/1600 [12:45<07:22,  1.34it/s, loss=0.000938, recon_loss=0.00064, kl_loss=0.298]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0746966367113373e-09/0.32861649990081787\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081613.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133442.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  63%|   | 1008/1600 [12:45<06:34,  1.50it/s, loss=0.000507, recon_loss=0.000215, kl_loss=0.292]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/147/147413.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/019/019073.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1132546967607126e-10/0.4238826036453247\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030682.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110448.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115735.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088867.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  63%|   | 1009/1600 [12:46<07:58,  1.23it/s, loss=0.00113, recon_loss=0.00085, kl_loss=0.283]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091084.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0779589665332878e-08/0.45572584867477417\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117666.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091184.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130934.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  63%|   | 1010/1600 [12:47<08:09,  1.21it/s, loss=0.00241, recon_loss=0.00214, kl_loss=0.275]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1503709629323566e-07/0.38615918159484863\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052034.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042475.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063250.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047068.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  63%|   | 1011/1600 [12:48<08:19,  1.18it/s, loss=0.00145, recon_loss=0.00117, kl_loss=0.272]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137171.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2193785980940675e-09/0.4169376492500305\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111371.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104724.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142081.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  63%|   | 1012/1600 [12:49<08:19,  1.18it/s, loss=0.00141, recon_loss=0.00114, kl_loss=0.27]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143061.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.234941286540561e-08/0.3904035985469818\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127662.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072562.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  63%|   | 1013/1600 [12:50<07:40,  1.27it/s, loss=0.000959, recon_loss=0.000691, kl_loss=0.268]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117966.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.721093572162104e-11/0.4547024071216583\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122901.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044799.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013540.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007710.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098621.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  63%|   | 1014/1600 [12:51<08:33,  1.14it/s, loss=0.00257, recon_loss=0.00231, kl_loss=0.266]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.901085192046459e-12/0.4434126615524292\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111188.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099436.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  63%|   | 1015/1600 [12:51<07:18,  1.33it/s, loss=0.00221, recon_loss=0.00194, kl_loss=0.269]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.668977621718028e-11/0.46170198917388916\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/150/150288.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064366.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032339.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1016/1600 [12:52<06:59,  1.39it/s, loss=0.00198, recon_loss=0.00171, kl_loss=0.275]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086262.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129962.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027855.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032760.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112209.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.742006480349062e-10/0.37375786900520325\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094468.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1017/1600 [12:53<08:03,  1.21it/s, loss=0.00102, recon_loss=0.000734, kl_loss=0.283]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137900.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/076/076077.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.732342993695292e-12/0.3943607211112976\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137722.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038821.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1018/1600 [12:54<08:09,  1.19it/s, loss=0.000805, recon_loss=0.000517, kl_loss=0.288]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056650.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.67762326042498e-09/0.4373314380645752\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075399.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/018/018350.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122673.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1019/1600 [12:55<08:08,  1.19it/s, loss=0.00187, recon_loss=0.00158, kl_loss=0.292]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012376.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064856.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048456.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.956662161414442e-10/0.4520327150821686\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116549.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1020/1600 [12:55<08:05,  1.20it/s, loss=0.00243, recon_loss=0.00214, kl_loss=0.297]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133781.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.214083552753436e-08/0.4191032946109772\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057418.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052121.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114411.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1021/1600 [12:56<07:54,  1.22it/s, loss=0.0015, recon_loss=0.00119, kl_loss=0.306]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028241.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107911.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.3840123592199234e-07/0.4174952507019043\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067366.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006684.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1022/1600 [12:57<08:00,  1.20it/s, loss=0.00192, recon_loss=0.0016, kl_loss=0.314]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024742.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.005613618573989e-09/0.4113374948501587\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113343.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073819.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054466.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1023/1600 [12:58<07:58,  1.21it/s, loss=0.00149, recon_loss=0.00117, kl_loss=0.323]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141182.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2326908382931379e-08/0.37526121735572815\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145067.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004787.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052630.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1024/1600 [12:59<07:52,  1.22it/s, loss=0.000742, recon_loss=0.000409, kl_loss=0.332]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129186.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.3934569760040176e-08/0.3819403350353241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/020/020364.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082918.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088872.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1025/1600 [13:00<07:53,  1.21it/s, loss=0.000993, recon_loss=0.000655, kl_loss=0.338]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131325.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.873432825012401e-09/0.4141947627067566\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000825.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130135.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116833.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1026/1600 [13:00<07:48,  1.23it/s, loss=0.000891, recon_loss=0.000549, kl_loss=0.342]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098235.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.920593462045872e-08/0.3470612168312073\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111186.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003532.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093941.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1027/1600 [13:01<07:47,  1.23it/s, loss=0.000785, recon_loss=0.000443, kl_loss=0.342]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117846.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1526509607895363e-10/0.3919290602207184\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127274.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124477.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130944.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1028/1600 [13:02<07:42,  1.24it/s, loss=0.00107, recon_loss=0.00073, kl_loss=0.341]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006358.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.9388150807042592e-10/0.4606252610683441\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124460.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091098.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085438.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1029/1600 [13:03<07:46,  1.22it/s, loss=0.00386, recon_loss=0.00353, kl_loss=0.338]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.9023826664829073e-11/0.291269451379776\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060754.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012531.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1030/1600 [13:03<06:57,  1.37it/s, loss=0.000502, recon_loss=0.000159, kl_loss=0.344]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072605.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108838.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107596.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4738303910633022e-08/0.4798973798751831\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003271.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054237.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/101/101864.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1031/1600 [13:04<08:00,  1.18it/s, loss=0.00516, recon_loss=0.00482, kl_loss=0.345]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067333.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.322049579868036e-10/0.476198673248291\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054443.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069223.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  64%|   | 1032/1600 [13:05<07:28,  1.27it/s, loss=0.0032, recon_loss=0.00285, kl_loss=0.356]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056521.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.559301600818969e-10/0.3273269236087799\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042240.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027611.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  65%|   | 1033/1600 [13:06<07:16,  1.30it/s, loss=0.000699, recon_loss=0.000326, kl_loss=0.373]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114398.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069567.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146970.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.2663417809098974e-09/0.3816872537136078\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141310.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108885.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006354.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  65%|   | 1034/1600 [13:07<08:22,  1.13it/s, loss=0.000979, recon_loss=0.000593, kl_loss=0.386]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047670.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.025573042629958e-09/0.367862343788147\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/150/150267.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117630.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144940.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057823.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  65%|   | 1035/1600 [13:08<08:51,  1.06it/s, loss=0.00092, recon_loss=0.000525, kl_loss=0.395]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055718.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2331474730231662e-09/0.3539194166660309\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085833.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  65%|   | 1036/1600 [13:09<07:30,  1.25it/s, loss=0.000865, recon_loss=0.000465, kl_loss=0.4]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112483.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.669370082925454e-11/0.3832947611808777\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/076/076375.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097393.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064594.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123868.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125812.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  65%|   | 1037/1600 [13:10<08:42,  1.08it/s, loss=0.0011, recon_loss=0.000701, kl_loss=0.402]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.159334989120353e-10/0.4512833058834076\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149523.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049407.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  65%|   | 1038/1600 [13:10<07:13,  1.30it/s, loss=0.00226, recon_loss=0.00186, kl_loss=0.402]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0034869601938112e-09/0.3216100335121155\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/016/016337.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085487.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  65%|   | 1039/1600 [13:11<06:09,  1.52it/s, loss=0.000677, recon_loss=0.00027, kl_loss=0.406]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.262742254150908e-08/0.42133843898773193\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011505.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140875.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068682.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  65%|   | 1040/1600 [13:11<05:48,  1.61it/s, loss=0.00099, recon_loss=0.000584, kl_loss=0.406]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0785665693902047e-09/0.32928669452667236\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149140.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042377.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012394.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130454.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114051.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091170.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026465.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  65%|   | 1041/1600 [13:12<06:34,  1.42it/s, loss=0.000784, recon_loss=0.000381, kl_loss=0.403]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.915352959043105e-10/0.3255655765533447\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044778.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096726.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/101/101111.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003272.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104434.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  65%|   | 1042/1600 [13:13<07:05,  1.31it/s, loss=0.000607, recon_loss=0.000209, kl_loss=0.398]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0635843317174931e-09/0.31358903646469116\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112583.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133978.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  65%|   | 1043/1600 [13:13<06:06,  1.52it/s, loss=0.000547, recon_loss=0.000158, kl_loss=0.389]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3211011662406236e-07/0.42060843110084534\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132781.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062184.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113273.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108038.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  65%|   | 1044/1600 [13:14<06:05,  1.52it/s, loss=0.00125, recon_loss=0.000871, kl_loss=0.377]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130691.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108529.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108304.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135373.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131476.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.563270460446802e-08/0.4085272252559662\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117628.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  65%|   | 1045/1600 [13:15<06:51,  1.35it/s, loss=0.000984, recon_loss=0.000617, kl_loss=0.366]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128888.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.767932742013372e-11/0.3478385806083679\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047657.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148215.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006367.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  65%|   | 1046/1600 [13:16<07:06,  1.30it/s, loss=0.000656, recon_loss=0.000301, kl_loss=0.355]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/031/031888.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2733764265249192e-07/0.42540284991264343\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040842.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071709.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007482.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  65%|   | 1047/1600 [13:16<06:53,  1.34it/s, loss=0.00211, recon_loss=0.00177, kl_loss=0.342]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.716458110846759e-10/0.34009039402008057\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062526.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106570.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121913.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1048/1600 [13:17<06:41,  1.37it/s, loss=0.000694, recon_loss=0.000361, kl_loss=0.334]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122510.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/017/017636.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137212.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.5670176146140875e-08/0.4626571238040924\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/016/016743.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057892.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090826.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1049/1600 [13:18<07:45,  1.18it/s, loss=0.00239, recon_loss=0.00207, kl_loss=0.325]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.426024197289884e-12/0.35761523246765137\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118060.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131773.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1050/1600 [13:19<06:38,  1.38it/s, loss=0.000661, recon_loss=0.000341, kl_loss=0.321]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.744018676840824e-10/0.461527019739151\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133537.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/100/100973.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1051/1600 [13:19<05:55,  1.54it/s, loss=0.00184, recon_loss=0.00153, kl_loss=0.315]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126180.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134928.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000574.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052861.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1184394743679604e-08/0.31311851739883423\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149714.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081803.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049844.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110436.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1052/1600 [13:21<08:05,  1.13it/s, loss=0.000581, recon_loss=0.000269, kl_loss=0.312]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000814.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.661273087628985e-11/0.45766061544418335\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027803.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1053/1600 [13:21<06:53,  1.32it/s, loss=0.0028, recon_loss=0.0025, kl_loss=0.306]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.2774748127148996e-08/0.4205690920352936\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081436.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/005/005376.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1054/1600 [13:22<06:00,  1.52it/s, loss=0.00222, recon_loss=0.00192, kl_loss=0.307]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055782.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.826922304194795e-09/0.37271153926849365\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014744.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073335.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082890.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026583.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051479.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1055/1600 [13:22<06:46,  1.34it/s, loss=0.000756, recon_loss=0.000444, kl_loss=0.312]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.844018714449504e-10/0.3549278676509857\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042119.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042040.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148430.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/061/061006.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1056/1600 [13:23<06:53,  1.32it/s, loss=0.00075, recon_loss=0.000435, kl_loss=0.315]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049478.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.940861693583429e-09/0.4076446294784546\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113259.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142098.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1057/1600 [13:24<06:20,  1.43it/s, loss=0.00127, recon_loss=0.000955, kl_loss=0.315]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035608.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.20457604896518e-10/0.3507784307003021\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052451.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142570.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111871.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004778.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/095/095727.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085595.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1058/1600 [13:25<07:55,  1.14it/s, loss=0.000638, recon_loss=0.000321, kl_loss=0.316]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.736462789698635e-08/0.37850579619407654\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089192.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120462.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1059/1600 [13:26<06:39,  1.35it/s, loss=0.0012, recon_loss=0.000882, kl_loss=0.315]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.2349140316180183e-09/0.3788386881351471\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062190.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110259.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1060/1600 [13:26<05:47,  1.55it/s, loss=0.000638, recon_loss=0.000324, kl_loss=0.313]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038911.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.123724886705986e-09/0.4125753939151764\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122360.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114283.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109902.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148605.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075377.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148211.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010481.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1061/1600 [13:27<07:35,  1.18it/s, loss=0.001, recon_loss=0.000694, kl_loss=0.309]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.777421456329648e-09/0.35937511920928955\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142086.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131771.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1062/1600 [13:28<06:28,  1.39it/s, loss=0.000764, recon_loss=0.00046, kl_loss=0.304]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/058/058070.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1928088725077224e-13/0.3594318628311157\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074669.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068895.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144544.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011803.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1063/1600 [13:29<07:15,  1.23it/s, loss=0.000778, recon_loss=0.00048, kl_loss=0.298]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073192.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4043330734403447e-11/0.4514503479003906\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/023/023063.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111148.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006461.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  66%|   | 1064/1600 [13:30<07:19,  1.22it/s, loss=0.0017, recon_loss=0.00141, kl_loss=0.291]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113932.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.135760592471343e-08/0.4020862579345703\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  67%|   | 1065/1600 [13:30<05:55,  1.51it/s, loss=0.00103, recon_loss=0.000742, kl_loss=0.286]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108774.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124154.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049857.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108840.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.730554519800535e-08/0.3777400255203247\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082629.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073172.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062527.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098670.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  67%|   | 1066/1600 [13:31<07:55,  1.12it/s, loss=0.000764, recon_loss=0.000483, kl_loss=0.281]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060472.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.1365957614261077e-10/0.397919237613678\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131448.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035734.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  67%|   | 1068/1600 [13:32<05:35,  1.58it/s, loss=0.00103, recon_loss=0.000759, kl_loss=0.269]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0299299191274258e-09/0.41452422738075256\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064516.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060757.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.6402131592107025e-09/0.30511295795440674\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114289.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142080.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091621.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073561.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069001.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  67%|   | 1069/1600 [13:33<06:54,  1.28it/s, loss=0.000484, recon_loss=0.00022, kl_loss=0.263]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.8199340645619344e-10/0.3202713131904602\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144938.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/109/109447.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140926.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036526.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059718.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  67%|   | 1070/1600 [13:34<07:10,  1.23it/s, loss=0.000605, recon_loss=0.000349, kl_loss=0.256]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052522.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.7434126081971044e-09/0.27677902579307556\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116099.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  67%|   | 1071/1600 [13:35<06:14,  1.41it/s, loss=0.000445, recon_loss=0.000197, kl_loss=0.248]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/037/037141.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/101/101112.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099438.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.9108741134441516e-08/0.38062673807144165\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130440.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/103/103519.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  67%|   | 1072/1600 [13:36<06:43,  1.31it/s, loss=0.000862, recon_loss=0.000624, kl_loss=0.238]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075401.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067363.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042245.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.843704605126618e-09/0.3600468039512634\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068539.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092951.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  67%|   | 1073/1600 [13:36<07:14,  1.21it/s, loss=0.000821, recon_loss=0.000592, kl_loss=0.23]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000204.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.582676767419855e-10/0.39094728231430054\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/050/050444.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043595.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  67%|   | 1074/1600 [13:37<06:39,  1.32it/s, loss=0.000796, recon_loss=0.000574, kl_loss=0.221]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011773.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.766853271640173e-10/0.329015851020813\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082919.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069170.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  67%|   | 1075/1600 [13:38<06:32,  1.34it/s, loss=0.000554, recon_loss=0.000341, kl_loss=0.213]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052954.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116868.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051005.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149953.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137418.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.048694700666601e-08/0.40413495898246765\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083437.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134643.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  67%|   | 1076/1600 [13:39<07:56,  1.10it/s, loss=0.000735, recon_loss=0.00053, kl_loss=0.205]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.567003403759372e-08/0.36187660694122314\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130940.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107592.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  67%|   | 1077/1600 [13:40<06:51,  1.27it/s, loss=0.000823, recon_loss=0.000625, kl_loss=0.197]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110654.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.772785639455378e-09/0.37157464027404785\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122107.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096742.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073820.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  67%|   | 1078/1600 [13:40<06:56,  1.25it/s, loss=0.00052, recon_loss=0.00033, kl_loss=0.19]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0273944889283015e-10/0.3109295070171356\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083719.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051268.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075230.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086721.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  67%|   | 1079/1600 [13:41<06:43,  1.29it/s, loss=0.000397, recon_loss=0.000213, kl_loss=0.183]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046078.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.825804059282461e-11/0.47095340490341187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/057/057175.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052646.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  68%|   | 1080/1600 [13:42<06:21,  1.36it/s, loss=0.00209, recon_loss=0.00192, kl_loss=0.176]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142668.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001102.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/058/058060.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011776.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088860.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1351392048553066e-10/0.30927807092666626\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053589.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110649.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  68%|   | 1081/1600 [13:43<07:52,  1.10it/s, loss=0.000421, recon_loss=0.000249, kl_loss=0.172]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142948.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.132766276612518e-11/0.32644349336624146\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123490.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  68%|   | 1082/1600 [13:44<06:47,  1.27it/s, loss=0.000332, recon_loss=0.000165, kl_loss=0.167]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048368.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.727969930648726e-10/0.38795390725135803\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052508.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111911.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  68%|   | 1083/1600 [13:44<06:31,  1.32it/s, loss=0.000469, recon_loss=0.000307, kl_loss=0.162]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075783.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115392.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110111.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.3705402358030767e-10/0.39235907793045044\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149103.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  68%|   | 1084/1600 [13:45<06:22,  1.35it/s, loss=0.00112, recon_loss=0.000968, kl_loss=0.157]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053152.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074390.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004037.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.78381015356355e-11/0.4202064275741577\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122085.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054467.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/023/023016.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069791.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  68%|   | 1085/1600 [13:46<07:34,  1.13it/s, loss=0.00128, recon_loss=0.00112, kl_loss=0.153]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.243199486746562e-09/0.3919352889060974\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073170.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001083.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  68%|   | 1086/1600 [13:47<06:20,  1.35it/s, loss=0.000768, recon_loss=0.000618, kl_loss=0.15]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.031015089060567e-12/0.29653799533843994\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  68%|   | 1087/1600 [13:47<05:07,  1.67it/s, loss=0.0003, recon_loss=0.000153, kl_loss=0.148]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132795.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063471.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.484374483913143e-09/0.37902504205703735\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142085.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145004.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129816.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  68%|   | 1088/1600 [13:47<05:09,  1.65it/s, loss=0.000547, recon_loss=0.000403, kl_loss=0.145]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099440.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107025.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122087.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129997.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107435.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114040.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.6845178857648477e-11/0.3601348400115967\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134923.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127349.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/121/121475.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  68%|   | 1089/1600 [13:49<07:14,  1.18it/s, loss=0.000896, recon_loss=0.000755, kl_loss=0.141]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.276289248788089e-07/0.38196995854377747\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134094.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113810.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  68%|   | 1090/1600 [13:49<06:18,  1.35it/s, loss=0.00116, recon_loss=0.00102, kl_loss=0.139]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054624.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.015509426023243e-10/0.41645538806915283\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088856.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132118.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  68%|   | 1091/1600 [13:50<05:54,  1.43it/s, loss=0.00156, recon_loss=0.00142, kl_loss=0.137]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.1779138482134215e-10/0.33844485878944397\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040938.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126429.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056798.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090027.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  68%|   | 1092/1600 [13:51<05:50,  1.45it/s, loss=0.000443, recon_loss=0.000305, kl_loss=0.138]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.820699591092989e-09/0.31076592206954956\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003896.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129405.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114395.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056694.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117668.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128482.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  68%|   | 1093/1600 [13:52<06:56,  1.22it/s, loss=0.000436, recon_loss=0.000299, kl_loss=0.138]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.4422968028227068e-12/0.389644056558609\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148031.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081037.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  68%|   | 1094/1600 [13:52<06:03,  1.39it/s, loss=0.000461, recon_loss=0.000324, kl_loss=0.137]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5547133358495557e-08/0.3458338975906372\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066534.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/101/101893.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126015.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080389.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099368.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084152.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012481.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  68%|   | 1095/1600 [13:54<07:24,  1.14it/s, loss=0.00056, recon_loss=0.000425, kl_loss=0.135]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.79345734006165e-08/0.4588226079940796\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086487.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/041/041971.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  68%|   | 1096/1600 [13:54<06:31,  1.29it/s, loss=0.00284, recon_loss=0.0027, kl_loss=0.134]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1133357430415103e-10/0.40451255440711975\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117611.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090278.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  69%|   | 1097/1600 [13:54<05:36,  1.49it/s, loss=0.00118, recon_loss=0.00105, kl_loss=0.136]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.0137796380149666e-08/0.403757244348526\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/137/137896.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136449.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060736.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122362.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099439.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134610.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  69%|   | 1098/1600 [13:55<06:24,  1.30it/s, loss=0.000884, recon_loss=0.000746, kl_loss=0.139]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062446.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064865.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112735.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.16120132690412e-08/0.40657123923301697\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006680.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124184.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  69%|   | 1099/1600 [13:56<06:46,  1.23it/s, loss=0.00141, recon_loss=0.00127, kl_loss=0.141]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067784.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.644656463412502e-09/0.4060405492782593\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114076.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012527.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139992.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  69%|   | 1100/1600 [13:57<06:59,  1.19it/s, loss=0.000968, recon_loss=0.000823, kl_loss=0.145]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/015/015773.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052123.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.344006374727542e-09/0.3857375979423523\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142093.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055900.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  69%|   | 1101/1600 [13:58<06:55,  1.20it/s, loss=0.000865, recon_loss=0.000716, kl_loss=0.149]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040903.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.8939130819184413e-10/0.3423319458961487\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071510.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/022/022295.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131657.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  69%|   | 1102/1600 [13:59<06:44,  1.23it/s, loss=0.000339, recon_loss=0.000186, kl_loss=0.152]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133836.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.5186826846379518e-08/0.42750394344329834\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072456.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  69%|   | 1103/1600 [13:59<05:45,  1.44it/s, loss=0.0013, recon_loss=0.00114, kl_loss=0.154]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081945.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.251895254128499e-10/0.3747619092464447\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026307.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110744.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081638.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142577.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  69%|   | 1104/1600 [14:00<06:14,  1.32it/s, loss=0.000994, recon_loss=0.000837, kl_loss=0.156]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063747.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063117.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/046/046726.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145058.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087161.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.228334544136402e-10/0.3730536997318268\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/135/135222.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  69%|   | 1106/1600 [14:02<05:27,  1.51it/s, loss=0.00135, recon_loss=0.00119, kl_loss=0.159]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.317479955304407e-09/0.42597368359565735\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110648.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/095/095486.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047197.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.632529773587521e-07/0.42802342772483826\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090639.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  69%|   | 1107/1600 [14:02<05:25,  1.51it/s, loss=0.00173, recon_loss=0.00157, kl_loss=0.161]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/094/094033.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146152.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131021.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.029997142078855e-09/0.40058156847953796\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038820.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006381.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144487.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132041.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085427.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  69%|   | 1109/1600 [14:04<05:26,  1.50it/s, loss=0.000363, recon_loss=0.000196, kl_loss=0.167]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.907502789558427e-12/0.3452157974243164\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122805.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/079/079606.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112210.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/059/059823.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074389.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.344014011195327e-09/0.3983582556247711\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122474.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/061/061589.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148113.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/141/141593.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  69%|   | 1110/1600 [14:05<07:36,  1.07it/s, loss=0.000693, recon_loss=0.000525, kl_loss=0.168]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062452.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.786916794178978e-08/0.47807955741882324\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  69%|   | 1111/1600 [14:06<05:53,  1.38it/s, loss=0.00344, recon_loss=0.00327, kl_loss=0.168]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.2098851637508687e-09/0.32953935861587524\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049817.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/091/091177.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  70%|   | 1112/1600 [14:06<05:06,  1.59it/s, loss=0.000322, recon_loss=0.000149, kl_loss=0.173]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098583.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.6868141872758997e-10/0.33157867193222046\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/032/032001.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107577.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132042.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088861.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063733.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  70%|   | 1113/1600 [14:07<05:42,  1.42it/s, loss=0.000375, recon_loss=0.0002, kl_loss=0.176]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.0191899088099e-12/0.43037715554237366\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/136/136320.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/129/129918.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/022/022000.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  70%|   | 1114/1600 [14:07<05:11,  1.56it/s, loss=0.00121, recon_loss=0.00103, kl_loss=0.176]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049476.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056690.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.1976536146439685e-09/0.4260962903499603\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/008/008372.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074937.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/030/030120.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010527.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  70%|   | 1115/1600 [14:08<06:20,  1.27it/s, loss=0.000721, recon_loss=0.000544, kl_loss=0.177]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.5967314137554922e-09/0.40871763229370117\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120172.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/146/146147.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131902.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  70%|   | 1116/1600 [14:09<05:53,  1.37it/s, loss=0.00112, recon_loss=0.000947, kl_loss=0.177]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090695.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001066.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115699.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.476029395547812e-08/0.4646553695201874\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071252.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069762.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  70%|   | 1117/1600 [14:10<06:24,  1.26it/s, loss=0.0029, recon_loss=0.00272, kl_loss=0.178]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2066921684095178e-08/0.4347730278968811\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  70%|   | 1118/1600 [14:10<05:03,  1.59it/s, loss=0.00142, recon_loss=0.00124, kl_loss=0.183]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144934.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052860.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/015/015769.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.966957400931449e-10/0.3926534950733185\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054158.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042031.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  70%|   | 1119/1600 [14:11<05:15,  1.52it/s, loss=0.000733, recon_loss=0.000545, kl_loss=0.188]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131941.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.441900485265606e-11/0.37987473607063293\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133681.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116116.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027194.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001689.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  70%|   | 1120/1600 [14:12<05:39,  1.42it/s, loss=0.000503, recon_loss=0.000311, kl_loss=0.192]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011790.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144216.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/022/022095.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083558.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116242.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.072707336990391e-10/0.4625166356563568\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047896.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127181.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  70%|   | 1121/1600 [14:13<07:05,  1.13it/s, loss=0.00537, recon_loss=0.00517, kl_loss=0.195]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098669.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.0698626690982564e-09/0.3446003794670105\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/075/075928.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  70%|   | 1122/1600 [14:14<06:07,  1.30it/s, loss=0.000487, recon_loss=0.00028, kl_loss=0.207]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108300.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149626.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.7424082177086575e-09/0.29450348019599915\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051263.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/084/084135.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/080/080694.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074371.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  70%|   | 1123/1600 [14:15<07:09,  1.11it/s, loss=0.00041, recon_loss=0.000194, kl_loss=0.216]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120333.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116528.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.257281163854714e-09/0.354391872882843\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134922.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  70%|   | 1124/1600 [14:15<06:35,  1.20it/s, loss=0.000697, recon_loss=0.000474, kl_loss=0.223]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.401305667059205e-07/0.37284278869628906\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130667.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054159.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  70%|   | 1125/1600 [14:16<05:41,  1.39it/s, loss=0.00107, recon_loss=0.000842, kl_loss=0.229]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086116.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.9353839419977703e-08/0.35018834471702576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042138.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011237.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  70%|   | 1126/1600 [14:16<05:22,  1.47it/s, loss=0.000653, recon_loss=0.00042, kl_loss=0.233]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134084.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107617.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148076.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.182875575267417e-08/0.39257562160491943\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126749.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072784.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/022/022315.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  70%|   | 1127/1600 [14:17<05:54,  1.34it/s, loss=0.000611, recon_loss=0.000374, kl_loss=0.236]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/076/076072.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.79633169450355e-10/0.28969234228134155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/009/009505.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063287.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038775.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035296.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  70%|   | 1128/1600 [14:18<06:27,  1.22it/s, loss=0.000386, recon_loss=0.000148, kl_loss=0.238]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/060/060756.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.5357412553338463e-09/0.44148316979408264\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099395.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142576.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/089/089816.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  71%|   | 1129/1600 [14:19<06:32,  1.20it/s, loss=0.00138, recon_loss=0.00115, kl_loss=0.237]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.2702217883363573e-09/0.4123133718967438\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117169.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120313.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  71%|   | 1130/1600 [14:20<05:36,  1.40it/s, loss=0.00115, recon_loss=0.000913, kl_loss=0.236]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092539.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056470.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6931905877370923e-09/0.32074129581451416\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068820.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055711.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  71%|   | 1131/1600 [14:20<05:29,  1.42it/s, loss=0.000498, recon_loss=0.000262, kl_loss=0.236]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.2639566877333834e-10/0.4254911243915558\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139772.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145761.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112133.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/090/090527.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  71%|   | 1132/1600 [14:21<05:23,  1.45it/s, loss=0.000855, recon_loss=0.000621, kl_loss=0.234]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036966.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.4308247081883394e-10/0.3446556329727173\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/140/140922.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114233.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  71%|   | 1133/1600 [14:22<05:07,  1.52it/s, loss=0.000468, recon_loss=0.000237, kl_loss=0.232]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133450.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/117/117942.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.2508391534236125e-09/0.403932124376297\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122675.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085492.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145745.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/041/041020.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/028/028072.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087096.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  71%|   | 1134/1600 [14:23<06:48,  1.14it/s, loss=0.000958, recon_loss=0.00073, kl_loss=0.228]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.917646703883065e-10/0.44650259613990784\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026651.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072070.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  71%|   | 1135/1600 [14:23<05:52,  1.32it/s, loss=0.000904, recon_loss=0.000679, kl_loss=0.224]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/013/013220.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.8254347750333864e-09/0.32257452607154846\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073174.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114416.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036322.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  71%|   | 1136/1600 [14:24<05:56,  1.30it/s, loss=0.000512, recon_loss=0.000292, kl_loss=0.221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.62350382074828e-12/0.3253001570701599\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/126/126886.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118988.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040656.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  71%|   | 1137/1600 [14:25<05:28,  1.41it/s, loss=0.000499, recon_loss=0.000283, kl_loss=0.216]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086795.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072287.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123645.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026659.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/042/042376.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6039319666264623e-13/0.4054628312587738\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118954.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115176.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  71%|   | 1138/1600 [14:26<06:45,  1.14it/s, loss=0.00063, recon_loss=0.000419, kl_loss=0.21]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048443.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.132327119377166e-11/0.3705013394355774\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055430.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  71%|   | 1139/1600 [14:27<05:54,  1.30it/s, loss=0.000551, recon_loss=0.000346, kl_loss=0.205]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108839.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.999986533808624e-08/0.4417283236980438\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106463.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/007/007712.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052629.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142536.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120330.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  71%|  | 1140/1600 [14:28<06:52,  1.11it/s, loss=0.00155, recon_loss=0.00135, kl_loss=0.199]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/104/104068.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.611894391525766e-09/0.4071730077266693\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149102.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  71%|  | 1141/1600 [14:28<05:55,  1.29it/s, loss=0.00149, recon_loss=0.00129, kl_loss=0.194]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134445.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/074/074381.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.2698124773891095e-09/0.31046560406684875\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/043/043533.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142579.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087188.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087160.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  71%|  | 1142/1600 [14:29<06:50,  1.12it/s, loss=0.000427, recon_loss=0.000235, kl_loss=0.192]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0161083913450284e-09/0.3765207529067993\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/081/081623.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097215.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  72%|  | 1144/1600 [14:30<04:18,  1.77it/s, loss=0.00224, recon_loss=0.00206, kl_loss=0.185]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.912040913434112e-09/0.43053320050239563\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139485.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040233.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149778.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.524755901184733e-10/0.314396470785141\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067010.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/062/062591.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/067/067016.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/053/053229.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011261.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040239.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/119/119086.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108299.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  72%|  | 1146/1600 [14:32<05:19,  1.42it/s, loss=0.000816, recon_loss=0.000631, kl_loss=0.185]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.457832602002611e-10/0.37578317523002625\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068892.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/063/063900.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.8430222559782123e-08/0.46259036660194397\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055293.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  72%|  | 1147/1600 [14:33<05:01,  1.50it/s, loss=0.00445, recon_loss=0.00427, kl_loss=0.184]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.65105243208086e-09/0.35188278555870056\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054580.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/118/118953.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144946.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/093/093522.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/073/073306.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052042.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127357.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  72%|  | 1148/1600 [14:34<06:02,  1.25it/s, loss=0.000503, recon_loss=0.000313, kl_loss=0.19]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.065000198088086e-10/0.4260435104370117\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/045/045126.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/128/128760.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  72%|  | 1149/1600 [14:34<05:10,  1.45it/s, loss=0.000981, recon_loss=0.000786, kl_loss=0.195]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/027/027673.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/025/025609.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.508648650450084e-09/0.3589683175086975\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012353.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114391.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127299.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/087/087193.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145741.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  72%|  | 1150/1600 [14:35<06:26,  1.16it/s, loss=0.000439, recon_loss=0.000239, kl_loss=0.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.530183060959871e-09/0.40961289405822754\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/056/056803.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107429.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  72%|  | 1151/1600 [14:36<05:27,  1.37it/s, loss=0.00134, recon_loss=0.00114, kl_loss=0.203]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116757.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.6382852852103724e-09/0.38578200340270996\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004684.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/108/108531.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070878.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107567.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  72%|  | 1152/1600 [14:37<05:53,  1.27it/s, loss=0.000878, recon_loss=0.000672, kl_loss=0.206]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/134/134052.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.539439377841518e-09/0.40017133951187134\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/064/064553.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133544.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/069/069826.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  72%|  | 1153/1600 [14:38<05:59,  1.24it/s, loss=0.00073, recon_loss=0.000522, kl_loss=0.208]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003920.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.33429613416547e-08/0.3836391270160675\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/010/010386.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/049/049030.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120111.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  72%|  | 1154/1600 [14:38<05:57,  1.25it/s, loss=0.000935, recon_loss=0.000725, kl_loss=0.21]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.061847722728999e-08/0.38305869698524475\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110928.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107184.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  72%|  | 1155/1600 [14:39<05:10,  1.43it/s, loss=0.000604, recon_loss=0.000394, kl_loss=0.211]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/120/120312.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052446.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.7902509453811035e-09/0.39975666999816895\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/147/147261.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066058.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  72%|  | 1156/1600 [14:40<05:10,  1.43it/s, loss=0.000789, recon_loss=0.000578, kl_loss=0.21]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123506.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.579094963792386e-10/0.42716389894485474\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123614.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110775.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/115/115293.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/036/036097.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088900.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040908.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  72%|  | 1157/1600 [14:41<06:22,  1.16it/s, loss=0.00164, recon_loss=0.00143, kl_loss=0.209]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/014/014684.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.4661373771172066e-10/0.3542204201221466\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/001/001482.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  72%|  | 1158/1600 [14:41<05:35,  1.32it/s, loss=0.000597, recon_loss=0.000387, kl_loss=0.21]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048015.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.130333021099773e-09/0.3291146457195282\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/052/052129.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/071/071158.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106563.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/088/088899.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145005.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  72%|  | 1159/1600 [14:43<06:37,  1.11it/s, loss=0.000524, recon_loss=0.000315, kl_loss=0.209]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.713533202111876e-09/0.3741324543952942\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/098/098701.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038898.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  72%|  | 1160/1600 [14:43<05:29,  1.34it/s, loss=0.000556, recon_loss=0.000349, kl_loss=0.207]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 6.234177174491151e-09/0.3623950481414795\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/037/037041.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004688.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  73%|  | 1161/1600 [14:43<04:50,  1.51it/s, loss=0.000722, recon_loss=0.000518, kl_loss=0.204]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.710172974929037e-09/0.4676544666290283\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/040/040683.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004788.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/138/138016.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  73%|  | 1162/1600 [14:44<04:37,  1.58it/s, loss=0.00301, recon_loss=0.00281, kl_loss=0.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097569.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092124.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072068.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/139/139934.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/092/092275.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/125/125617.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.961286854092805e-10/0.3301873207092285\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/047/047895.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  73%|  | 1163/1600 [14:45<05:52,  1.24it/s, loss=0.00067, recon_loss=0.00047, kl_loss=0.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127469.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/026/026011.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.634253550264475e-07/0.38359200954437256\n",
            "Input data min/max: 0.0/0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024369.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/085/085953.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/000/000897.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012518.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  73%|  | 1165/1600 [14:46<04:54,  1.48it/s, loss=0.000562, recon_loss=0.000363, kl_loss=0.199]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 4.678376352984515e-09/0.33740153908729553\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/006/006387.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/106/106937.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.1512835840221669e-07/0.3885963559150696\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/116/116240.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114943.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  73%|  | 1166/1600 [14:47<05:00,  1.45it/s, loss=0.000769, recon_loss=0.000572, kl_loss=0.197]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/035/035182.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/066/066074.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 8.456008671053894e-10/0.4001758098602295\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/070/070875.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/145/145742.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/023/023039.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114390.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122635.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  73%|  | 1167/1600 [14:48<05:53,  1.23it/s, loss=0.00116, recon_loss=0.00096, kl_loss=0.196]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/002/002096.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.3361806156192997e-13/0.3171243369579315\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/048/048494.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/051/051260.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/021/021422.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  73%|  | 1168/1600 [14:49<05:51,  1.23it/s, loss=0.000297, recon_loss=0.000102, kl_loss=0.194]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099374.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.1851197240518871e-10/0.4558897018432617\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097886.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111413.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/123/123821.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  73%|  | 1169/1600 [14:50<05:48,  1.24it/s, loss=0.0018, recon_loss=0.00161, kl_loss=0.192]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/112/112020.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148302.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed output min/max: 2.833455414741337e-10/0.35377100110054016\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/133/133297.mp3: Failed to open the input \"/content/drive/MyDrive/DL4AM_datasets/fma_small/133/133297.mp3\" (Invalid argument).\n",
            "Exception raised from get_input_format_context at /__w/audio/audio/pytorch/audio/src/libtorio/ffmpeg/stream_reader/stream_reader.cpp:42 (most recent call first):\n",
            "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x79bfa736c1b6 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\n",
            "frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x79bfa7315a76 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\n",
            "frame #2: <unknown function> + 0x42034 (0x79bfa72a8034 in /usr/local/lib/python3.11/dist-packages/torio/lib/libtorio_ffmpeg4.so)\n",
            "frame #3: torio::io::StreamingMediaDecoder::StreamingMediaDecoder(std::string const&, std::optional<std::string> const&, std::optional<std::map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<std::string const, std::string> > > > const&) + 0x14 (0x79bfa72aaa34 in /usr/local/lib/python3.11/dist-packages/torio/lib/libtorio_ffmpeg4.so)\n",
            "frame #4: <unknown function> + 0x3bfee (0x79be7af58fee in /usr/local/lib/python3.11/dist-packages/torio/lib/_torio_ffmpeg4.so)\n",
            "frame #5: <unknown function> + 0x330c7 (0x79be7af500c7 in /usr/local/lib/python3.11/dist-packages/torio/lib/_torio_ffmpeg4.so)\n",
            "frame #6: /usr/bin/python3() [0x55560b]\n",
            "frame #7: _PyObject_MakeTpCall + 0x27c (0x52f6dc in /usr/bin/python3)\n",
            "frame #8: /usr/bin/python3() [0x5853fd]\n",
            "frame #9: /usr/bin/python3() [0x56e2a9]\n",
            "frame #10: /usr/bin/python3() [0x52fac0]\n",
            "frame #11: <unknown function> + 0xfc6b (0x79bfa7751c6b in /usr/local/lib/python3.11/dist-packages/torchaudio/lib/_torchaudio.so)\n",
            "frame #12: _PyObject_MakeTpCall + 0x27c (0x52f6dc in /usr/bin/python3)\n",
            "frame #13: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #14: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #15: /usr/bin/python3() [0x56df36]\n",
            "frame #16: _PyObject_MakeTpCall + 0x23b (0x52f69b in /usr/bin/python3)\n",
            "frame #17: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #18: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #19: _PyEval_EvalFrameDefault + 0x4aab (0x541c5b in /usr/bin/python3)\n",
            "frame #20: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #21: /usr/bin/python3() [0x56df36]\n",
            "frame #22: _PyObject_MakeTpCall + 0x23b (0x52f69b in /usr/bin/python3)\n",
            "frame #23: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #24: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #25: /usr/bin/python3() [0x56df36]\n",
            "frame #26: _PyObject_MakeTpCall + 0x23b (0x52f69b in /usr/bin/python3)\n",
            "frame #27: _PyEval_EvalFrameDefault + 0x6bf (0x53d86f in /usr/bin/python3)\n",
            "frame #28: _PyFunction_Vectorcall + 0x173 (0x566243 in /usr/bin/python3)\n",
            "frame #29: PyObject_CallOneArg + 0x47 (0x56bde7 in /usr/bin/python3)\n",
            "frame #30: /usr/bin/python3() [0x6566fd]\n",
            "frame #31: PyObject_GetIter + 0x18 (0x52c1a8 in /usr/bin/python3)\n",
            "frame #32: _PyEval_EvalFrameDefault + 0x232a (0x53f4da in /usr/bin/python3)\n",
            "frame #33: /usr/bin/python3() [0x583367]\n",
            "frame #34: /usr/bin/python3() [0x5b95f5]\n",
            "frame #35: _PyEval_EvalFrameDefault + 0x549 (0x53d6f9 in /usr/bin/python3)\n",
            "frame #36: /usr/bin/python3() [0x613a24]\n",
            "frame #37: PyEval_EvalCode + 0x97 (0x613087 in /usr/bin/python3)\n",
            "frame #38: /usr/bin/python3() [0x62cde3]\n",
            "frame #39: _PyEval_EvalFrameDefault + 0x3801 (0x5409b1 in /usr/bin/python3)\n",
            "frame #40: /usr/bin/python3() [0x6288d0]\n",
            "frame #41: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #42: /usr/bin/python3() [0x6288d0]\n",
            "frame #43: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #44: /usr/bin/python3() [0x6288d0]\n",
            "frame #45: /usr/bin/python3() [0x62ae9c]\n",
            "frame #46: _PyEval_EvalFrameDefault + 0x3a8a (0x540c3a in /usr/bin/python3)\n",
            "frame #47: /usr/bin/python3() [0x585b17]\n",
            "frame #48: /usr/bin/python3() [0x5852fe]\n",
            "frame #49: PyObject_Call + 0xf4 (0x570784 in /usr/bin/python3)\n",
            "frame #50: _PyEval_EvalFrameDefault + 0x4aab (0x541c5b in /usr/bin/python3)\n",
            "frame #51: /usr/bin/python3() [0x6288d0]\n",
            "frame #52: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #53: /usr/bin/python3() [0x6288d0]\n",
            "frame #54: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #55: /usr/bin/python3() [0x6288d0]\n",
            "frame #56: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #57: /usr/bin/python3() [0x6288d0]\n",
            "frame #58: _PyEval_EvalFrameDefault + 0x3444 (0x5405f4 in /usr/bin/python3)\n",
            "frame #59: /usr/bin/python3() [0x6288d0]\n",
            "frame #60: <unknown function> + 0x745f (0x79c037bfa45f in /usr/lib/python3.11/lib-dynload/_asyncio.cpython-311-x86_64-linux-gnu.so)\n",
            "frame #61: /usr/bin/python3() [0x553a8f]\n",
            "frame #62: /usr/bin/python3() [0x4d0cb0]\n",
            "\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144600.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  73%|  | 1170/1600 [14:50<05:21,  1.34it/s, loss=0.000444, recon_loss=0.000254, kl_loss=0.191]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/083/083906.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.860871675813286e-11/0.4168316721916199\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114371.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/124/124912.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/096/096166.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  73%|  | 1171/1600 [14:51<05:17,  1.35it/s, loss=0.000552, recon_loss=0.000363, kl_loss=0.188]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/144/144215.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 1.3989038816220045e-09/0.43407130241394043\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/097/097041.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/044/044848.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/148/148287.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  73%|  | 1172/1600 [14:52<05:21,  1.33it/s, loss=0.00207, recon_loss=0.00189, kl_loss=0.186]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/054/054163.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.9210454499661864e-08/0.3657967150211334\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055292.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/127/127290.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  73%|  | 1173/1600 [14:53<05:01,  1.42it/s, loss=0.00071, recon_loss=0.000525, kl_loss=0.185]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/086/086443.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/111/111227.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.0639627784646564e-09/0.37698352336883545\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  73%|  | 1174/1600 [14:53<04:36,  1.54it/s, loss=0.000651, recon_loss=0.000468, kl_loss=0.184]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110207.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/143/143216.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/003/003721.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131795.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/142/142537.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.4824342581553083e-10/0.3475341498851776\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/055/055572.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/110/110546.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011234.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  73%|  | 1175/1600 [14:54<05:52,  1.20it/s, loss=0.000626, recon_loss=0.000444, kl_loss=0.182]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/132/132962.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 5.657639912115542e-10/0.36334842443466187\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122932.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  74%|  | 1176/1600 [14:55<05:07,  1.38it/s, loss=0.000518, recon_loss=0.000338, kl_loss=0.18]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/012/012691.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 7.216343522742363e-09/0.41125231981277466\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/072/072930.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107178.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/131/131553.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/130/130992.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/004/004682.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  74%|  | 1177/1600 [14:56<06:01,  1.17it/s, loss=0.000789, recon_loss=0.000613, kl_loss=0.177]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/011/011783.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/038/038895.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 9.485214835791567e-10/0.3369414806365967\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:  74%|  | 1178/1600 [14:56<05:16,  1.33it/s, loss=0.000341, recon_loss=0.000168, kl_loss=0.173]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/149/149452.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 3.4917119196009594e-10/0.42100101709365845\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/024/024367.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/113/113336.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/114/114234.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/005/005158.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/107/107805.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  74%|  | 1179/1600 [14:58<06:13,  1.13it/s, loss=0.000851, recon_loss=0.000682, kl_loss=0.169]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.443774071991811e-09/0.3269064426422119\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/068/068838.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/082/082630.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  74%|  | 1180/1600 [14:58<05:17,  1.32it/s, loss=0.000375, recon_loss=0.000209, kl_loss=0.166]WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/099/099261.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Model input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder input shape: torch.Size([4, 1, 128, 860])\n",
            "Encoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Flattened encoder output shape: torch.Size([4, 221184])\n",
            "Mu shape: torch.Size([4, 16])\n",
            "Log_var shape: torch.Size([4, 16])\n",
            "Latent vector shape: torch.Size([4, 16])\n",
            "Decoder input shape: torch.Size([4, 16])\n",
            "Decoder FC output shape: torch.Size([4, 221184])\n",
            "Reshaped decoder output shape: torch.Size([4, 128, 16, 108])\n",
            "Decoder conv output shape: torch.Size([4, 1, 128, 864])\n",
            "Final decoder output shape: torch.Size([4, 1, 128, 860])\n",
            "Model output shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n",
            "Reconstructed output min/max: 2.9461615369541505e-09/0.36812451481819153\n",
            "Input data min/max: 0.0/0.0\n",
            "Reconstructed output shape: torch.Size([4, 1, 128, 860])\n",
            "Input data shape: torch.Size([4, 1, 128, 860])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Error processing /content/drive/MyDrive/DL4AM_datasets/fma_small/122/122353.mp3: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'\n",
            "Epoch 1/100 [Train]:  74%|  | 1180/1600 [14:59<05:17,  1.32it/s, loss=0.000579, recon_loss=0.000418, kl_loss=0.161]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get a sample from the FMADataset\n",
        "sample = fma_dataset[0]\n",
        "\n",
        "# Extract the spectrogram tensor\n",
        "spec = sample['spectrogram']  # Shape: (1, 128, 860)\n",
        "\n",
        "# Remove channel dimension for plotting and printing\n",
        "spec_2d = spec.squeeze(0)  # Shape: (128, 860)\n",
        "\n",
        "# Print a small portion (top 5 mel bands, first 10 frames)\n",
        "print(\"Spectrogram slice (mel 0:5, frames 0:10):\")\n",
        "print(spec_2d[0:5, 0:10])\n",
        "\n",
        "# Plot the full spectrogram for visual upload\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.imshow(spec_2d.numpy(), aspect='auto', origin='lower', cmap='magma')\n",
        "plt.title(\"Mel Spectrogram (FMADataset sample)\")\n",
        "plt.xlabel(\"Time frames\")\n",
        "plt.ylabel(\"Mel bands\")\n",
        "plt.colorbar(label='dB')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BAq-t2A322dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first sample from FMADataset\n",
        "sample = fma_dataset[0]\n",
        "print(\"Sample type:\", type(sample))\n",
        "print(\"Sample contents:\", sample)\n"
      ],
      "metadata": {
        "id": "w8S28I3UPLgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xCzHXSFbP0m7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}